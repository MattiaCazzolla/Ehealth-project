PMID,doi,Title,Pubblication Date,Journal Title,Authors,Keywords,Abstract,Pubblication type,Conflic Of Interests
36206688,10.1016/j.cmpb.2022.107147,Convolutional bi-directional learning and spatial enhanced attentions for lung tumor segmentation.,2022 Sep 20,Computer methods and programs in biomedicine,"Xuan P, Jiang B, Cui H, Jin Q, Cheng P, Nakaguchi T, Zhang T, Li C, Ning Z, Guo M, Wang L","Convolutional bi-directional gated recurrent unit, Cross-channel region-level attention mechanism, Lung tumor segmentation from CT volumes, Multi-channel contextual relation learning, Position enhanced self-attention mechanism","BACKGROUND AND OBJECTIVE: Accurate lung tumor segmentation from computed tomography (CT) is complex due to variations in tumor sizes, shapes, patterns and growing locations. Learning semantic and spatial relations between different feature channels, image regions and positions is critical yet challenging. METHODS: We propose a new segmentation method, PRCS, by learning and integrating multi-channel contextual relations, and spatial and position dependencies across image regions. Firstly, to extract contextual relationships between different deep image feature tensor channels, we propose a new convolutional bi-directional gated recurrent unit based module for forward and backward learning. Secondly, a novel cross-channel region-level attention mechanism is proposed to discriminate the contributions of different local regions and associated features in the global learning process. Finally, spatial and position dependencies are formulated by a new position-enhanced self-attention mechanism. The new attention can measure the diverse contributions of other positions to a target position and obtain an enhanced adaptive feature vector for the target position. RESULTS: Our model outperformed seven state-of-the-art segmentation methods on both public and in-house lung tumor datasets in terms of spatial overlapping and shape similarity. Ablation study results proved the effectiveness of three technical innovations and generalization ability on different 3D CNN segmentation backbones. CONCLUSION: The proposed model enhanced the learning and propagation of contextual, spatial and position relations in 3D volumes, improving lung tumours' segmentation performance with large variations and indistinct boundaries. PRCS provides an effective automated approach to support precision diagnosis and treatment planning of lung cancer.",Journal Article,Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
36203393,10.1002/mp.16001,Automated Lung Tumor Delineation on Positron Emission Tomography/Computed Tomography via a Hybrid Regional Network.,2022 Oct 6,Medical physics,"Lei Y, Wang T, Jeong JJ, Janopaul-Naylor J, Kesarwala AH, Roper J, Tian S, Bradley JD, Liu T, Higgins K, Yang X","PET/CT, deep learning, lung tumor, radiotherapy, segmentation","BACKGROUND: Multimodality positron emission tomography/computed tomography (PET/CT) imaging combines the anatomical information of CT with the functional information of PET. In the diagnosis and treatment of many cancers such as non-small cell lung cancer (NSCLC), PET/CT imaging allows more accurate delineation of tumor or involved lymph nodes for radiation planning. PURPOSE: In this paper, we propose a hybrid regional network method of automatically segmenting lung tumors from PET/CT images. METHODS: The hybrid regional network architecture synthesizes the functional and anatomical information from the two image modalities while the mask regional convolutional neural network (R-CNN) and scoring fine-tune the regional location and quality of the output segmentation. This model consists of five major subnetworks, i.e., a dual feature representation network (DFRN), a regional proposal network (RPN), a specific tumor-wise R-CNN, a mask-Net and a score head. Given a PET/CT image as input, the DFRN extracts feature maps from the PET and CT images. Then, the RPN and R-CNN work together to localize lung tumors and reduce the image size and feature map size by removing irrelevant regions. The mask-Net is used to segment tumor within a volume-of-interest (VOI) with a score head evaluating the segmentation performed by the mask-Net. Finally, the segmented tumor within the VOI was mapped back to the volumetric coordinate system based on the location information derived via the RPN and R-CNN. We trained, validated, and tested the proposed neural network using 100 PET/CT images of patients with NSCLC. A five-fold cross-validation study was performed. The segmentation was evaluated with two indicators, 1) multiple metrics including the Dice similarity coefficient (DSC), Jacard, 95th percentile Hausdorff distance (HD95 ), mean surface distance (MSD), residual mean square distance (RMSD), and center-of-mass distance (COMD); 2) Bland-Altman analysis and volumetric Pearson correlation analysis. RESULTS: In five-fold cross-validation, this method achieved Dice and MSD of 0.84+/-0.15 and 1.38+/-2.2 mm, respectively. A new PET/CT can be segmented in 1 s by this model. External validation on The Cancer Imaging Archive (TCIA) dataset (63 PET/CT images) indicates that the proposed model has superior performance compared to other methods. CONCLUSION: The proposed method shows great promise to automatically delineate NSCLC tumors on PET/CT images, thereby allowing for a more streamlined clinical workflow that is faster and reduces physician effort. This article is protected by copyright. All rights reserved.",Journal Article,
36199795,10.1155/2022/5682451,Lung Cancer Nodules Detection via an Adaptive Boosting Algorithm Based on Self-Normalized Multiview Convolutional Neural Network.,2022,Journal of oncology,"Khan A, Tariq I, Khan H, Khan SU, He N, Zhiyang L, Raza F",,"Lung cancer is the deadliest cancer killing almost 1.8 million people in 2020. The new cases are expanding alarmingly. Early lung cancer manifests itself in the form of nodules in the lungs. One of the most widely used techniques for both lung cancer early and noninvasive diagnosis is computed tomography (CT). However, the intensive workload of radiologists to read a large number of scans for nodules detection gives rise to issues like false detection and missed detection. To overcome these issues, we proposed an innovative strategy titled adaptive boosting self-normalized multiview convolution neural network (AdaBoost-SNMV-CNN) for lung cancer nodules detection across CT scans. In AdaBoost-SNMV-CNN, MV-CNN function as a baseline learner while the scaled exponential linear unit (SELU) activation function normalizes the layers by considering their neighbors' information and a special drop-out technique (alpha-dropout). The proposed method was trained and tested using the widely Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) and Early Lung Cancer Action Program (ELCAP) datasets. AdaBoost-SNMV-CNN achieved an accuracy of 92%, sensitivity of 93%, and specificity of 92% for lung nodules detection on the LIDC-IDRI dataset. Meanwhile, on the ELCAP dataset, the accuracy for detecting lung nodules was 99%, sensitivity 100%, and specificity 98%. AdaBoost-SNMV-CNN outperformed the majority of the model in accuracy, sensitivity, and specificity. The multiviews confer the model's good generalization and learning ability for diverse features of lung nodules, the model architecture is simple, and has a minimal computational time of around 10(2) minutes. We believe that AdaBoost-SNMV-CNN has good accuracy for the detection of lung nodules and anticipate its potential application in the noninvasive clinical diagnosis of lung cancer. This model can be of good assistance to the radiologist and will be of interest to researchers involved in the designing and development of advanced systems for the detection of lung nodules to accomplish the goal of noninvasive diagnosis of lung cancer.",Journal Article,The authors declare that they have no conflicts of interest or personal relationships that could have appeared to influence the work reported in this research article.
36194194,10.7554/eLife.80547,Early stage NSCLS patients' prognostic prediction with multi-information using transformer and graph neural network model.,2022 Oct 4,eLife,"Lian J, Deng J, Hui ES, Koohi-Moghadam M, She Y, Chen C, Vardhanabhuti V","China, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, Prognosis, ROC Curve, computational biology, computed tomography, lung cancer, medical imaging, medicine, none, prognostic model, survival, systems biology, transformer cnn","Background: We proposed a population graph with Transformer-generated and clinical features for the purpose of predicting overall survival (OS) and recurrence-free survival (RFS) for patients with early stage non-small cell lung carcinomas and to compare this model with traditional models. Methods: The study included 1705 patients with lung cancer (stages I and II), and a public data set for external validation (n=127). We proposed a graph with edges representing non-imaging patient characteristics and nodes representing imaging tumour region characteristics generated by a pretrained Vision Transformer. The model was compared with a TNM model and a ResNet-Graph model. To evaluate the models' performance, the area under the receiver operator characteristic curve (ROC-AUC) was calculated for both OS and RFS prediction. The Kaplan-Meier method was used to generate prognostic and survival estimates for low- and high-risk groups, along with net reclassification improvement (NRI), integrated discrimination improvement (IDI), and decision curve analysis. An additional subanalysis was conducted to examine the relationship between clinical data and imaging features associated with risk prediction. Results: Our model achieved AUC values of 0.785 (95% confidence interval [CI]: 0.716-0.855) and 0.695 (95% CI: 0.603-0.787) on the testing and external data sets for OS prediction, and 0.726 (95% CI: 0.653-0.800) and 0.700 (95% CI: 0.615-0.785) for RFS prediction. Additional survival analyses indicated that our model outperformed the present TNM and ResNet-Graph models in terms of net benefit for survival prediction. Conclusions: Our Transformer-Graph model was effective at predicting survival in patients with early stage lung cancer, which was constructed using both imaging and non-imaging clinical features. Some high-risk patients were distinguishable by using a similarity score function defined by non-imaging characteristics such as age, gender, histology type, and tumour location, while Transformer-generated features demonstrated additional benefits for patients whose non-imaging characteristics were non-discriminatory for survival outcomes. Funding: The study was supported by the National Natural Science Foundation of China (91959126, 8210071009), and Science and Technology Commission of Shanghai Municipality (20XD1403000, 21YF1438200).",Journal Article,"JL, JD, EH, MK, YS, CC, VV No competing interests declared"
36191438,10.1016/j.saa.2022.121839,Raman spectroscopy and FTIR spectroscopy fusion technology combined with deep learning: A novel cancer prediction method.,2022 Sep 20,"Spectrochimica acta. Part A, Molecular and biomolecular spectroscopy","Leng H, Chen C, Chen C, Chen F, Du Z, Chen J, Yang B, Zuo E, Xiao M, Lv X, Liu P","FTIR spectroscopy, Feature fusion, Low-level fusion, MFCNN, Raman","According to the limited molecular information reflected by single spectroscopy, and the complementarity of FTIR spectroscopy and Raman spectroscopy, we propose a novel diagnostic technology combining multispectral fusion and deep learning. We used serum samples from 45 healthy controls, 44 non-small cell lung cancer (NSCLC), 38 glioma and 37 esophageal cancer patients, and the Raman spectra and FTIR spectra were collected respectively. Then we performed low-level fusion and feature fusion on the spectral, and used SVM, Convolutional Neural Network-Long-Short Term Memory (CNN-LSTM) and the multi-scale convolutional fusion neural network (MFCNN). The accuracy of low-level fusion and feature fusion models are improved by about 10% compared with single spectral models.",Journal Article,Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
36157356,10.1007/s11042-022-13843-7,"CDC_Net: multi-classification convolutional neural network model for detection of COVID-19, pneumothorax, pneumonia, lung Cancer, and tuberculosis using chest X-rays.",2022 Sep 20,Multimedia tools and applications,"Malik H, Anees T, Din M, Naeem A","COVID-19, Chest x-rays, Coronavirus, Deep learning, Pneumonia","Coronavirus (COVID-19) has adversely harmed the healthcare system and economy throughout the world. COVID-19 has similar symptoms as other chest disorders such as lung cancer (LC), pneumothorax, tuberculosis (TB), and pneumonia, which might mislead the clinical professionals in detecting a new variant of flu called coronavirus. This motivates us to design a model to classify multi-chest infections. A chest x-ray is the most ubiquitous disease diagnosis process in medical practice. As a result, chest x-ray examinations are the primary diagnostic tool for all of these chest infections. For the sake of saving human lives, paramedics and researchers are working tirelessly to establish a precise and reliable method for diagnosing the disease COVID-19 at an early stage. However, COVID-19's medical diagnosis is exceedingly idiosyncratic and varied. A multi-classification method based on the deep learning (DL) model is developed and tested in this work to automatically classify the COVID-19, LC, pneumothorax, TB, and pneumonia from chest x-ray images. COVID-19 and other chest tract disorders are diagnosed using a convolutional neural network (CNN) model called CDC Net that incorporates residual network thoughts and dilated convolution. For this study, we used this model in conjunction with publically available benchmark data to identify these diseases. For the first time, a single deep learning model has been used to diagnose five different chest ailments. In terms of classification accuracy, recall, precision, and f1-score, we compared the proposed model to three CNN-based pre-trained models, such as Vgg-19, ResNet-50, and inception v3. An AUC of 0.9953 was attained by the CDC Net when it came to identifying various chest diseases (with an accuracy of 99.39%, a recall of 98.13%, and a precision of 99.42%). Moreover, CNN-based pre-trained models Vgg-19, ResNet-50, and inception v3 achieved accuracy in classifying multi-chest diseases are 95.61%, 96.15%, and 95.16%, respectively. Using chest x-rays, the proposed model was found to be highly accurate in diagnosing chest diseases. Based on our testing data set, the proposed model shows significant performance as compared to its competitor methods. Statistical analyses of the datasets using McNemar's, and ANOVA tests also showed the robustness of the proposed model.",Journal Article,Conflict of interestThe authors declare no conflict of interest.
36148416,10.1155/2022/4608145,Analysis of Smart Lung Tumour Detector and Stage Classifier Using Deep Learning Techniques with Internet of Things.,2022,Computational intelligence and neuroscience,"Joshi S, Pandit SV, Shukla PK, Almalki AH, Othman NA, Alharbi A, Alhassan M","Artificial Intelligence, *Deep Learning, Humans, *Internet of Things, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer","The use of artificial intelligence (AI) and the Internet of Things (IoT), which is a developing technology in medical applications that assists physicians in making more informed decisions regarding patients' courses of treatment, has become increasingly widespread in recent years in the field of healthcare. On the other hand, the number of PET scans that are being performed is rising, and radiologists are getting significantly overworked as a result. As a direct result of this, a novel approach that goes by the name ""computer-aided diagnostics"" is now being investigated as a potential method for reducing the tremendous workloads. A Smart Lung Tumor Detector and Stage Classifier (SLD-SC) is presented in this study as a hybrid technique for PET scans. This detector can identify the stage of a lung tumour. Following the development of the modified LSTM for the detection of lung tumours, the proposed SLD-SC went on to develop a Multilayer Convolutional Neural Network (M-CNN) for the classification of the various stages of lung cancer. This network was then modelled and validated utilising standard benchmark images. The suggested SLD-SC is now being evaluated on lung cancer pictures taken from patients with the disease. We observed that our recommended method gave good results when compared to other tactics that are currently being used in the literature. These findings were outstanding in terms of the performance metrics accuracy, recall, and precision that were assessed. As can be shown by the much better outcomes that were achieved with each of the test images that were used, our proposed method excels its rivals in a variety of respects. In addition to this, it achieves an average accuracy of 97 percent in the categorization of lung tumours, which is much higher than the accuracy achieved by the other approaches.",Journal Article,The authors declare that they have no conflicts of interest related to this work.
36146380,10.3390/s22187031,Image Recovery from Synthetic Noise Artifacts in CT Scans Using Modified U-Net.,2022 Sep 16,"Sensors (Basel, Switzerland)","Gunawan R, Tran Y, Zheng J, Nguyen H, Chai R","*Artifacts, *Image Processing, Computer-Assisted/methods, Radiation Dosage, Signal-To-Noise Ratio, Tomography, X-Ray Computed/methods, denoising, lung cancer, noise artifacts","Computed Tomography (CT) is commonly used for cancer screening as it utilizes low radiation for the scan. One problem with low-dose scans is the noise artifacts associated with low photon count that can lead to a reduced success rate of cancer detection during radiologist assessment. The noise had to be removed to restore detail clarity. We propose a noise removal method using a new model Convolutional Neural Network (CNN). Even though the network training time is long, the result is better than other CNN models in quality score and visual observation. The proposed CNN model uses a stacked modified U-Net with a specific number of feature maps per layer to improve the image quality, observable on an average PSNR quality score improvement out of 174 images. The next best model has 0.54 points lower in the average score. The score difference is less than 1 point, but the image result is closer to the full-dose scan image. We used separate testing data to clarify that the model can handle different noise densities. Besides comparing the CNN configuration, we discuss the denoising quality of CNN compared to classical denoising in which the noise characteristics affect quality.",Journal Article,
36131239,10.1186/s12885-022-10081-w,Deep learning-based tumor microenvironment segmentation is predictive of tumor mutations and patient survival in non-small-cell lung cancer.,2022 Sep 21,BMC cancer,"Raczkowski L, Pasnik I, Kukielka M, Nicos M, Budzinska MA, Kucharczyk T, Szumilo J, Krawczyk P, Crosetto N, Szczurek E","*Adenocarcinoma of Lung/genetics, *Carcinoma, Non-Small-Cell Lung/genetics, *Deep Learning, Eosine Yellowish-(YS), Hematoxylin, Humans, *Lung Neoplasms/genetics/pathology, Mutation, Receptor, Platelet-Derived Growth Factor beta, Tumor Microenvironment/genetics, Bayesian deep learning, Digital pathology, Image segmentation, Mutation prediction, Survival prediction, Tumor microenvironment","BACKGROUND: Despite the fact that tumor microenvironment (TME) and gene mutations are the main determinants of progression of the deadliest cancer in the world - lung cancer, their interrelations are not well understood. Digital pathology data provides a unique insight into the spatial composition of the TME. Various spatial metrics and machine learning approaches were proposed for prediction of either patient survival or gene mutations from this data. Still, these approaches are limited in the scope of analyzed features and in their explainability, and as such fail to transfer to clinical practice. METHODS: Here, we generated 23,199 image patches from 26 hematoxylin-and-eosin (H&E)-stained lung cancer tissue sections and annotated them into 9 different tissue classes. Using this dataset, we trained a deep neural network ARA-CNN. Next, we applied the trained network to segment 467 lung cancer H&E images from The Cancer Genome Atlas (TCGA) database. We used the segmented images to compute human-interpretable features reflecting the heterogeneous composition of the TME, and successfully utilized them to predict patient survival and cancer gene mutations. RESULTS: We achieved per-class AUC ranging from 0.72 to 0.99 for classifying tissue types in lung cancer with ARA-CNN. Machine learning models trained on the proposed human-interpretable features achieved a c-index of 0.723 in the task of survival prediction and AUC up to 73.5% for PDGFRB in the task of mutation classification. CONCLUSIONS: We presented a framework that accurately predicted survival and gene mutations in lung adenocarcinoma patients based on human-interpretable features extracted from H&E slides. Our approach can provide important insights for designing novel cancer treatments, by linking the spatial structure of the TME in lung adenocarcinoma to gene mutations and patient survival. It can also expand our understanding of the effects that the TME has on tumor evolutionary processes. Our approach can be generalized to different cancer types to inform precision medicine strategies.",Journal Article,
36087795,10.1016/j.chest.2022.08.2227,Diagnostic Accuracy of a Convolutional Neural Network Assessment of Solitary Pulmonary Nodules Compared With PET With CT Imaging and Dynamic Contrast-Enhanced CT Imaging Using Unenhanced and Contrast-Enhanced CT Imaging.,2022 Sep 8,Chest,"Weir-McCall JR, Debruyn E, Harris S, Qureshi NR, Rintoul RC, Gleeson FV, Gilbert FJ","CT scan imaging, PET imaging, diagnostic test accuracy, machine learning, radiograph computed, solitary pulmonary nodule, tomography","BACKGROUND: Solitary pulmonary nodules (SPNs) measuring 8 to 30 mm in diameter require further workup to determine the likelihood of malignancy. RESEARCH QUESTION: What is the diagnostic performance of a lung cancer prediction convolutional neural network (LCP-CNN) in SPNs using unenhanced and contrast-enhanced CT imaging compared with the current clinical workup? STUDY DESIGN AND METHODS: This was a post hoc analysis of the SPUtNIk trial, a prospective multicenter study comparing the diagnostic accuracy of dynamic contrast-enhanced (DCE) CT imaging with PET imaging in SPNs. The LCP-CNN was designed and validated in an external cohort. LCP-CNN-generated risk scores were created from the noncontrast and contrast-enhanced CT scan images from the DCE CT imaging. The gold standard was histologic analysis or 2 years of follow-up. The area under the receiver operating characteristic curves (AUC) were calculated using LCP-CNN score, maximum standardized uptake value, and DCE CT scan maximum enhancement and were compared using the DeLong test. RESULTS: Two hundred seventy participants (mean +/- SD age, 68.3 +/- 8.8 years; 49% women) underwent PET with CT scan imaging and DCE CT imaging with CT scan data available centrally for LCP-CNN analysis. The accuracy of the LCP-CNN on the noncontrast images (AUC, 0.83; 95% CI, 0.79-0.88) was superior to that of DCE CT imaging (AUC, 0.76; 95% CI, 0.69-0.82; P = .03) and equal to that of PET with CT scan imaging (AUC, 0.86; 95% CI, 0.81-0.90; P = .35). The presence of contrast resulted in a small reduction in diagnostic accuracy, with the AUC falling from 0.83 (95% CI, 0.79-0.88) on the noncontrast images to 0.80 to 0.83 after contrast (P < .05 for 240 s after contrast only). INTERPRETATION: An LCP-CNN algorithm provides an AUC equivalent to PET with CT scan imaging in the diagnosis of solitary pulmonary nodules.",Journal Article,
36086462,10.1109/EMBC48229.2022.9870880,FcTC-UNet: Fine-grained Combination of Transformer and CNN for Thoracic Organs Segmentation.,2022 Jul,Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference,"Qiao L, Liu Q, Shi J, Zhao M, Kan H, Wang Z, An H, Xiao C, Wang S","Electric Power Supplies, Humans, *Neural Networks, Computer, Observer Variation, *Organs at Risk, Tomography, X-Ray Computed/methods","Precise segmentation of organs at risk (OARs) in computed tomography (CT) images is an essential step for lung cancer radiotherapy. However, the manual delineation of OARs is time-consuming and subject to inter-observer variation. Although U-like architecture has achieved great success in medical image segmentation recently, it exhibits the limitations in modeling long-range dependencies. As an alternative structure, Transformers have emerged due to the outstanding capability of capturing the global contextual information provided by Self-Attention(SA) mechanism. However, Transformers need more computational cost than CNNs for introducing the SA module. In this paper, we propose a novel module named fine-grained combination of Transformer and CNN(FcTC). FcTC module is composed of dual-path extractor and fusing unit to effectively extract local information and model long-distance dependency. Then we build FcTC-UNet to automatically segment the OARs in thoracic CT images. The experiments results demonstrate that the proposed method achieves better performance over other state-of-the-art methods.",Journal Article,
36059280,10.31661/jbpe.v0i0.2110-1412,An Effective Approach for Automated Lung Node Detection using CT Scans.,2022 Aug,Journal of biomedical physics & engineering,"Moragheb MA, Badie A, Noshad A","Deep Convolutional Neural Networks, Deep Learning, Diagnostic Imaging, Early Diagnosis, Lung Neoplasms, Lung Nodule Detection","Background: Pulmonary or benign nodules are classified as nodules with a diameter of 3 cm or less and defined as non-cancerous nodules. The early diagnosis of malignant lung nodules is important for a more reliable prognosis of lung cancer and less invasive chemotherapy and radiotherapy procedures. Objective: This study aimed to introduce an improved hybrid approach for efficient nodule mask generation and false-positive reduction. Material and Methods: In this experimental study, nodule segmentation preprocessing was conducted to prepare the input computed tomography (CT) scans for the U-Net convolutional neural network (CNN) model, and includes the normalization of CT scans and transfer of pixel values corresponding to the radiodensity of Hounsfield Units (HU). A U-Net CNN was developed based on lung CT scans for nodule identification. Results: The U-net model converged to a dice coefficient of 0.678 with a sensitivity of 75%. Many false positives were considered in every real positive, at 11.1, reduced in the proposed CNN to 2.32 FPs (False Positive) per TP (True Positive). Conclusion: Based on the disadvantages of the largest nodule, the similarity of extracted features of the current study with those of others was imperative. The improved hybrid approach introduced was useful for other image classification tasks as expected.",Journal Article,None
36057739,10.1038/s41379-022-01141-4,Direct identification of ALK and ROS1 fusions in non-small cell lung cancer from hematoxylin and eosin-stained slides using deep learning algorithms.,2022 Sep 3,"Modern pathology : an official journal of the United States and Canadian Academy of Pathology, Inc","Mayer C, Ofek E, Fridrich DE, Molchanov Y, Yacobi R, Gazy I, Hayun I, Zalach J, Paz-Yaacov N, Barshack I",,"Anaplastic lymphoma kinase (ALK) and ROS oncogene 1 (ROS1) gene fusions are well-established key players in non-small cell lung cancer (NSCLC). Although their frequency is relatively low, their detection is important for patient care and guides therapeutic decisions. The accepted methods used for their detection are immunohistochemistry (IHC) and fluorescence in situ hybridization (FISH) assay, as well as DNA and RNA-based sequencing methodologies. These assays are expensive, time-consuming, and require technical expertise and specialized equipment as well as biological specimens that are not always available. Here we present an alternative detection method using a computer vision deep learning approach. An advanced convolutional neural network (CNN) was used to generate classifier models to detect ALK and ROS1-fusions directly from scanned hematoxylin and eosin (H&E) whole slide images prepared from NSCLC tumors of patients. A two-step training approach was applied, with an initial unsupervised training step performed on a pan-cancer sample cohort followed by a semi-supervised fine-tuning step, which supported the development of a classifier with performances equal to those accepted for diagnostic tests. Validation of the ALK/ROS1 classifier on a cohort of 72 lung cancer cases who underwent ALK and ROS1-fusion testing at the pathology department at Sheba Medical Center displayed sensitivities of 100% for both genes (six ALK-positive and two ROS1-positive cases) and specificities of 100% and 98.6% respectively for ALK and ROS1, with only one false-positive result for ROS1-alteration. These results demonstrate the potential advantages that machine learning solutions may have in the molecular pathology domain, by allowing fast, standardized, accurate, and robust biomarker detection overcoming many limitations encountered when using current techniques. The integration of such novel solutions into the routine pathology workflow can support and improve the current clinical pipeline.",Journal Article,
36010850,10.3390/cancers14163856,Deep Learning Algorithms for Diagnosis of Lung Cancer: A Systematic Review and Meta-Analysis.,2022 Aug 9,Cancers,"Forte GC, Altmayer S, Silva RF, Stefani MT, Libermann LL, Cavion CC, Youssef A, Forghani R, King J, Mohamed TL, Andrade RGF, Hochhegger B","CNN, artificial intelligence, deep learning, deep learning networks, lung cancer","We conducted a systematic review and meta-analysis of the diagnostic performance of current deep learning algorithms for the diagnosis of lung cancer. We searched major databases up to June 2022 to include studies that used artificial intelligence to diagnose lung cancer, using the histopathological analysis of true positive cases as a reference. The quality of the included studies was assessed independently by two authors based on the revised Quality Assessment of Diagnostic Accuracy Studies. Six studies were included in the analysis. The pooled sensitivity and specificity were 0.93 (95% CI 0.85-0.98) and 0.68 (95% CI 0.49-0.84), respectively. Despite the significantly high heterogeneity for sensitivity (I(2) = 94%, p &lt; 0.01) and specificity (I(2) = 99%, p &lt; 0.01), most of it was attributed to the threshold effect. The pooled SROC curve with a bivariate approach yielded an area under the curve (AUC) of 0.90 (95% CI 0.86 to 0.92). The DOR for the studies was 26.7 (95% CI 19.7-36.2) and heterogeneity was 3% (p = 0.40). In this systematic review and meta-analysis, we found that when using the summary point from the SROC, the pooled sensitivity and specificity of DL algorithms for the diagnosis of lung cancer were 93% and 68%, respectively.","Journal Article, Review",
35996649,10.1155/2022/7326537,Deep Learning-Based CT Imaging in the Diagnosis of Treatment Effect of Pulmonary Nodules and Radiofrequency Ablation.,2022,Computational intelligence and neuroscience,"Zhou C, Zhao X, Zhao L, Liu J, Chen Z, Fang S","Algorithms, *Deep Learning, Humans, Image Processing, Computer-Assisted/methods, Neural Networks, Computer, *Radiofrequency Ablation, Tomography, X-Ray Computed/methods","To study the effect of computerized tomography (CT) images based on deep learning algorithms on the diagnosis of pulmonary nodules and the effect of radiofrequency ablation (RFA), the U-shaped fully convolutional neural network (FCNN) (U-Net) was enhanced. The convolutional neural network (CNN) algorithm was compared with the U-Net algorithm, and segmentation performances were analyzed. Then, it was applied to the CT image diagnosis of 110 lung cancer patients admitted to hospital. The patients in the observation group (55 cases) were diagnosed based on the improved U-Net algorithm, while those in the control group (55 cases) were diagnosed by traditional methods and then treated with RFA. The Dice coefficient (0.8753) and intersection over union (IOU) (0.8788) obtained by the proposed algorithm were remarkably higher than the Dice coefficient (0.7212) and IOU (0.7231) obtained by the CNN algorithm, and the differences were considerable (P < 0.05). The boundary of the pulmonary nodule can be segmented more accurately by the proposed algorithm, which had the segmentation result closest to the gold standard among the three algorithms. The diagnostic accuracy of the pulmonary nodule in the observation group (95.3%) was superior to that of the control group (90.7%). The long diameter, volume, and maximum area of the pulmonary nodule of the observation group were significantly higher than those of the control group, with substantial differences (P < 0.05). Patients were reexamined after one, three, and six months of treatment, and 71 patients (64.55%) had complete remission, 32 patients (29.10%) had partial remission, 6 patients (5.45%) had stable disease, and 1 patient (0.90%) had disease progression. The remission rate (complete remission + partial remission) was 93.65%. The improved U-NET algorithm had good image segmentation performance and ideal segmentation effect. It can clearly display the shape of pulmonary nodules, locate the lesions, and accurately evaluate the therapeutic effect of RFA, which had clinical application value.",Journal Article,The authors declare no conflicts of interest.
35986072,10.1038/s41598-022-18085-z,Radiomics and deep learning methods for the prediction of 2-year overall survival in LUNG1 dataset.,2022 Aug 19,Scientific reports,"Braghetto A, Marturano F, Paiusco M, Baiesi M, Bettinelli A","*Carcinoma, Non-Small-Cell Lung/diagnostic imaging, *Deep Learning, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, ROC Curve","In this study, we tested and compared radiomics and deep learning-based approaches on the public LUNG1 dataset, for the prediction of 2-year overall survival (OS) in non-small cell lung cancer patients. Radiomic features were extracted from the gross tumor volume using Pyradiomics, while deep features were extracted from bi-dimensional tumor slices by convolutional autoencoder. Both radiomic and deep features were fed to 24 different pipelines formed by the combination of four feature selection/reduction methods and six classifiers. Direct classification through convolutional neural networks (CNNs) was also performed. Each approach was investigated with and without the inclusion of clinical parameters. The maximum area under the receiver operating characteristic on the test set improved from 0.59, obtained for the baseline clinical model, to 0.67 +/- 0.03, 0.63 +/- 0.03 and 0.67 +/- 0.02 for models based on radiomic features, deep features, and their combination, and to 0.64 +/- 0.04 for direct CNN classification. Despite the high number of pipelines and approaches tested, results were comparable and in line with previous works, hence confirming that it is challenging to extract further imaging-based information from the LUNG1 dataset for the prediction of 2-year OS.",Journal Article,
35962181,10.1038/s41598-022-17976-5,Deep learning-based diagnosis from endobronchial ultrasonography images of pulmonary lesions.,2022 Aug 12,Scientific reports,"Hotta T, Kurimoto N, Shiratsuki Y, Amano Y, Hamaguchi M, Tanino A, Tsubata Y, Isobe T","Bronchoscopy/methods, Cohort Studies, *Deep Learning, Endosonography/methods, Humans, Lung/diagnostic imaging/pathology, *Lung Neoplasms/diagnostic imaging/pathology, Retrospective Studies, Ultrasonography/methods","Endobronchial ultrasonography with a guide sheath (EBUS-GS) improves the accuracy of bronchoscopy. The possibility of differentiating benign from malignant lesions based on EBUS findings may be useful in making the correct diagnosis. The convolutional neural network (CNN) model investigated whether benign or malignant (lung cancer) lesions could be predicted based on EBUS findings. This was an observational, single-center cohort study. Using medical records, patients were divided into benign and malignant groups. We acquired EBUS data for 213 participants. A total of 2,421,360 images were extracted from the learning dataset. We trained and externally validated a CNN algorithm to predict benign or malignant lung lesions. Test was performed using 26,674 images. The dataset was interpreted by four bronchoscopists. The accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) of the CNN model for distinguishing benign and malignant lesions were 83.4%, 95.3%, 53.6%, 83.8%, and 82.0%, respectively. For the four bronchoscopists, the accuracy rate was 68.4%, sensitivity was 80%, specificity was 39.6%, PPV was 76.8%, and NPV was 44.2%. The developed EBUS-computer-aided diagnosis system is expected to read EBUS findings that are difficult for clinicians to judge with precision and help differentiate between benign lesions and lung cancers.","Journal Article, Observational Study",
35940164,10.1016/j.compbiomed.2022.105913,Fx-Net and PureNet: Convolutional Neural Network architecture for discrimination of Chronic Obstructive Pulmonary Disease from smokers and healthy subjects through electronic nose signals.,2022 Sep,Computers in biology and medicine,"Avian C, Mahali MI, Putro NAS, Prakosa SW, Leu JS","Breath Tests, *Electronic Nose, Exhalation, Healthy Volunteers, Humans, Neural Networks, Computer, *Pulmonary Disease, Chronic Obstructive, Chronic obstructive pulmonary disease (COPD), Convolutional neural network, Electronic nose, Kernel principal component analysis, Lung cancer","As one of the most reliable and significant indicators, Chronic Obstructive Pulmonary Disease (COPD) becomes a robust predictor of lung cancer early detection, the world's leading cause of cancer death. One of the methods is to analyze the Volatile Organic Compounds (VOCs) in exhaled breath using electronic noses (E-noses), which have become emerging tools for analyzing breath because of their potential and promising technology for diagnosing. However, the signal processing of the E-Nose sensor becomes vital in exposing information about the subject condition, which most researchers strive to accomplish. We proposed a Convolutional Neural Network (CNN) architecture to classify COPD in smokers and non-smokers, healthy subjects, and smokers from E-Nose signals to contribute to this field. Two models were constructed following E-Nose signal processing state-of-the-arts. One was by combined feature extraction and classifier, and the second was by CNN, which directly processed the raw signal. In addition, various feature extraction and classifier (Machine Learning and CNN) used in prior research were investigated. Using 3K and 5K Fold cross-validation results demonstrated that our proposed models outperformed in Kernel Principal Component Analysis (KPCA) with Fx-ConvNet and Pure-ConvNet. They all reached maximum F1-Score with zero standard deviation values indicating a consistent result. Further experiments also showed that KPCA contributed to the increasing performance of some classifiers with average F1-Score 0.933 and 0.068 as standard deviation values.",Journal Article,
35936797,10.1016/j.phro.2022.07.004,Dose-volume-based evaluation of convolutional neural network-based auto-segmentation of thoracic organs at risk.,2022 Jul,Physics and imaging in radiation oncology,"Johnston N, De Rycke J, Lievens Y, van Eijkeren M, Aelterman J, Vandersmissen E, Ponte S, Vanderstraeten B","Dice, Dose, Lung cancer, Radiotherapy, Treatment planning, Volume","Background and purpose: The geometrical accuracy of auto-segmentation using convolutional neural networks (CNNs) has been demonstrated. This study aimed to investigate the dose-volume impact of differences between automatic and manual OARs for locally advanced (LA) and peripherally located early-stage (ES) non-small cell lung cancer (NSCLC). Material and methods: A single CNN was created for automatic delineation of the heart, lungs, main left and right bronchus, esophagus, spinal cord and trachea using 55/10/40 patients for training/validation/testing. Dice score coefficient (DSC) and 95th percentile Hausdorff distance (HD95) were used for geometrical analysis. A new treatment plan based on the auto-segmented OARs was created for each test patient using 3D for ES-NSCLC (SBRT, 3-8 fractions) and IMRT for LA-NSCLC (24-35 fractions). The correlation between geometrical metrics and dose-volume differences was investigated. Results: The average (+/-1 SD) DSC and HD95 were 0.82 +/- 0.07 and 16.2 +/- 22.4 mm, while the average dose-volume differences were 0.5 +/- 1.5 Gy (ES) and 1.5 +/- 2.8 Gy (LA). The geometrical metrics did not correlate with the observed dose-volume differences (average Pearson for DSC: -0.27 +/- 0.18 (ES) and -0.09 +/- 0.12 (LA); HD95: 0.1 +/- 0.3 mm (ES) and 0.2 +/- 0.2 mm (LA)). Conclusions: After post-processing, manual adjustments of automatic contours are only needed for clinically relevant OARs situated close to the tumor or within an entry or exit beam e.g., the heart and the esophagus for LA-NSCLC and the bronchi for ES-NSCLC. The lungs do not need to be checked further in detail.",Journal Article,The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
35936745,10.3389/fonc.2022.949546,Deep-LC: A Novel Deep Learning Method of Identifying Non-Small Cell Lung Cancer-Related Genes.,2022,Frontiers in oncology,"Li M, Meng GX, Liu XW, Ma T, Sun G, He H","Deep-LC, convolutional neural network (CNN) accelerator, genome-wide association analysis, graph convolutional networks, non-small cell lung cancer","According to statistics, lung cancer kills 1.8 million people each year and is the main cause of cancer mortality worldwide. Non-small cell lung cancer (NSCLC) accounts for over 85% of all lung cancers. Lung cancer has a strong genetic predisposition, demonstrating that the susceptibility and survival of lung cancer are related to specific genes. Genome-wide association studies (GWASs) and next-generation sequencing have been used to discover genes related to NSCLC. However, many studies ignored the intricate interaction information between gene pairs. In the paper, we proposed a novel deep learning method named Deep-LC for predicting NSCLC-related genes. First, we built a gene interaction network and used graph convolutional networks (GCNs) to extract features of genes and interactions between gene pairs. Then a simple convolutional neural network (CNN) module is used as the decoder to decide whether the gene is related to the disease. Deep-LC is an end-to-end method, and from the evaluation results, we can conclude that Deep-LC performs well in mining potential NSCLC-related genes and performs better than existing state-of-the-art methods.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35936706,10.3389/fonc.2022.868186,Imaging-Based Deep Graph Neural Networks for Survival Analysis in Early Stage Lung Cancer Using CT: A Multicenter Study.,2022,Frontiers in oncology,"Lian J, Long Y, Huang F, Ng KS, Lee FMY, Lam DCL, Fang BXL, Dou Q, Vardhanabhuti V","cox proportional-hazards, graph convolutional networks, lung cancer, lung graph model, survival prediction","Background: Lung cancer is the leading cause of cancer-related mortality, and accurate prediction of patient survival can aid treatment planning and potentially improve outcomes. In this study, we proposed an automated system capable of lung segmentation and survival prediction using graph convolution neural network (GCN) with CT data in non-small cell lung cancer (NSCLC) patients. Methods: In this retrospective study, we segmented 10 parts of the lung CT images and built individual lung graphs as inputs to train a GCN model to predict 5-year overall survival. A Cox proportional-hazard model, a set of machine learning (ML) models, a convolutional neural network based on tumor (Tumor-CNN), and the current TNM staging system were used as comparison. Findings: A total of 1,705 patients (main cohort) and 125 patients (external validation cohort) with lung cancer (stages I and II) were included. The GCN model was significantly predictive of 5-year overall survival with an AUC of 0.732 (p < 0.0001). The model stratified patients into low- and high-risk groups, which were associated with overall survival (HR = 5.41; 95% CI:, 2.32-10.14; p < 0.0001). On external validation dataset, our GCN model achieved the AUC score of 0.678 (95% CI: 0.564-0.792; p < 0.0001). Interpretation: The proposed GCN model outperformed all ML, Tumor-CNN, and TNM staging models. This study demonstrated the value of utilizing medical imaging graph structure data, resulting in a robust and effective model for the prediction of survival in early-stage lung cancer.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35909590,10.1155/2022/2492124,Study on the Relationship between Lung Cancer Stromal Cells and Air Cavity Diffusion Based on an Image Acquisition System.,2022,Contrast media & molecular imaging,"Bai S, Wang Z, Sun Z, Liu Z","*Adenocarcinoma of Lung, Humans, *Lung Neoplasms/diagnostic imaging/pathology, Prognosis, Quality of Life, Stromal Cells/pathology","Objective: The study aimed to investigate the role of tumor stromal cells in the pathogenesis of STAS, the relationship between air diffusion (STAS) and tumor stromal cells (TSCs) was studied, and the prognostic significance of TSC and STAS in patients with lung adenocarcinoma was evaluated. Methods: A total of 150 patients with lung cancer diagnosed in the Affiliated Hospital of Jiangsu Province were selected. From the perspective of pathology, medical information technology was used to assist the diagnosis. The data of multiple magnetic resonance images were analyzed by three-dimensional space convolution (CNN), fuzzy neural network (FNN), transfinite learning machine (ELM), and binarization. Result: After data fusion, the specificity and sensitivity of multiple magnetic resonance (MRI) data are significantly higher than those of single MRI data, and the more fusion times, the better the sensitivity and specificity. With the increase in the number of information and data fusion, the proportion of the significant effect and the comprehensive effective rate of patients are on the rise. Multiple MRI data fusion examination and analysis under medical information technology can improve the cure rate of patients, and the 1-year survival rate and the 3-year survival rate of patients have also gradually improved. Conclusion: The MRI data fusion diagnosis method under the application of information technology can improve the sensitivity and specificity of the diagnosis results and comprehensively improve the clinical cure rate and the survival rate at different times of prognosis. In the context of the current big data information age, this multifeature fusion analysis technology is playing a more and more important role in medical treatment. The application of this method and technology not only improves the quality of life of patients but also processes multiple types of data at one time only by using the proposed medical assistant diagnosis model, which can save the diagnosis time to a certain extent. It has effectively realized the medical management and medical service quality and has important promotion significance.",Journal Article,The authors declare no conflicts of interest.
35901600,10.1016/j.ejrad.2022.110443,One-step algorithm for fast-track localization and multi-category classification of histological subtypes in lung cancer.,2022 Sep,European journal of radiology,"Qi J, Deng Z, Sun G, Qian S, Liu L, Xu B","*Adenocarcinoma of Lung, Algorithms, *Carcinoma, Non-Small-Cell Lung/pathology, Humans, *Lung Neoplasms/diagnostic imaging/pathology, Retrospective Studies, Tomography, X-Ray Computed/methods, Deep learning, Histological subtypes, Lung cancer, Prediction, Small cell lung cancer","BACKGROUNDS: Accumulated evidence has proven that computer-derived features from computed tomography (CT) through radiomics and deep learning technologies can identify extensive characteristics of pulmonary malignancies, such as nodules detection and malignant lesion discrimination. However, there are few studies on whether CT images can reflect histological subtypes of lung cancer through computer-derived features. METHODS: Contrast-enhanced CT images prior treatment from 417 patients diagnosed with small cell lung cancer (SCLC), lung adenocarcinoma (ADC), or lung squamous cell carcinoma (SCC) were collected. ITK-SNAP software was used by trained radiologists for the manual delineation of tumor volume. Patients of each category (SCLC, ADC, SCC) were then randomly split into training datasets and test datasets in an approximately ratio of 8:2. After image pre-processing and augmentation, 25,042 CT images from the training datasets were used to train our self-developed deep learning model for fast-tracking tumor lesions and classifying corresponding histological subtypes simultaneously. The performance of the network was evaluated by accuracy, F1-score and weighted F1-average using 1,921 testing images based on parameters generated during training. RESULTS: The prediction accuracy of SCLC, ADC, and SCC were 0.83, 0.75 and 0.67, respectively. The weighted F1-average was 0.75. ADC obtained the best F1-score of 0.78, which was outperformed SCLC (0.77) and SCC (0.66). The corresponding AUC values of SCLC, ADC, and SCC were 0.87, 0.84, and 0.76, respectively. Only 0.24 s were required to simultaneously achieve functions of tumor localization and histological classification on a thoracic CT image slice. The heat map visualization illustrated the extracted tumor features to classify subtypes of lung cancer by the proposed model. CONCLUSIONS: The newly developed multi-task algorithm provides a CNN-based DL approach in lung cancer for automatically fast-tracking tumor lesions and classifying corresponding histological subtypes in one-step.",Journal Article,
35885458,10.3390/diagnostics12071552,Pulmonary Lesion Classification Framework Using the Weighted Ensemble Classification with Random Forest and CNN Models for EBUS Images.,2022 Jun 26,"Diagnostics (Basel, Switzerland)","Khomkham B, Lipikorn R","convolutional neural network (CNN), endobronchial ultrasonography images (EBUS), gray-level co-occurrence matrix (GLCM), pulmonary lesion, radiomics features, random forest, weighted ensemble","Lung cancer is a deadly disease with a high mortality rate. Endobronchial ultrasonography (EBUS) is one of the methods for detecting pulmonary lesions. Computer-aided diagnosis of pulmonary lesions from images can help radiologists to classify lesions; however, most of the existing methods need a large volume of data to give good results. Thus, this paper proposes a novel pulmonary lesion classification framework for EBUS images that works well with small datasets. The proposed framework integrates the statistical results from three classification models using the weighted ensemble classification. The three classification models include the radiomics feature and patient data-based model, the single-image-based model, and the multi-patch-based model. The radiomics features are combined with the patient data to be used as input data for the random forest, whereas the EBUS images are used as input data to the other two CNN models. The performance of the proposed framework was evaluated on a set of 200 EBUS images consisting of 124 malignant lesions and 76 benign lesions. The experimental results show that the accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and area under the curve are 95.00%, 100%, 86.67%, 92.59%, 100%, and 93.33%, respectively. This framework can significantly improve the pulmonary lesion classification.",Journal Article,
35845926,10.1155/2022/7966553,Histopathological Tissue Segmentation of Lung Cancer with Bilinear CNN and Soft Attention.,2022,BioMed research international,"Xu R, Wang Z, Liu Z, Han C, Yan L, Lin H, Xu Z, Feng Z, Liang C, Chen X, Pan X, Liu Z","Algorithms, Attention, Humans, *Image Processing, Computer-Assisted/methods, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer","Automatic tissue segmentation in whole-slide images (WSIs) is a critical task in hematoxylin and eosin- (H&E-) stained histopathological images for accurate diagnosis and risk stratification of lung cancer. Patch classification and stitching the classification results can fast conduct tissue segmentation of WSIs. However, due to the tumour heterogeneity, large intraclass variability and small interclass variability make the classification task challenging. In this paper, we propose a novel bilinear convolutional neural network- (Bilinear-CNN-) based model with a bilinear convolutional module and a soft attention module to tackle this problem. This method investigates the intraclass semantic correspondence and focuses on the more distinguishable features that make feature output variations relatively large between interclass. The performance of the Bilinear-CNN-based model is compared with other state-of-the-art methods on the histopathological classification dataset, which consists of 107.7 k patches of lung cancer. We further evaluate our proposed algorithm on an additional dataset from colorectal cancer. Extensive experiments show that the performance of our proposed method is superior to that of previous state-of-the-art ones and the interpretability of our proposed method is demonstrated by Grad-CAM.",Journal Article,The authors declare no competing interest.
35832207,10.3389/frai.2022.884749,A Survey on Human Cancer Categorization Based on Deep Learning.,2022,Frontiers in artificial intelligence,"Ibrahim A, Mohamed HK, Maher A, Zhang B","cancer types, convolutional neural network, deep learning, human cancer, medical imaging","In recent years, we have witnessed the fast growth of deep learning, which involves deep neural networks, and the development of the computing capability of computer devices following the advance of graphics processing units (GPUs). Deep learning can prototypically and successfully categorize histopathological images, which involves imaging classification. Various research teams apply deep learning to medical diagnoses, especially cancer diseases. Convolutional neural networks (CNNs) detect the conventional visual features of disease diagnoses, e.g., lung, skin, brain, prostate, and breast cancer. A CNN has a procedure for perfectly investigating medicinal science images. This study assesses the main deep learning concepts relevant to medicinal image investigation and surveys several charities in the field. In addition, it covers the main categories of imaging procedures in medication. The survey comprises the usage of deep learning for object detection, classification, and human cancer categorization. In addition, the most popular cancer types have also been introduced. This article discusses the Vision-Based Deep Learning System among the dissimilar sorts of data mining techniques and networks. It then introduces the most extensively used DL network category, which is convolutional neural networks (CNNs) and investigates how CNN architectures have evolved. Starting with Alex Net and progressing with the Google and VGG networks, finally, a discussion of the revealed challenges and trends for upcoming research is held.","Journal Article, Review",The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35811128,10.6009/jjrt.2022-1224,[Prognosis Prediction of Lung Cancer Patients Using CT Images: Feature Extraction by Convolutional Neural Network and Prediction by Machine Learning].,2022 Aug 20,Nihon Hoshasen Gijutsu Gakkai zasshi,"Oshita Y, Takeuchi N, Teramoto A, Kondo M, Imaizumi K, Saito K, Fujita H","*Algorithms, Bayes Theorem, Humans, *Lung Neoplasms/diagnostic imaging, Machine Learning, Neural Networks, Computer, Prognosis, Tomography, X-Ray Computed/methods, convolutional neural network, lung cancer, machine learning, predict prognosis, survival curve","PURPOSE: Lung cancer accounts for the largest number of deaths among malignant tumors. Recently, more and more patients are concerned about their own life expectancy. CT examination is essential for the diagnosis of lung cancer. However, it is difficult to accurately predict the prognosis using CT images. In this study, we developed a method to predict the prognosis of lung cancer patients from CT images using a convolutional neural network (CNN) and a machine learning method. METHODS: In this study, the CT images of 173 lung cancer patients were collected. First, we selected the slice with the largest tumor size in each case and extracted features using a CNN. Next, we performed feature selection using information gain and predicted alive or death by classifiers. An artificial neural network or Naive Bayes was used as a classifier and alive and death were predicted at one-year intervals from one year to five years later. RESULTS: We evaluated the prediction accuracy via the three-fold cross-validation method and found that the prediction accuracies were around 80% for all periods from 1 to 5 years. In the evaluation of the survival curve, the shape of the curve was close to the actual curve. CONCLUSION: These results indicate that feature extraction by a CNN and classification by the machine learning method may be effective in predicting the prognosis of lung cancer patients using CT images.",Journal Article,
35810561,10.1016/j.ebiom.2022.104127,Prediction of lung malignancy progression and survival with machine learning based on pre-treatment FDG-PET/CT.,2022 Aug,EBioMedicine,"Huang B, Sollee J, Luo YH, Reddy A, Zhong Z, Wu J, Mammarappallil J, Healey T, Cheng G, Azzoli C, Korogodsky D, Zhang P, Feng X, Li J, Yang L, Jiao Z, Bai HX","Fluorodeoxyglucose F18, Humans, *Lung Neoplasms/diagnostic imaging/therapy, Machine Learning, *Positron Emission Tomography Computed Tomography/methods, Positron-Emission Tomography, Artificial intelligence, Deep learning, FDG-PET/CT, Lung cancer, Machine learning, Prognosis","BACKGROUND: Pre-treatment FDG-PET/CT scans were analyzed with machine learning to predict progression of lung malignancies and overall survival (OS). METHODS: A retrospective review across three institutions identified patients with a pre-procedure FDG-PET/CT and an associated malignancy diagnosis. Lesions were manually and automatically segmented, and convolutional neural networks (CNNs) were trained using FDG-PET/CT inputs to predict malignancy progression. Performance was evaluated using area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity. Image features were extracted from CNNs and by radiomics feature extraction, and random survival forests (RSF) were constructed to predict OS. Concordance index (C-index) and integrated brier score (IBS) were used to evaluate OS prediction. FINDINGS: 1168 nodules (n=965 patients) were identified. 792 nodules had progression and 376 were progression-free. The most common malignancies were adenocarcinoma (n=740) and squamous cell carcinoma (n=179). For progression risk, the PET+CT ensemble model with manual segmentation (accuracy=0.790, AUC=0.876) performed similarly to the CT only (accuracy=0.723, AUC=0.888) and better compared to the PET only (accuracy=0.664, AUC=0.669) models. For OS prediction with deep learning features, the PET+CT+clinical RSF ensemble model (C-index=0.737) performed similarly to the CT only (C-index=0.730) and better than the PET only (C-index=0.595), and clinical only (C-index=0.595) models. RSF models constructed with radiomics features had comparable performance to those with CNN features. INTERPRETATION: CNNs trained using pre-treatment FDG-PET/CT and extracted performed well in predicting lung malignancy progression and OS. OS prediction performance with CNN features was comparable to a radiomics approach. The prognostic models could inform treatment options and improve patient care. FUNDING: NIH NHLBI training grant (5T35HL094308-12, John Sollee).",Journal Article,"Declaration of interests Dr. Feng reports personal fees from Carina Medical LLC, outside the submitted work. The remaining authors declare that they have no conflicts of interest and nothing to disclose."
35810236,10.1038/s41374-022-00801-y,A convolutional neural network model for survival prediction based on prognosis-related cascaded Wx feature selection.,2022 Oct,Laboratory investigation; a journal of technical methods and pathology,"Yin Q, Chen W, Zhang C, Wei Z","*Adenocarcinoma of Lung, *Carcinoma, Renal Cell, Humans, *Kidney Neoplasms, Kinesins, *Lung Neoplasms/pathology, *Melanoma/genetics, Nerve Tissue Proteins, Neural Networks, Computer, Prognosis, *Skin Neoplasms","Great advances in deep learning have provided effective solutions for prediction tasks in the biomedical field. However, accurate prognosis prediction using cancer genomics data remains challenging due to the severe overfitting problem caused by curse of dimensionality inherent to high-throughput sequencing data. Moreover, there are unique challenges to perform survival analysis, arising from the difficulty in utilizing censored samples whose events of interest are not observed. Convolutional neural network (CNN) models provide us the opportunity to extract meaningful hierarchical features to characterize cancer subtype and prognosis outcomes. On the other hand, feature selection can mitigate overfitting and reduce subsequent model training computation burden by screening out significant genes from redundant genes. To accomplish model simplification, we developed a concise and efficient survival analysis model, named CNN-Cox model, which combines a special CNN framework with prognosis-related feature selection cascaded Wx, with the advantage of less computation demand utilizing light training parameters. Experiment results show that CNN-Cox model achieved consistent higher C-index values and better survival prediction performance across seven cancer type datasets in The Cancer Genome Atlas cohort, including bladder carcinoma, head and neck squamous cell carcinoma, kidney renal cell carcinoma, brain low-grade glioma, lung adenocarcinoma (LUAD), lung squamous cell carcinoma, and skin cutaneous melanoma, compared with the existing state-of-the-art survival analysis methods. As an illustration of model interpretation, we examined potential prognostic gene signatures of LUAD dataset using the proposed CNN-Cox model. We conducted protein-protein interaction network analysis to identify potential prognostic genes and further analyzed the biological function of 13 hub genes, including ANLN, RACGAP1, KIF4A, KIF20A, KIF14, ASPM, CDK1, SPC25, NCAPG, MKI67, HJURP, EXO1, HMMR, whose high expression is significantly associated with poor survival of LUAD patients. These findings confirmed that CNN-Cox model is effective in extracting not only prognosis factors but also biologically meaningful gene features. The codes are available at the GitHub website: https://github.com/wangwangCCChen/CNN-Cox .",Journal Article,
35795700,10.3389/fpubh.2022.894920,VCNet: Hybrid Deep Learning Model for Detection and Classification of Lung Carcinoma Using Chest Radiographs.,2022,Frontiers in public health,"Tandon R, Agrawal S, Chang A, Band SS","*Carcinoma, *Deep Learning, Humans, Lung, *Lung Neoplasms/diagnostic imaging, Tomography, X-Ray Computed, *CT, *MobileNet, *VCNet, *VGG-16, *Xception, *capsule network, *convolutional neural networks","Detection of malignant lung nodules from Computed Tomography (CT) images is a significant task for radiologists. But, it is time-consuming in nature. Despite numerous breakthroughs in studies on the application of deep learning models for the identification of lung cancer, researchers and doctors still face challenges when trying to deploy the model in clinical settings to achieve improved accuracy and sensitivity on huge datasets. In most situations, deep convolutional neural networks are used for detecting the region of the main nodule of the lung exclusive of considering the neighboring tissues of the nodule. Although the accuracy achieved through CNN is good enough but this models performance degrades when there are variations in image characteristics like: rotation, tiling, and other abnormal image orientations. CNN does not store relative spatial relationships among features in scanned images. As CT scans have high spatial resolution and are sensitive to misalignments during the scanning process, there is a requirement of a technique which helps in considering spatial information of image features also. In this paper, a hybrid model named VCNet is proposed by combining the features of VGG-16 and capsule network (CapsNet). VGG-16 model is used for object recognition and classification. CapsNet is used to address the shortcomings of convolutional neural networks for image rotation, tiling, and other abnormal image orientations. The performance of VCNeT is verified on the Lung Image Database Consortium (LIDC) image collection dataset. It achieves higher testing accuracy of 99.49% which is significantly better than MobileNet, Xception, and VGG-16 that has achieved an accuracy of 98, 97.97, and 96.95%, respectively. Therefore, the proposed hybrid VCNet framework can be used for the clinical purpose for nodule detection in lung carcinoma detection.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35783280,10.3389/fgene.2022.896884,Path-ATT-CNN: A Novel Deep Neural Network Method for Key Pathway Identification of Lung Cancer.,2022,Frontiers in genetics,"Yuan L, Lai J, Zhao J, Sun T, Hu C, Ye L, Yu G, Yang Z","ATT-CNN, Path-ATT-CNN, neural network, pathways, primary lung tumor symptom","Attention convolutional neural networks (ATT-CNNs) have got a huge gain in picture operating and nature language processing. Shortage of interpretability cannot remain the adoption of deep neural networks. It is very conspicuous that is shown in the prediction model of disease aftermath. Biological data are commonly revealed in a nominal grid data structured pattern. ATT-CNN cannot be applied directly. In order to figure out these issues, a novel method which is called the Path-ATT-CNN is proposed by us, making an explicable ATT-CNN model based on united omics data by making use of a recently characterized pathway image. Path-ATT-CNN shows brilliant predictive demonstration difference in primary lung tumor symptom (PLTS) and non-primary lung tumor symptom (non-PLTS) when applied to lung adenocarcinomas (LADCs). The imaginational tool adoption which is linked with statistical analysis enables the status of essential pathways which finally exist in LADCs. In conclusion, Path-ATT-CNN shows that it can be effectively put into use elucidating omics data in an interpretable mode. When people start to figure out key biological correlates of disease, this mode makes promising power in predicting illness.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35777084,10.1016/j.compbiomed.2022.105781,CSE-GAN: A 3D conditional generative adversarial network with concurrent squeeze-and-excitation blocks for lung nodule segmentation.,2022 Aug,Computers in biology and medicine,"Tyagi S, Talbar SN","Humans, *Image Processing, Computer-Assisted/methods, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, CT scan, Computer-aided diagnosis, Deep learning, Generative adversarial network, Lung cancer, Squeeze & excitation","Lung nodule segmentation plays a crucial role in early-stage lung cancer diagnosis, and early detection of lung cancer can improve the survival rate of the patients. The approaches based on convolutional neural networks (CNN) have outperformed the traditional image processing approaches in various computer vision applications, including medical image analysis. Although multiple techniques based on convolutional neural networks have provided state-of-the-art performances for medical image segmentation tasks, these techniques still have some challenges. Two main challenges are data scarcity and class imbalance, which can cause overfitting resulting in poor performance. In this study, we propose an approach based on a 3D conditional generative adversarial network for lung nodule segmentation, which generates better segmentation results by learning the data distribution, leading to better accuracy. The generator in the proposed network is based on the famous U-Net architecture with a concurrent squeeze & excitation module. The discriminator is a simple classification network with a spatial squeeze & channel excitation module, differentiating between ground truth and fake segmentation. To deal with the overfitting, we implement patch-based training. We have evaluated the proposed approach on two datasets, LUNA16 data and a local dataset. We achieved significantly improved performances with dice coefficients of 80.74% and 76.36% and sensitivities of 85.46% and 82.56% for the LUNA test set and local dataset, respectively.",Journal Article,
35773100,10.1016/j.diii.2022.06.002,3D convolutional neural network model from contrast-enhanced CT to predict spread through air spaces in non-small cell lung cancer.,2022 Jun 27,Diagnostic and interventional imaging,"Tao J, Liang C, Yin K, Fang J, Chen B, Wang Z, Lan X, Zhang J","Computer vision, Conventional radiomics, Deep learning, Non-small cell lung cancer, Spread through air spaces","PURPOSE: The purpose of this study was to compare the efficacy of five non-invasive models, including three-dimensional (3D) convolutional neural network (CNN) model, to predict the spread through air spaces (STAS) status of non-small cell lung cancer (NSCLC), and to obtain the best prediction model to provide a basis for clinical surgery planning. MATERIALS AND METHODS: A total of 203 patients (112 men, 91 women; mean age, 60 years; age range 22-80 years) with NSCLC were retrospectively included. Of these, 153 were used for training cohort and 50 for validation cohort. According to the image biomarker standardization initiative reference manual, the image processing and feature extraction were standardized using PyRadiomics. The logistic regression classifier was used to build the model. Five models (clinicopathological/CT model, conventional radiomics model, computer vision (CV) model, 3D CNN model and combined model) were constructed to predict STAS by NSCLC. Area under the receiver operating characteristic curves (AUC) were used to validate the capability of the five models to predict STAS. RESULTS: For predicting STAS, the 3D CNN model was superior to the clinicopathological/CT model, conventional radiomics model, CV model and combined model and achieved satisfactory discrimination performance, with an AUC of 0.93 (95% CI: 0.70-0.82) in the training cohort and 0.80 (95% CI: 0.65-0.86) in the validation cohort. Decision curve analysis indicated that, when the probability of the threshold was over 10%, the 3D CNN model was beneficial for predicting STAS status compared to either treating all or treating none of the patients within certain ranges of risk threshold CONCLUSION: The 3D CNN model can be used for the preoperative prediction of STAS in patients with NSCLC, and was superior to the other four models in predicting patients' risk of developing STAS.",Journal Article,Declaration of Competing Interest The authors declare that they have no competing of interest.
35770126,10.1155/2022/2702328,A Novel Approach to Predict Brain Cancerous Tumor Using Transfer Learning.,2022,Computational and mathematical methods in medicine,"Khan MM, Omee AS, Tazin T, Almalki FA, Aljohani M, Algethami H","Brain/diagnostic imaging, *Brain Neoplasms/diagnostic imaging, Humans, Machine Learning, Male, *Neural Networks, Computer, Reproducibility of Results","As the most prevalent and deadly malignancy, brain tumors have a dismal survival rate when they are at their most hazardous. Using mostly traditional medical image processing methods, segmenting and classifying brain malignant tumors is a challenging and time-consuming task. Indeed, medical research reveals that categorization performed manually with the help of a person might result in inaccurate prediction and diagnosis. This is mostly due to the fact that malignancies and normal tissues are so dissimilar and comparable. The brain, lung, liver, breast, and prostate are all studied using imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and ultrasound. This research makes significant use of CT and X-ray imaging to identify brain malignant tumors. The purpose of this article is to examine the use of convolutional neural networks (CNNs) in image-based diagnosis of brain cancers. It expedites and improves the treatment's reliability. As a result of the abundance of research on this issue, the provided model focuses on increasing accuracy via the use of a transfer learning method. This experiment was conducted using Python and Google Colab. Deep features were extracted using VGG19 and MobileNetV2, two pretrained deep CNN models. The classification accuracy is used to evaluate this work's performance. This research achieved a 97 percent accuracy rate by MobileNetV2 and a 91 percent accuracy rate by the VGG19 algorithm. This allows us to find malignancies before they have a negative effect on our bodies, like paralysis.",Journal Article,The authors declare that they have no conflicts of interest to report regarding the present study.
35747775,10.3389/fpubh.2022.769692,A Neural Network and Optimization Based Lung Cancer Detection System in CT Images.,2022,Frontiers in public health,"Venkatesh C, Ramana K, Lakkisetty SY, Band SS, Agarwal S, Mosavi A","Algorithms, Female, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, Reproducibility of Results, *Tomography, X-Ray Computed/methods, *artificial intelligence, *cancer, *cancer detection, *deep learning, *lung cancer, *machine learning","One of the most common causes of death from cancer for both women and men is lung cancer. Lung nodules are critical for the screening of cancer and early recognition permits treatment and enhances the rate of rehabilitation in patients. Although a lot of work is being done in this area, an increase in accuracy is still required to swell patient persistence rate. However, traditional systems do not segment cancer cells of different forms accurately and no system attained greater reliability. An effective screening procedure is proposed in this work to not only identify lung cancer lesions rapidly but to increase accuracy. In this procedure, Otsu thresholding segmentation is utilized to accomplish perfect isolation of the selected area, and the cuckoo search algorithm is utilized to define the best characteristics for partitioning cancer nodules. By using a local binary pattern, the relevant features of the lesion are retrieved. The CNN classifier is designed to spot whether a lung lesion is malicious or non-malicious based on the retrieved features. The proposed framework achieves an accuracy of 96.97% percent. The recommended study reveals that accuracy is improved, and the results are compiled using Particle swarm optimization and genetic algorithms.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35746208,10.3390/s22124426,Performance Analysis of State-of-the-Art CNN Architectures for LUNA16.,2022 Jun 11,"Sensors (Basel, Switzerland)","Naseer I, Akram S, Masood T, Jaffar A, Khan MA, Mosavi A","Humans, *Lung Neoplasms/diagnosis, Machine Learning, *Neural Networks, Computer, Tomography, X-Ray Computed, AlexNet, LUNA16, LeNet, artificial intelligence, big data, cancer research, deep learning, lung cancer, machine learning, medical image analysis","The convolutional neural network (CNN) has become a powerful tool in machine learning (ML) that is used to solve complex problems such as image recognition, natural language processing, and video analysis. Notably, the idea of exploring convolutional neural network architecture has gained substantial attention as well as popularity. This study focuses on the intrinsic various CNN architectures: LeNet, AlexNet, VGG16, ResNet-50, and Inception-V1, which have been scrutinized and compared with each other for the detection of lung cancer using publicly available LUNA16 datasets. Furthermore, multiple performance optimizers: root mean square propagation (RMSProp), adaptive moment estimation (Adam), and stochastic gradient descent (SGD), were applied for this comparative study. The performances of the three CNN architectures were measured for accuracy, specificity, sensitivity, positive predictive value, false omission rate, negative predictive value, and F1 score. The experimental results showed that the CNN AlexNet architecture with the SGD optimizer achieved the highest validation accuracy for CT lung cancer with an accuracy of 97.42%, misclassification rate of 2.58%, 97.58% sensitivity, 97.25% specificity, 97.58% positive predictive value, 97.25% negative predictive value, false omission rate of 2.75%, and F1 score of 97.58%. AlexNet with the SGD optimizer was the best and outperformed compared to the other state-of-the-art CNN architectures.",Journal Article,
35742109,10.3390/healthcare10061058,A Transfer Learning Approach with a Convolutional Neural Network for the Classification of Lung Carcinoma.,2022 Jun 8,"Healthcare (Basel, Switzerland)","Humayun M, Sujatha R, Almuayqil SN, Jhanjhi NZ","TL, VGG 16, VGG 19, Xception, lung carcinoma","Lung cancer is among the most hazardous types of cancer in humans. The correct diagnosis of pathogenic lung disease is critical for medication. Traditionally, determining the pathological form of lung cancer involves an expensive and time-consuming process investigation. Lung cancer is a leading cause of mortality worldwide, with lung tissue nodules being the most prevalent way for doctors to identify it. The proposed model is based on robust deep-learning-based lung cancer detection and recognition. This study uses a deep neural network as an extraction of features approach in a computer-aided diagnosing (CAD) system to assist in detecting lung illnesses at high definition. The proposed model is categorized into three phases: first, data augmentation is performed, classification is then performed using the pretrained CNN model, and lastly, localization is completed. The amount of obtained data in medical image assessment is occasionally inadequate to train the learning network. We train the classifier using a technique known as transfer learning (TL) to solve the issue introduced into the process. The proposed methodology offers a non-invasive diagnostic tool for use in the clinical assessment that is effective. The proposed model has a lower number of parameters that are much smaller compared to the state-of-the-art models. We also examined the desired dataset's robustness depending on its size. The standard performance metrics are used to assess the effectiveness of the proposed architecture. In this dataset, all TL techniques perform well, and VGG 16, VGG 19, and Xception for 20 epoch structure are compared. Preprocessing functions as a wonderful bridge to build a dependable model and eventually helps to forecast future scenarios by including the interface at a faster phase for any model. At the 20th epoch, the accuracy of VGG 16, VGG 19, and Xception is 98.83 percent, 98.05 percent, and 97.4 percent.",Journal Article,
35705792,10.1038/s41698-022-00275-7,Usability of deep learning and H&E images predict disease outcome-emerging tool to optimize clinical trials.,2022 Jun 15,NPJ precision oncology,"Qaiser T, Lee CY, Vandenberghe M, Yeh J, Gavrielides MA, Hipp J, Scott M, Reischl J",,"Understanding factors that impact prognosis for cancer patients have high clinical relevance for treatment decisions and monitoring of the disease outcome. Advances in artificial intelligence (AI) and digital pathology offer an exciting opportunity to capitalize on the use of whole slide images (WSIs) of hematoxylin and eosin (H&E) stained tumor tissue for objective prognosis and prediction of response to targeted therapies. AI models often require hand-delineated annotations for effective training which may not be readily available for larger data sets. In this study, we investigated whether AI models can be trained without region-level annotations and solely on patient-level survival data. We present a weakly supervised survival convolutional neural network (WSS-CNN) approach equipped with a visual attention mechanism for predicting overall survival. The inclusion of visual attention provides insights into regions of the tumor microenvironment with the pathological interpretation which may improve our understanding of the disease pathomechanism. We performed this analysis on two independent, multi-center patient data sets of lung (which is publicly available data) and bladder urothelial carcinoma. We perform univariable and multivariable analysis and show that WSS-CNN features are prognostic of overall survival in both tumor indications. The presented results highlight the significance of computational pathology algorithms for predicting prognosis using H&E stained images alone and underpin the use of computational methods to improve the efficiency of clinical trial studies.",Journal Article,
35669646,10.1155/2022/3149406,Lung Cancer Detection Based on Kernel PCA-Convolution Neural Network Feature Extraction and Classification by Fast Deep Belief Neural Network in Disease Management Using Multimedia Data Sources.,2022,Computational intelligence and neuroscience,"Jain DK, Lakshmi KM, Varma KP, Ramachandran M, Bharati S","Disease Management, Humans, Information Storage and Retrieval, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging, *Multimedia, Neural Networks, Computer","In lung cancer, tumor histology is a significant predictor of treatment response and prognosis. Although tissue samples for pathologist view are the most pertinent approach for histology classification, current advances in DL for medical image analysis point to the importance of radiologic data in further characterization of disease characteristics as well as risk stratification. Cancer is a complex global health problem that has seen an increase in death rates in recent years. Progress in cancer disease detection based on subset traits has enabled awareness of significant as well as exact disease diagnosis, thanks to the rapid flowering of high-throughput technology as well as numerous ML techniques that have emerged in recent years. As a result, advanced ML approaches that can successfully distinguish lung cancer patients from healthy people are of major importance. This paper proposed lung tumor detection based on histopathological image analysis using deep learning architectures. Here, the input image is taken as a histopathological image, and it has also been processed for removing noise, image resizing, and enhancing the image. Then the image features are extracted using Kernel PCA integrated with a convolutional neural network (KPCA-CNN), in which KPCA has been used in the feature extraction layer of CNN. The classification of extracted features has been put into effect using a Fast Deep Belief Neural Network (FDBNN). Finally, the classified output will give the tumorous cell and nontumorous cell of the lung from the input histopathological image. The experimental analysis has been carried out for various histopathological image datasets, and the obtained parameters are accuracy, precision, recall, and F-measure. Confusion matrix gives the actual class and predicted class of tumor in an input image. From the comparative analysis, the proposed technique obtains enhanced output in detecting the tumor once compared with an existing methodology for the various datasets.",Journal Article,The authors declare no conflicts of interest.
35629106,10.3390/jpm12050683,Multi-Class Classification of Breast Cancer Using 6B-Net with Deep Feature Fusion and Selection Method.,2022 Apr 26,Journal of personalized medicine,"Umer MJ, Sharif M, Kadry S, Alharbi A","6B-Net, breast cancer, deep features selection, deep learning, fusion, machine learning, multi-class","Breast cancer has now overtaken lung cancer as the world's most commonly diagnosed cancer, with thousands of new cases per year. Early detection and classification of breast cancer are necessary to overcome the death rate. Recently, many deep learning-based studies have been proposed for automatic diagnosis and classification of this deadly disease, using histopathology images. This study proposed a novel solution for multi-class breast cancer classification from histopathology images using deep learning. For this purpose, a novel 6B-Net deep CNN model, with feature fusion and selection mechanism, was developed for multi-class breast cancer classification. For the evaluation of the proposed method, two large, publicly available datasets, namely, BreaKHis, with eight classes containing 7909 images, and a breast cancer histopathology dataset, containing 3771 images of four classes, were used. The proposed method achieves a multi-class average accuracy of 94.20%, with a classification training time of 226 s in four classes of breast cancer, and a multi-class average accuracy of 90.10%, with a classification training time of 147 s in eight classes of breast cancer. The experimental outcomes show that the proposed method achieves the highest multi-class average accuracy for breast cancer classification, and hence, the proposed method can effectively be applied for early detection and classification of breast cancer to assist the pathologists in early and accurate diagnosis of breast cancer.",Journal Article,
35625678,10.3390/biomedicines10050941,Temporal and Locational Values of Images Affecting the Deep Learning of Cancer Stem Cell Morphology.,2022 Apr 19,Biomedicines,"Hanai Y, Ishihata H, Zhang Z, Maruyama R, Kasai T, Kameda H, Sugiyama T","artificial intelligence, cancer stem cell, cell morphology, classification, segmentation","Deep learning is being increasingly applied for obtaining digital microscopy image data of cells. Well-defined annotated cell images have contributed to the development of the technology. Cell morphology is an inherent characteristic of each cell type. Moreover, the morphology of a cell changes during its lifetime because of cellular activity. Artificial intelligence (AI) capable of recognizing a mouse-induced pluripotent stem (miPS) cell cultured in a medium containing Lewis lung cancer (LLC) cell culture-conditioned medium (cm), miPS-LLCcm cell, which is a cancer stem cell (CSC) derived from miPS cell, would be suitable for basic and applied science. This study aims to clarify the limitation of AI models constructed using different datasets and the versatility improvement of AI models. The trained AI was used to segment CSC in phase-contrast images using conditional generative adversarial networks (CGAN). The dataset included blank cell images that were used for training the AI but they did not affect the quality of predicting CSC in phase contrast images compared with the dataset without the blank cell images. AI models trained using images of 1-day culture could predict CSC in images of 2-day culture; however, the quality of the CSC prediction was reduced. Convolutional neural network (CNN) classification indicated that miPS-LLCcm cell image classification was done based on cultivation day. By using a dataset that included images of each cell culture day, the prediction of CSC remains to be improved. This is useful because cells do not change the characteristics of stem cells owing to stem cell marker expression, even if the cell morphology changes during culture.",Journal Article,
35609382,10.1016/j.ejmp.2022.05.008,Treatment plan prediction for lung IMRT using deep learning based fluence map generation.,2022 Jul,Physica medica : PM : an international journal devoted to the applications of physics to medicine and biology : official journal of the Italian Association of Biomedical Physics (AIFB),"Vandewinckele L, Willems S, Lambrecht M, Berkovic P, Maes F, Crijns W","*Deep Learning, Humans, Lung, *Lung Neoplasms/radiotherapy, Radiotherapy Dosage, Radiotherapy Planning, Computer-Assisted, *Radiotherapy, Intensity-Modulated, Automation, Deep learning, Fluence prediction, IMRT, Radiotherapy treatment planning","PURPOSE: Recently, it has been shown that automated treatment planning can be executed by direct fluence prediction from patient anatomy using convolutional neural networks. Proof of principle publications utilise a fixed dose prescription and fixed collimator (0 degrees ) and gantry angles. The goal of this work is to further develop these principles for the challenging lung cancer indication with variable dose prescriptions, collimator and gantry angles. First we investigate the impact of clinical applicable collimator angles and various input parameters. Then, the model is tested in a complete user independent planning workflow. METHODS: The dataset consists of 152 lung cancer patients, previously treated with IMRT. The patients are treated with either a left or a right beam setup and collimator angles and dose prescriptions adjusted to their tumour shape and stage. First we compare two CNNs with standard vs. personalised, clinical collimator angles. Next, four CNNs are trained with various combinations of CT and contour inputs. Finally, a complete user free treatment planning workflow is evaluated. RESULTS: The difference between the predicted and ground truth fluence maps for the fluence prediction CNN with all anatomical inputs in terms of the mean mean absolute error (MAE) is 4.17 x 10(-4) for a fixed collimator angle and 5.46 x 10(-4) for variable collimator angles. These differences vanish in terms of DVH metrics. Furthermore, the impact of anatomical inputs is small. The mean MAE is 5.88 x 10(-4) if no anatomical information is given to the network. The DVH differences increase when a total user free planning workflow is examined. CONCLUSIONS: Fluence prediction with personalised collimator angles performs as good as fluence prediction with a standard collimator angle of zero degrees. The impact of anatomical inputs is small. The combination of a dose prediction and fluence prediction CNN deteriorates the fluence predictions. More investigation is required.",Journal Article,
35609005,10.1002/bab.2356,Targeted therapies in non-small cell lung cancer and the potential role of AI interventions in cancer treatment.,2022 May 24,Biotechnology and applied biochemistry,"Menon T, Gopal S, Rastogi Verma S","CAR-T and CAR-NK cells, CNN, CRISPR-Cas9, cancer vaccines, immunotherapy, machine learning and AI for tumor detection, non-small cell lung cancer","Non-small cell lung cancer is the most prevalent lung cancer, and almost three-fourths of patients are diagnosed in the advanced stage directly. In this stage, chemotherapy gives only a 15% 5-year survival rate. As people have varied symptoms and reactions to a specific cancer type, treatment for the tumor is likely to fall short, complicating cancer therapy. Immunotherapy is a breakthrough treatment involving drugs targeting novel immune checkpoint inhibitors like CTLA-4 and PD-1/PD-L1, along with combination therapies. In addition, the utility of engineered CAR-T and CAR-NK cells can be an effective strategy to promote the immune response against tumors. The concept of personalized cancer vaccines with the discovery of neoantigens loaded on dendritic cell vectors can also be an effective approach to cure cancer. Advances in genetic engineering tools like CRISPR/Cas9-mediated gene editing of T cells to enhance their effector function is another ray of hope. This review aims to provide an overview of recent developments in cancer immunotherapy, which can be used in first- and second-line treatments in the clinical space. Further, the intervention of artificial intelligence to detect cancer tumors at an initial stage with the help of machine learning techniques is also explored.","Journal Article, Review",
35573467,10.1117/1.JMI.9.5.052402,Efficient multiscale fully convolutional UNet model for segmentation of 3D lung nodule from CT image.,2022 Sep,"Journal of medical imaging (Bellingham, Wash.)","Agnes SA, Anitha J","convolutional neural network, deep learning, maxout aggregation, multiscale fully convolutional UNet, semantic segmentation, three-dimensional nodule segmentation","Purpose: Segmentation of lung nodules in chest CT images is essential for image-driven lung cancer diagnosis and follow-up treatment planning. Manual segmentation of lung nodules is subjective because the approach depends on the knowledge and experience of the specialist. We proposed a multiscale fully convolutional three-dimensional UNet (MF-3D UNet) model for automatic segmentation of lung nodules in CT images. Approach: The proposed model employs two strategies, fusion of multiscale features with Maxout aggregation and trainable downsampling, to improve the performance of nodule segmentation in 3D CT images. The fusion of multiscale (fine and coarse) features with the Maxout function allows the model to retain the most important features while suppressing the low-contribution features. The trainable downsampling process is used instead of fixed pooling-based downsampling. Results: The performance of the proposed MF-3D UNet model is examined by evaluating the model with CT scans obtained from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset. A quantitative and visual comparative analysis of the proposed work with various customized UNet models is also presented. The comparative analysis shows that the proposed model yields reliable segmentation results compared with other methods. The experimental result of 3D MF-UNet shows encouraging results in the segmentation of different types of nodules, including juxta-pleural, solitary pulmonary, and non-solid nodules, with an average Dice similarity coefficient of 0.83 +/- 0.05 , and it outperforms other CNN-based segmentation models. Conclusions: The proposed model accurately segments the nodules using multiscale feature aggregation and trainable downsampling approaches. Also, 3D operations enable precise segmentation of complex nodules using inter-slice connections.",Journal Article,
35551276,10.1371/journal.pone.0268329,Artificial neural network in the discrimination of lung cancer based on infrared spectroscopy.,2022,PloS one,"Lugtu EJ, Ramos DB, Agpalza AJ, Cabral EA, Carandang RP, Dee JE, Martinez A, Jose JE, Santillan A, Bangaoil R, Albano PM, Tomas RC","Area Under Curve, *Brain Neoplasms, Humans, *Lung Neoplasms/diagnosis, Machine Learning, Neural Networks, Computer, Spectrophotometry, Infrared","Given the increasing prevalence of lung cancer worldwide, an auxiliary diagnostic method is needed alongside the microscopic examination of biopsy samples, which is dependent on the skills and experience of pathologists. Thus, this study aimed to advance lung cancer diagnosis by developing five (5) artificial neural network (NN) models that can discriminate malignant from benign samples based on infrared spectral data of lung tumors (n = 122; 56 malignant, 66 benign). NNs were benchmarked with classical machine learning (CML) models. Stratified 10-fold cross-validation was performed to evaluate the NN models, and the performance metrics-area under the curve (AUC), accuracy (ACC) positive predictive value (PPV), negative predictive value (NPV), specificity rate (SR), and recall rate (RR)-were averaged for comparison. All NNs were able to outperform the CML models, however, support vector machine is relatively comparable to NNs. Among the NNs, CNN performed best with an AUC of 92.28% +/- 7.36%, ACC of 98.45% +/- 1.72%, PPV of 96.62% +/- 2.30%, NPV of 90.50% +/- 11.92%, SR of 96.01% +/- 3.09%, and RR of 89.21% +/- 12.93%. In conclusion, NNs can be potentially used as a computational tool in lung cancer diagnosis based on infrared spectroscopy of lung tissues.",Journal Article,The authors have declared that no competing interests exist.
35548037,10.4103/jmp.jmp_61_21,A Novel Hybridized Feature Extraction Approach for Lung Nodule Classification Based on Transfer Learning Technique.,2022 Jan-Mar,Journal of medical physics,"Bruntha PM, Pandian SIA, Anitha J, Abraham SS, Kumar SN","Convolutional neural network, hybridized features, radial basis function support vector machine, residual neural network, transfer learning","Purpose: In the field of medical diagnosis, deep learning-based computer-aided detection of diseases will reduce the burden of physicians in the diagnosis of diseases especially in the case of lung cancer nodule classification. Materials and Methods: A hybridized model which integrates deep features from Residual Neural Network using transfer learning and handcrafted features from the histogram of oriented gradients feature descriptor is proposed to classify the lung nodules as benign or malignant. The intrinsic convolutional neural network (CNN) features have been incorporated and they can resolve the drawbacks of handcrafted features that do not completely reflect the specific characteristics of a nodule. In the meantime, they also reduce the need for a large-scale annotated dataset for CNNs. For classifying malignant nodules and benign nodules, radial basis function support vector machine is used. The proposed hybridized model is evaluated on the LIDC-IDRI dataset. Results: It has achieved an accuracy of 97.53%, sensitivity of 98.62%, specificity of 96.88%, precision of 95.04%, F1 score of 0.9679, false-positive rate of 3.117%, and false-negative rate of 1.38% and has been compared with other state of the art techniques. Conclusions: The performance of the proposed hybridized feature-based classification technique is better than the deep features-based classification technique in lung nodule classification.",Journal Article,There are no conflicts of interest.
35524089,10.1007/s11517-022-02578-0,An improved CNN-based architecture for automatic lung nodule classification.,2022 Jul,Medical & biological engineering & computing,"Mahmood SA, Ahmed HA","Diagnosis, Computer-Assisted/methods, Humans, Lung/diagnostic imaging/pathology, *Lung Neoplasms/diagnosis, *Neural Networks, Computer, Tomography, X-Ray Computed/methods, Computer-aided diagnosis, Convolutional neural network, Deep learning, Lung nodule classification","Lung cancer is one of the most critical diseases due to its significant death rate compared to all other types of cancer. The early diagnosis of lung cancer that improves the patient's chance of surviving is mostly done in two phases: screening through CT scan imaging modality and, more importantly the medical expert's reading of the scan, which is a time-consuming task and is vulnerable to errors. It is difficult to differentiate between malignant and benign nodules and biopsies are highly invasive, and patients with benign nodules may undergo unnecessary procedures. In this study, we propose a CNN-based computer-aided diagnosis system to automatically classify pulmonary nodules into benign or malignant. The proposed network architecture is based on AlexNet architecture that experiments with several types of layer ordering, hyperparameters, and functions for the various sides of the network. To build a well-trained model, several pre-processing steps are applied to the entire dataset, for instance segmentation, normalization, and zero centering. Finally, the proposed system obtained results with 98.7% accuracy, 98.6% sensitivity, and 98.9% specificity. The proposed model achieved superior performance compared to the AlexNet. The modifications in the original AlexNet is done to get a reasonable structure that has high nodule analysis sensitivity.",Journal Article,
35523553,10.7507/1001-5515.202011058,[A three dimensional convolutional neural network pulmonary nodule detection algorithm based on the multi-scale attention mechanism].,2022 Apr 25,Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi,"Zhao Y, Peng Z, Ma J, Xia H, Wan H","Algorithms, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, *Radiographic Image Interpretation, Computer-Assisted/methods, Tomography, X-Ray Computed/methods, Attention mechanism, Multi-scale feature extraction, Pulmonary nodule detection, Three dimensional convolutional neural network","Early screening based on computed tomography (CT) pulmonary nodule detection is an important means to reduce lung cancer mortality, and in recent years three dimensional convolutional neural network (3D CNN) has achieved success and continuous development in the field of lung nodule detection. We proposed a pulmonary nodule detection algorithm by using 3D CNN based on a multi-scale attention mechanism. Aiming at the characteristics of different sizes and shapes of lung nodules, we designed a multi-scale feature extraction module to extract the corresponding features of different scales. Through the attention module, the correlation information between the features was mined from both spatial and channel perspectives to strengthen the features. The extracted features entered into a pyramid-similar fusion mechanism, so that the features would contain both deep semantic information and shallow location information, which is more conducive to target positioning and bounding box regression. On representative LUNA16 datasets, compared with other advanced methods, this method significantly improved the detection sensitivity, which can provide theoretical reference for clinical medicine.",Journal Article,
35503850,10.1109/JBHI.2022.3171851,Self-Supervised Transfer Learning Based on Domain Adaptation for Benign-Malignant Lung Nodule Classification on Thoracic CT.,2022 Aug,IEEE journal of biomedical and health informatics,"Huang H, Wu R, Li Y, Peng C","*Deep Learning, Humans, Lung/pathology, *Lung Neoplasms/diagnostic imaging, Radiographic Image Interpretation, Computer-Assisted/methods, *Solitary Pulmonary Nodule/diagnostic imaging, Tomography, X-Ray Computed/methods","The spatial heterogeneity is an important indicator of the malignancy of lung nodules in lung cancer diagnosis. Compared with 2D nodule CT images, the 3D volumes with entire nodule objects hold richer discriminative information. However, for deep learning methods driven by massive data, effectively capturing the 3D discriminative features of nodules in limited labeled samples is a challenging task. Different from previous models that proposed transfer learning models in a 2D pattern or learning from scratch 3D models, we develop a self-supervised transfer learning based on domain adaptation (SSTL-DA) 3D CNN framework for benign-malignant lung nodule classification. At first, a data pre-processing strategy termed adaptive slice selection (ASS) is developed to eliminate the redundant noise of the input samples with lung nodules. Then, the self-supervised learning network is constructed to learn robust image representations from CT images. Finally, a transfer learning method based on domain adaptation is designed to obtain discriminant features for classification. The proposed SSTL-DA method has been assessed on the LIDC-IDRI benchmark dataset, and it obtains an accuracy of 91.07% and an AUC of 95.84%. These results demonstrate that the SSTL-DA model achieves quite a competitive classification performance compared with some state-of-the-art approaches.","Journal Article, Research Support, Non-U.S. Gov't",
35445619,10.1177/09544119221090725,Lung cancer diagnosis of CT images using metaheuristics and deep learning.,2022 Apr 21,"Proceedings of the Institution of Mechanical Engineers. Part H, Journal of engineering in medicine","Ma Q, Jimenez G","Lung cancer CT scan image, computer-aided diagnosis, convolutional neural network, gray-level co-occurrence matrices, modified Red Fox Optimization","Lung cancer is the uncontrolled growth of cells in the lung that is made up of two spongy organs located in the chest. These cells may penetrate outside the lung in a process called metastasis and spread to the tissues and organs of the body and increase the risk of death from this disease. CT scan of pulmonary nodules is one of the methods of early detection of lung cancer. One of the main challenges in diagnosing pulmonary nodules is the difficulty of identifying and distinguishing pulmonary nodules from lung components. In this study, a computer-aided detection system is introduced to identify these nodules. In the study, after image preprocessing, an image segmentation based on Otsu followed by mathematical morphology is proposed. Then, optimal features are selected based on a new metaheuristic method. Consequently, the characteristics are injected into an improved convolutional neural network (CNN)-based classifier to provide a high accuracy diagnosis system. The optimization of the Otsu method, feature selection, and CNN classifier is established by a new modified version of the Red Fox Optimizer (RFO) algorithm. The approach is then applied to three popular lung cancer datasets and the results are compared with three state-of-the-art methods to show the proposed method's higher efficiency.",Journal Article,
35443832,10.1177/15330338221090847,Gross Tumor Volume Segmentation for Stage III NSCLC Radiotherapy Using 3D ResSE-Unet.,2022 Jan-Dec,Technology in cancer research & treatment,"Yu X, Jin F, Luo H, Lei Q, Wu Y","*Carcinoma, Non-Small-Cell Lung/diagnostic imaging/radiotherapy, Humans, Image Processing, Computer-Assisted, *Lung Neoplasms/diagnostic imaging/radiotherapy, Tomography, X-Ray Computed, Tumor Burden, *CNNs, *GTV, *auto-segmentation, *lung cancer, *radiotherapy","INTRODUCTION: Radiotherapy is one of the most effective ways to treat lung cancer. Accurately delineating the gross target volume is a key step in the radiotherapy process. In current clinical practice, the target area is still delineated manually by radiologists, which is time-consuming and laborious. However, these problems can be better solved by deep learning-assisted automatic segmentation methods. METHODS: In this paper, a 3D CNN model named 3D ResSE-Unet is proposed for gross tumor volume segmentation for stage III NSCLC radiotherapy. This model is based on 3D Unet and combines residual connection and channel attention mechanisms. Three-dimensional convolution operation and encoding-decoding structure are used to mine three-dimensional spatial information of tumors from computed tomography data. Inspired by ResNet and SE-Net, residual connection and channel attention mechanisms are used to improve segmentation performance. A total of 214 patients with stage III NSCLC were collected selectively and 148 cases were randomly selected as the training set, 30 cases as the validation set, and 36 cases as the testing set. The segmentation performance of models was evaluated by the testing set. In addition, the segmentation results of different depths of 3D Unet were analyzed. And the performance of 3D ResSE-Unet was compared with 3D Unet, 3D Res-Unet, and 3D SE-Unet. RESULTS: Compared with other depths, 3D Unet with four downsampling depths is more suitable for our work. Compared with 3D Unet, 3D Res-Unet, and 3D SE-Unet, 3D ResSE-Unet can obtain superior results. Its dice similarity coefficient, 95th-percentile of Hausdorff distance, and average surface distance can reach 0.7367, 21.39mm, 4.962mm, respectively. And the average time cost of 3D ResSE-Unet to segment a patient is only about 10s. CONCLUSION: The method proposed in this study provides a new tool for GTV auto-segmentation and may be useful for lung cancer radiotherapy.","Journal Article, Research Support, Non-U.S. Gov't",
35428965,10.1007/s12539-022-00509-z,DNRLCNN: A CNN Framework for Identifying MiRNA-Disease Associations Using Latent Feature Matrix Extraction with Positive Samples.,2022 Jun,"Interdisciplinary sciences, computational life sciences","Zhong J, Zhou W, Kang J, Fang Z, Xie M, Xiao Q, Peng W","Algorithms, Computational Biology/methods, Genetic Predisposition to Disease, Humans, *MicroRNAs/genetics, Neural Networks, Computer, Convolutional neural network, Disease-gene association, Latent feature extraction, Positive samples, Similarity networks","Emerging evidence indicates that miRNAs have strong relationships with many human diseases. Investigating the associations will contribute to elucidating the activities of miRNAs and pathogenesis mechanisms, and providing new opportunities for disease diagnosis and drug discovery. Therefore, it is of significance to identify potential associations between miRNAs and diseases. The existing databases about the miRNA-disease associations (MDAs) only provide the known MDAs, which can be regarded as positive samples. However, the unknown MDAs are not sufficient to regard as reliable negative samples. To deal with this uncertainty, we proposed a convolutional neural network (CNN) framework, named DNRLCNN, based on a latent feature matrix extracted by only positive samples to predict MDAs. First, by only considering the positive samples into the calculation process, we captured the latent feature matrix for complex interactions between miRNAs and diseases in low-dimensional space. Then, we constructed a feature vector for each miRNA and disease pair based on the feature representation. Finally, we adopted a modified CNN for the feature vector to predict MDAs. As a result, our model achieves better performance than other state-of-the-art methods which based CNN in fivefold cross-validation on both miRNA-disease association prediction task (average AUC of 0.9030) and miRNA-phenotype association prediction task (average AUC of 0. 9442). In addition, we carried out case studies on two human diseases, and all the top-50 predicted miRNAs for lung neoplasms are confirmed by HMDD v3.2 and dbDEMC 2.0 databases, 98% of the top-50 predicted miRNAs for heart failure are confirmed. The experiment results show that our model has the capability of inferring potential disease-related miRNAs.",Journal Article,
35406511,10.3390/cancers14071740,Deep Learning Facilitates Distinguishing Histologic Subtypes of Pulmonary Neuroendocrine Tumors on Digital Whole-Slide Images.,2022 Mar 29,Cancers,"Ilie M, Benzaquen J, Tourniaire P, Heeke S, Ayache N, Delingette H, Long-Mira E, Lassalle S, Hamila M, Fayada J, Otto J, Cohen C, Gomez-Caro A, Berthet JP, Marquette CH, Hofman V, Bontoux C, Hofman P","CNN, HALO-AI, deep learning, lung, neuroendocrine carcinoma","The histological distinction of lung neuroendocrine carcinoma, including small cell lung carcinoma (SCLC), large cell neuroendocrine carcinoma (LCNEC) and atypical carcinoid (AC), can be challenging in some cases, while bearing prognostic and therapeutic significance. To assist pathologists with the differentiation of histologic subtyping, we applied a deep learning classifier equipped with a convolutional neural network (CNN) to recognize lung neuroendocrine neoplasms. Slides of primary lung SCLC, LCNEC and AC were obtained from the Laboratory of Clinical and Experimental Pathology (University Hospital Nice, France). Three thoracic pathologists blindly established gold standard diagnoses. The HALO-AI module (Indica Labs, UK) trained with 18,752 image tiles extracted from 60 slides (SCLC = 20, LCNEC = 20, AC = 20 cases) was then tested on 90 slides (SCLC = 26, LCNEC = 22, AC = 13 and combined SCLC with LCNEC = 4 cases; NSCLC = 25 cases) by F1-score and accuracy. A HALO-AI correct area distribution (AD) cutoff of 50% or more was required to credit the CNN with the correct diagnosis. The tumor maps were false colored and displayed side by side to original hematoxylin and eosin slides with superimposed pathologist annotations. The trained HALO-AI yielded a mean F1-score of 0.99 (95% CI, 0.939-0.999) on the testing set. Our CNN model, providing further larger validation, has the potential to work side by side with the pathologist to accurately differentiate between the different lung neuroendocrine carcinoma in challenging cases.",Journal Article,
35398579,10.1016/j.cmpb.2022.106786,One-stage pulmonary nodule detection using 3-D DCNN with feature fusion and attention mechanism in CT image.,2022 Jun,Computer methods and programs in biomedicine,"Huang YS, Chou PR, Chen HM, Chang YC, Chang RF","Humans, *Lung Neoplasms/diagnostic imaging, Radiographic Image Interpretation, Computer-Assisted/methods, *Sleep Apnea, Obstructive, *Solitary Pulmonary Nodule/diagnostic imaging, Tomography, X-Ray Computed/methods, Computer-aided detection, Feature fusion scheme, Lung nodule detection, One-shot aggregation, Receptive field block, YOLO","BACKGROUND AND OBJECTIVE: Lung cancer is the most common cause of cancer-related death in the world. Low-dose computed tomography (LDCT) is a widely used modality in lung cancer detection. The nodule is an abnormal tissue and may evolve into lung cancer. Hence, it is crucial to detect nodules in the early detection stage. However, reviewing the LDCT scans to observe suspicious nodules is a time-consuming task. Recently, designing a computer-aided detection (CADe) system with convolutional neural network (CNN) architecture has been proven that it is helpful for radiologists. Hence, in this study, a 3-D YOLO-based CADe system, 3-D OSAF-YOLOv3, is proposed for nodule detection in LDCT images. METHODS: The proposed CADe system consists of data preprocessing, nodule detection, and non-maximum suppression algorithm (NMS). At first, the data preprocessing including the background elimination, the spacing normalization, and the volume of interest (VOI) extraction, are conducted to remove the non-lung region, normalize the image spacing, and divide LDCT image into numerous VOIs. Then, the VOIs are fed into the 3-D OSAF-YOLOv3 model, to detect the suspicious nodules. The proposed model is constructed by integrating the 3-D YOLOv3 with the one-shot aggregation module (OSA), the receptive field block (RFB), and the feature fusion scheme (FFS). Finally, the NMS algorithm is performed to eliminate the duplicated detection generated by the model. RESULTS: In this study, the LUNA-16 dataset composed 1186 nodules from 888 LDCT scans and the competition performance metric (CPM) are used to evaluate our CADe system. In the experiment results, the proposed system can achieve a sensitivities rate of 0.962 with the false positive rate of 8 and complete a CPM value of 0.905. Moreover, according to the ablation study results, the employment of OSA module, RFB, and FFS could improve the detection performance actually. Furthermore, compared to other start-of-the-art (SOTA) models, our detection system could also achieve the higher performance. CONCLUSIONS: In this study, a YOLO-based CADe system for nodule detection in CT image system integrating additional modules and scheme is proposed for nodule detection in LDCT. The result indicates that the proposed the modification can significantly improve detection performance.",Journal Article,Declaration of Competing Interest The authors declare that they have no financial and personal relationships with other people or organizations that could inappropriately influence their work.
35395657,10.1088/1361-6560/ac65d6,Improved 3D tumour definition and quantification of uptake in simulated lung tumours using deep learning.,2022 Apr 27,Physics in medicine and biology,"Dal Toso L, Chalampalakis Z, Buvat I, Comtat C, Cook G, Goh V, Schnabel JA, Marsden PK","*Deep Learning, Humans, Image Processing, Computer-Assisted/methods, *Lung Neoplasms/diagnostic imaging, Phantoms, Imaging, Positron-Emission Tomography, *CNN, *PET, *quantification","Objective.In clinical positron emission tomography (PET) imaging, quantification of radiotracer uptake in tumours is often performed using semi-quantitative measurements such as the standardised uptake value (SUV). For small objects, the accuracy of SUV estimates is limited by the noise properties of PET images and the partial volume effect. There is need for methods that provide more accurate and reproducible quantification of radiotracer uptake.Approach.In this work, we present a deep learning approach with the aim of improving quantification of lung tumour radiotracer uptake and tumour shape definition. A set of simulated tumours, assigned with 'ground truth' radiotracer distributions, are used to generate realistic PET raw data which are then reconstructed into PET images. In this work, the ground truth images are generated by placing simulated tumours characterised by different sizes and activity distributions in the left lung of an anthropomorphic phantom. These images are then used as input to an analytical simulator to simulate realistic raw PET data. The PET images reconstructed from the simulated raw data and the corresponding ground truth images are used to train a 3D convolutional neural network.Results.When tested on an unseen set of reconstructed PET phantom images, the network yields improved estimates of the corresponding ground truth. The same network is then applied to reconstructed PET data generated with different point spread functions. Overall the network is able to recover better defined tumour shapes and improved estimates of tumour maximum and median activities.Significance.Our results suggest that the proposed approach, trained on data simulated with one scanner geometry, has the potential to restore PET data acquired with different scanners.","Journal Article, Research Support, Non-U.S. Gov't",
35392465,10.3389/fpubh.2022.860135,Dosimetric Study of Deep Learning-Guided ITV Prediction in Cone-beam CT for Lung Stereotactic Body Radiotherapy.,2022,Frontiers in public health,"Zhang S, Lv B, Zheng X, Li Y, Ge W, Zhang L, Mo F, Qiu J","Cone-Beam Computed Tomography/methods, *Deep Learning, Four-Dimensional Computed Tomography/methods, Humans, Lung/pathology, *Lung Neoplasms/diagnostic imaging/pathology/radiotherapy, *Radiosurgery/methods, Radiotherapy Dosage, Radiotherapy Planning, Computer-Assisted/methods, Retrospective Studies, *4DCT, *CBCT (cone beam computed tomography), *Mask R-CNN, *SBRT (stereotactic body radiation therapy), *deep learning","Purpose: The purpose of this study was to evaluate the accuracy of a lung stereotactic body radiotherapy (SBRT) treatment plan with the target of a newly predicted internal target volume (ITVpredict) and the feasibility of its clinical application. ITVpredict was automatically generated by our in-house deep learning model according to the cone-beam CT (CBCT) image database. Method: A retrospective study of 45 patients who underwent SBRT was involved, and Mask R-CNN based algorithm model helped to predict the internal target volume (ITV) using the CBCT image database. The geometric accuracy of ITVpredict was verified by the Dice Similarity Coefficient (DSC), 3D Motion Range (R3D), Relative Volume Index (RVI), and Hausdorff Distance (HD). The PTVpredict was generated by ITVpredict, which was registered and then projected on free-breath CT (FBCT) images. The PTVFBCT was margined from the GTV on FBCT images gross tumor volume on free-breath CT (GTVFBCT). Treatment plans with the target of Predict planning target volume on CBCT images (PTVpredict) and planning target volume on free-breath CT (PTVFBCT) were respectively re-established, and the dosimetric parameters included the ratio of the volume of patients receiving at least the prescribed dose to the volume of PTV (R100%), the ratio of the volume of patients receiving at least 50% of the prescribed dose to the volume of PTV in the Radiation Therapy Oncology Group (RTOG) 0813 Trial (R50%), Gradient Index (GI), and the maximum dose 2 cm from the PTV (D2cm), which were evaluated via Plan4DCT, plan which based on PTVpredict (Planpredict), and plan which based on PTVFBCT (PlanFBCT). Result: The geometric results showed that there existed a good correlation between ITVpredict and ITV on the 4-dimensional CT [ITV4DCT; DSC= 0.83 +/-0.18]. However, the average volume of ITVpredict was 10% less than that of ITV4DCT (p = 0.333). No significant difference in dose coverage was found in V100% for the ITV with 99.98 +/- 0.04% in the ITV4DCT vs. 97.56 +/- 4.71% in the ITVpredict (p = 0.162). Dosimetry parameters of PTV, including R100%, R50%, GI and D2cm showed no statistically significant difference between each plan (p > 0.05). Conclusion: Dosimetric parameters of Planpredict are clinically comparable to those of the original Plan4DCT. This study confirmed that the treatment plan based on ITVpredict produced by our model could automatically meet clinical requirements. Thus, for patients undergoing lung SBRT, the model has great potential for using CBCT images for ITV contouring which can be used in treatment planning.","Journal Article, Research Support, Non-U.S. Gov't",The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35387227,10.1155/2022/9452157,SC-Dynamic R-CNN: A Self-Calibrated Dynamic R-CNN Model for Lung Cancer Lesion Detection.,2022,Computational and mathematical methods in medicine,"Wang X, Wang L, Zheng P","*Carcinoma, Squamous Cell, Humans, Lung, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer","Lung cancer has complex biological characteristics and a high degree of malignancy. It has always been the number one ""killer"" in cancer, threatening human life and health. The diagnosis and early treatment of lung cancer still require improvement and further development. With high morbidity and mortality, there is an urgent need for an accurate diagnosis method. However, the existing computer-aided detection system has a complicated process and low detection accuracy. To solve this problem, this paper proposed a two-stage detection method based on the dynamic region-based convolutional neural network (Dynamic R-CNN). We divide lung cancer into squamous cell carcinoma, adenocarcinoma, and small cell carcinoma. By adding the self-calibrated convolution module into the feature network, we extracted more abundant lung cancer features and proposed a new regression loss function to further improve the detection performance of lung cancer. After experimental verification, the mAP (mean average precision) of the model can reach 88.1% on the lung cancer dataset and it performed particularly well with a high IoU (intersection over union) threshold. This method has a good performance in the detection of lung cancer and can improve the efficiency of doctors' diagnoses. It can avoid false detection and miss detection to a certain extent.",Journal Article,The authors declare that they have no conflicts of interest.
35386935,10.1109/trpms.2021.3133510,Enhancement of 4-D Cone-Beam Computed Tomography (4D-CBCT) Using a Dual-Encoder Convolutional Neural Network (DeCNN).,2022 Feb,IEEE transactions on radiation and plasma medical sciences,"Jiang Z, Zhang Z, Chang Y, Ge Y, Yin FF, Ren L","4D-CBCT, average-image constraint, deep learning, dual-encoder architecture, image enhancement","4D-CBCT is a powerful tool to provide respiration-resolved images for the moving target localization. However, projections in each respiratory phase are intrinsically under-sampled under the clinical scanning time and imaging dose constraints. Images reconstructed by compressed sensing (CS)-based methods suffer from blurred edges. Introducing the average-4D-image constraint to the CS-based reconstruction, such as prior-image-constrained CS (PICCS), can improve the edge sharpness of the stable structures. However, PICCS can lead to motion artifacts in the moving regions. In this study, we proposed a dual-encoder convolutional neural network (DeCNN) to realize the average-image-constrained 4D-CBCT reconstruction. The proposed DeCNN has two parallel encoders to extract features from both the under-sampled target phase images and the average images. The features are then concatenated and fed into the decoder for the high-quality target phase image reconstruction. The reconstructed 4D-CBCT using of the proposed DeCNN from the real lung cancer patient data showed (1) qualitatively, clear and accurate edges for both stable and moving structures; (2) quantitatively, low-intensity errors, high peak signal-to-noise ratio, and high structural similarity compared to the ground truth images; and (3) superior quality to those reconstructed by several other state-of-the-art methods including the back-projection, CS total-variation, PICCS, and the single-encoder CNN. Overall, the proposed DeCNN is effective in exploiting the average-image constraint to improve the 4D-CBCT image quality.",Journal Article,
35378943,10.1155/2022/3972298,Models of Artificial Intelligence-Assisted Diagnosis of Lung Cancer Pathology Based on Deep Learning Algorithms.,2022,Journal of healthcare engineering,Chen S,"Algorithms, Artificial Intelligence, *Deep Learning, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer","In this article, in order to explore the application of a diagnosis system for lung cancer, we use an auxiliary diagnostic system to predict and diagnose the good and evil attributes of chest CT pulmonary nodules. This research improves the new diagnosis method based on the convolutional neural network (CNN) and the recurrent neural network (RNN) and combines the dual effects of the two algorithms to process the classification of benign and malignant nodules. By collecting H-E-stained pathological slices of 652 patients' lung lesions from two hospitals between January 2018 and January 2019, the output results of the improved 3D U-net system and the consistent results of two-person reading were compared. This article analyzes the sensitivity, specificity, positive flammability rate, and negative flammability rate of different lung nodule detection methods. In addition, the artificial intelligence system's and the radiologist's judgment results of benign and malignant pulmonary nodules are used to draw ROC curves for further analysis. The improved model has an accuracy rate of 92.3% for predicting malignant lung nodules and an accuracy rate of 82.8% for benign lung nodules. The new diagnostic method using the convolutional neural network and the recurrent neural network can be very effective for improving the accuracy of predicting lung cancer diagnosis. It can play a very effective role in the disease prediction of lung cancer patients, thereby improving the treatment effect.",Journal Article,The author declares that there are no conflicts of interest with any financial organizations regarding the material reported in this article.
35368657,10.3389/fgene.2022.800853,A Novel Deep Learning Method to Predict Lung Cancer Long-Term Survival With Biological Knowledge Incorporated Gene Expression Images and Clinical Data.,2022,Frontiers in genetics,"Wang S, Zhang H, Liu Z, Liu Y","CNN, cancer precision medicine, cancer survival prediction, deep learning, multimodal, optimal threshold selection, survival analysis","Lung cancer is the leading cause of the cancer deaths. Therefore, predicting the survival status of lung cancer patients is of great value. However, the existing methods mainly depend on statistical machine learning (ML) algorithms. Moreover, they are not appropriate for high-dimensionality genomics data, and deep learning (DL), with strong high-dimensional data learning capability, can be used to predict lung cancer survival using genomics data. The Cancer Genome Atlas (TCGA) is a great database that contains many kinds of genomics data for 33 cancer types. With this enormous amount of data, researchers can analyze key factors related to cancer therapy. This paper proposes a novel method to predict lung cancer long-term survival using gene expression data from TCGA. Firstly, we select the most relevant genes to the target problem by the supervised feature selection method called mutual information selector. Secondly, we propose a method to convert gene expression data into two kinds of images with KEGG BRITE and KEGG Pathway data incorporated, so that we could make good use of the convolutional neural network (CNN) model to learn high-level features. Afterwards, we design a CNN-based DL model and added two kinds of clinical data to improve the performance, so that we finally got a multimodal DL model. The generalized experiments results indicated that our method performed much better than the ML models and unimodal DL models. Furthermore, we conduct survival analysis and observe that our model could better divide the samples into high-risk and low-risk groups.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35345362,10.31557/APJCP.2022.23.3.905,Segmentation of CT Lung Images Using FCM with Active Contour and CNN Classifier.,2022 Mar 1,Asian Pacific journal of cancer prevention : APJCP,"M M, P S, U M, K M, M N","*Fuzzy Logic, Humans, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, Tomography, X-Ray Computed/methods, Acive Contour Segmentation, Computer Tomography (CT), Convolutional Neural Network (CNN), FCM Fuzzy c means Algorithm, Lung cancer","OBJECTIVE: Lung cancer is one of the unsafe diseases for human which reduces the patient life time. Generally, most of the lung cancers are identified after it has been spread into the lung parts and moreover it is difficult to find the lung cancer at the early stage. It requires radiologist and special doctors to find the tumoral tissue of the lung cancer. For this reason, the recommended work helps to segment the tumoral tissue of CT lung image in an effective way. METHODS: The research work uses hybrid segmentation technique to separate the lung cancer cells to diagnose the lung tumour. It is a technique which combines active contour along with Fuzzy c means to diagnose the tumoral tissue. Further the segmented portion was trained by Convolutional Neural Network (CNN) in order to classify the segmented region as normal or abnormal. RESULTS: The evaluation of the proposed method was done by analyzing the results of test image with the ground truth image. Finally, the results of the implemented technique provided good accuracy, Peak signal to noise ratio (PSNR), Mean Square Error (MSE) value. In future the other techniques can be utilized to improve the details before segmentation. The proposed work provides 96.67 % accuracy. CONCLUSION: Hybrid segmentation technique involves several steps like preprocessing, binarization, thresholding, segmentation and feature extraction using GLCM.",Journal Article,
35331109,10.2174/1566523222666220324110914,Inferring Cell-type-specific Genes of Lung Cancer Based on Deep Learning.,2022,Current gene therapy,"Cheng N, Chen C, Li C, Huang J","*Deep Learning, Humans, Lung/pathology, *Lung Neoplasms/pathology, Neural Networks, Computer, Tumor Microenvironment, Cell-type-specific genes, chemotherapy, deep learning, lung cancer, radiotherapy, single-cell sequencing","BACKGROUND: Lung cancer is cancer with the highest incidence in the world, and there is obvious heterogeneity within its tumor. The emergence of single-cell sequencing technology allows researchers to obtain cell-type-specific expression genes at the single-cell level, thereby obtaining information regarding the cell status and subpopulation distribution, as well as the communication behavior between cells. Many researchers have applied this technology to lung cancer research, but due to the shortcomings of insufficient sequencing depth, only a small part of the gene expression can be detected. Researchers can only roughly compare whether a few thousand genes are significant in different cell types. METHODS: To fully explore the expression of all genes in different cell types, we propose a method to predict cell-type-specific genes. This method infers cell-type-specific genes based on the expression levels of genes in different tissues and cells and gene interactions. At present, biological experiments have discovered a large number of cell-type-specific genes, providing a large number of available samples for the application of deep learning methods. RESULTS: Therefore, we fused Graph Convolutional Network (GCN) with Convolutional Neural Network( CNN) to build, model, and inferred cell-type-specific genes of lung cancer in 8 cell types. CONCLUSION: This method further analyzes and processes single-cell data and provides a new basis for research on heterogeneity in lung cancer tumor, microenvironment, invasion and metastasis, treatment response, drug resistance, etc.",Journal Article,
35328149,10.3390/diagnostics12030596,3D Convolutional Neural Network-Based Denoising of Low-Count Whole-Body (18)F-Fluorodeoxyglucose and (89)Zr-Rituximab PET Scans.,2022 Feb 25,"Diagnostics (Basel, Switzerland)","de Vries BM, Golla SSV, Zwezerijnen GJC, Hoekstra OS, Jauw YWS, Huisman MC, van Dongen GAMS, Menke-van der Houven van Oordt WC, Zijlstra-Baalbergen JJM, Mesotten L, Boellaard R, Yaqub M","18F-FDG, 89Zr-antibody, CNN, denoising, low-count","Acquisition time and injected activity of (18)F-fluorodeoxyglucose ((18)F-FDG) PET should ideally be reduced. However, this decreases the signal-to-noise ratio (SNR), which impairs the diagnostic value of these PET scans. In addition, (89)Zr-antibody PET is known to have a low SNR. To improve the diagnostic value of these scans, a Convolutional Neural Network (CNN) denoising method is proposed. The aim of this study was therefore to develop CNNs to increase SNR for low-count (18)F-FDG and (89)Zr-antibody PET. Super-low-count, low-count and full-count (18)F-FDG PET scans from 60 primary lung cancer patients and full-count (89)Zr-rituximab PET scans from five patients with non-Hodgkin lymphoma were acquired. CNNs were built to capture the features and to denoise the PET scans. Additionally, Gaussian smoothing (GS) and Bilateral filtering (BF) were evaluated. The performance of the denoising approaches was assessed based on the tumour recovery coefficient (TRC), coefficient of variance (COV; level of noise), and a qualitative assessment by two nuclear medicine physicians. The CNNs had a higher TRC and comparable or lower COV to GS and BF and was also the preferred method of the two observers for both (18)F-FDG and (89)Zr-rituximab PET. The CNNs improved the SNR of low-count (18)F-FDG and (89)Zr-rituximab PET, with almost similar or better clinical performance than the full-count PET, respectively. Additionally, the CNNs showed better performance than GS and BF.",Journal Article,
35317723,10.1186/s12859-022-04611-3,A learning-based method to predict LncRNA-disease associations by combining CNN and ELM.,2022 Mar 22,BMC bioinformatics,"Guo ZH, Chen ZH, You ZH, Wang YB, Yi HC, Wang MN","Computational Biology/methods, Machine Learning, Neural Networks, Computer, *RNA, Long Noncoding/genetics, ROC Curve, Association prediction, CNN, Disease, ELM, lncRNA","BACKGROUND: lncRNAs play a critical role in numerous biological processes and life activities, especially diseases. Considering that traditional wet experiments for identifying uncovered lncRNA-disease associations is limited in terms of time consumption and labor cost. It is imperative to construct reliable and efficient computational models as addition for practice. Deep learning technologies have been proved to make impressive contributions in many areas, but the feasibility of it in bioinformatics has not been adequately verified. RESULTS: In this paper, a machine learning-based model called LDACE was proposed to predict potential lncRNA-disease associations by combining Extreme Learning Machine (ELM) and Convolutional Neural Network (CNN). Specifically, the representation vectors are constructed by integrating multiple types of biology information including functional similarity and semantic similarity. Then, CNN is applied to mine both local and global features. Finally, ELM is chosen to carry out the prediction task to detect the potential lncRNA-disease associations. The proposed method achieved remarkable Area Under Receiver Operating Characteristic Curve of 0.9086 in Leave-one-out cross-validation and 0.8994 in fivefold cross-validation, respectively. In addition, 2 kinds of case studies based on lung cancer and endometrial cancer indicate the robustness and efficiency of LDACE even in a real environment. CONCLUSIONS: Substantial results demonstrated that the proposed model is expected to be an auxiliary tool to guide and assist biomedical research, and the close integration of deep learning and biology big data will provide life sciences with novel insights.",Journal Article,
35310959,10.3389/frai.2022.826402,Developing a Cancer Digital Twin: Supervised Metastases Detection From Consecutive Structured Radiology Reports.,2022,Frontiers in artificial intelligence,"Batch KE, Yue J, Darcovich A, Lupton K, Liu CC, Woodlock DP, El Amine MAK, Causa-Andrieu PI, Gazit L, Nguyen GH, Zulkernine F, Do RKG, Simpson AL","cancer, convolutional neural network (CNN), digital twins, machine learning, metastases, natural language processing (NLP), radiology, recurrent neural network (RNN)","The development of digital cancer twins relies on the capture of high-resolution representations of individual cancer patients throughout the course of their treatment. Our research aims to improve the detection of metastatic disease over time from structured radiology reports by exposing prediction models to historical information. We demonstrate that Natural language processing (NLP) can generate better weak labels for semi-supervised classification of computed tomography (CT) reports when it is exposed to consecutive reports through a patient's treatment history. Around 714,454 structured radiology reports from Memorial Sloan Kettering Cancer Center adhering to a standardized departmental structured template were used for model development with a subset of the reports included for validation. To develop the models, a subset of the reports was curated for ground-truth: 7,732 total reports in the lung metastases dataset from 867 individual patients; 2,777 reports in the liver metastases dataset from 315 patients; and 4,107 reports in the adrenal metastases dataset from 404 patients. We use NLP to extract and encode important features from the structured text reports, which are then used to develop, train, and validate models. Three models-a simple convolutional neural network (CNN), a CNN augmented with an attention layer, and a recurrent neural network (RNN)-were developed to classify the type of metastatic disease and validated against the ground truth labels. The models use features from consecutive structured text radiology reports of a patient to predict the presence of metastatic disease in the reports. A single-report model, previously developed to analyze one report instead of multiple past reports, is included and the results from all four models are compared based on accuracy, precision, recall, and F1-score. The best model is used to label all 714,454 reports to generate metastases maps. Our results suggest that NLP models can extract cancer progression patterns from multiple consecutive reports and predict the presence of metastatic disease in multiple organs with higher performance when compared with a single-report-based prediction. It demonstrates a promising automated approach to label large numbers of radiology reports without involving human experts in a time- and cost-effective manner and enables tracking of cancer progression over time.",Journal Article,LG activities not related to the present article; receives options for consultancy from Within Health. The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35293240,10.1177/15330338221085375,Recognition of Peripheral Lung Cancer and Focal Pneumonia on Chest Computed Tomography Images Based on Convolutional Neural Network.,2022 Jan-Dec,Technology in cancer research & treatment,"Cheng X, Wen H, You H, Hua L, Xiaohua W, Qiuting C, Jiabao L","Artificial Intelligence, *COVID-19/diagnostic imaging, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, Pandemics, Retrospective Studies, Tomography, X-Ray Computed/methods, *3D CNN, *chest CT, *focal pneumonia, *peripheral lung cancer, *window settings","Introduction: Chest computed tomography (CT) is important for the early screening of lung diseases and clinical diagnosis, particularly during the COVID-19 pandemic. We propose a method for classifying peripheral lung cancer and focal pneumonia on chest CT images and undertake 5 window settings to study the effect on the artificial intelligence processing results. Methods: A retrospective collection of CT images from 357 patients with peripheral lung cancer having solitary solid nodule or focal pneumonia with a solitary consolidation was applied. We segmented and aligned the lung parenchyma based on some morphological methods and cropped this region of the lung parenchyma with the minimum 3D bounding box. Using these 3D cropped volumes of all cases, we designed a 3D neural network to classify them into 2 categories. We also compared the classification results of the 3 physicians with different experience levels on the same dataset. Results: We conducted experiments using 5 window settings. After cropping and alignment based on an automatic preprocessing procedure, our neural network achieved an average classification accuracy of 91.596% under a 5-fold cross-validation in the full window, in which the area under the curve (AUC) was 0.946. The classification accuracy and AUC value were 90.48% and 0.957 for the junior physician, 94.96% and 0.989 for the intermediate physician, and 96.92% and 0.980 for the senior physician, respectively. After removing the error prediction, the accuracy improved significantly, reaching 98.79% in the self-defined window2. Conclusion: Using the proposed neural network, in separating peripheral lung cancer and focal pneumonia in chest CT data, we achieved an accuracy competitive to that of a junior physician. Through a data ablation study, the proposed 3D CNN can achieve a slightly higher accuracy compared with senior physicians in the same subset. The self-defined window2 was the best for data training and evaluation.","Journal Article, Research Support, Non-U.S. Gov't",
35282064,10.21037/atm-21-3231,Total nodule number as an independent prognostic factor in resected stage III non-small cell lung cancer: a deep learning-powered study.,2022 Jan,Annals of translational medicine,"Chen X, Qi Q, Sun Z, Wang D, Sun J, Tan W, Liu X, Liu T, Hong N, Yang F","Nodule number, artificial intelligence, multiple pulmonary nodules, non-small cell lung cancer (NSCLC), prognosis","Background: Almost every patient with lung cancer has multiple pulmonary nodules; however, the significance of nodule multiplicity in locally advanced non-small cell lung cancer (NSCLC) remains unclear. Methods: We identified patients who had undergone surgical resection for stage I-III NSCLC at the Peking University People's Hospital from 2005 to 2018 for whom preoperative chest computed tomography (CT) scans were available. Deep learning-based artificial intelligence (AI) algorithms using convolutional neural networks (CNN) were applied to detect and classify pulmonary nodules (PNs). Maximally selected log-rank statistics were used to determine the optimal cutoff value of the total nodule number (TNN) for predicting survival. Results: A total of 33,410 PNs were detected by AI among the 2,126 participants. The median TNN detected per person was 12 [interquartile range (IQR) 7-20]. It was revealed that AI-detected TNN (analyzed as a continuous variable) was an independent prognostic factor for both recurrence-free survival (RFS) [hazard ratio (HR) 1.012, 95% confidence interval (CI): 1.002 to 1.022, P=0.021] and overall survival (OS) (HR 1.013, 95% CI: 1.002 to 1.025, P=0.021) in multivariate analyses of the stage III cohort. In contrast, AI-detected TNN was not significantly associated with survival in the stage I and II cohorts. In a survival tree analysis, rather than using traditional IIIA and IIIB classifications, the model grouped cases according to AI-detected TNN (lower vs. higher: log-rank P<0.001), which led to a more effective determination of survival rates in the stage III cohort. Conclusions: The AI-detected TNN is significantly associated with survival rates in patients with surgically resected stage III NSCLC. A lower TNN detected on preoperative CT scans indicates a better prognosis for patients who have undergone complete surgical resection.",Journal Article,"Conflicts of Interest: All authors have completed the ICMJE uniform disclosure form (available at https://atm.amegroups.com/article/view/10.21037/atm-21-3231/coif). XC reports funding from the National Natural Science Foundation of China (82002983). DW, JS, and WT were employed by the company Beijing Infervision Technology Co., Ltd. The other authors have no conflicts of interest to declare."
35280310,10.21037/tlcr-22-59,Prediction of future imagery of lung nodule as growth modeling with follow-up computed tomography scans using deep learning: a retrospective cohort study.,2022 Feb,Translational lung cancer research,"Tao G, Zhu L, Chen Q, Yin L, Li Y, Yang J, Ni B, Zhang Z, Koo CW, Patil PD, Chen Y, Yu H, Xu Y, Ye X","Lung nodule, deep learning, follow-up, growth pattern prediction","Background: Risk prediction models of lung nodules have been built to alleviate the heavy interpretative burden on clinicians. However, the malignancy scores output by those models can be difficult to interpret in a clinically meaningful manner. In contrast, the modeling of lung nodule growth may be more readily useful. This study developed a CT-based visual forecasting system that can visualize and quantify a nodule in three dimensions (3D) in any future time point using follow-up CT scans. Methods: We retrospectively included 246 patients with 313 lung nodules with at least 1 follow-up CT scan. For the manually segmented nodules, we calculated geometric properties including CT value, diameter, volume, and mass, as well as growth properties including volume doubling time (VDT), and consolidation-to-tumor ratio (CTR) at follow-ups. These nodules were divided into growth and non-growth groups by thresholding their VDTs. We then developed a convolutional neural network (CNN) to model the imagery change of the nodules from baseline CT image (combined with the nodule mask) to follow-up CT image with a particular time interval. The model was evaluated on the geometric and radiological properties using either logistic regression or receiver operating characteristic (ROC) curve. Results: The lung nodules consisted of 115 ground glass nodules (GGN) and 198 solid nodules and were followed up for an average of 354 days with 2 to 11 scans. The 2 groups differed significantly in most properties. The prediction of our forecasting system was highly correlated with the ground truth with small relative errors regarding the four geometric properties. The prediction-derived VDTs had an area under the curve (AUC) of 0.857 and 0.843 in differentiating growth and non-growth nodules for GGN and solid nodules, respectively. The prediction-derived CTRs had an AUC of 0.892 in classifying high- and low-risk nodules. Conclusions: This proof-of-concept study demonstrated that the deep learning-based model can accurately forecast the imagery of a nodule in a given future for both GGNs and solid nodules and is worthy of further investigation. With a larger dataset and more validation, such a system has the potential to become a prognostication tool for assessing lung nodules.",Journal Article,Conflicts of Interest: All authors have completed the ICMJE uniform disclosure form (available at https://tlcr.amegroups.com/article/view/10.21037/tlcr-22-59/coif). The authors have no conflicts of interest to declare.
35273914,10.3389/fonc.2022.821594,Deep Learning-Based Classification of Cancer Cell in Leptomeningeal Metastasis on Cytomorphologic Features of Cerebrospinal Fluid.,2022,Frontiers in oncology,"Yu W, Liu Y, Zhao Y, Huang H, Liu J, Yao X, Li J, Xie Z, Jiang L, Wu H, Cao X, Zhou J, Guo Y, Li G, Ren MX, Quan Y, Mu T, Izquierdo GA, Zhang G, Zhao R, Zhao D, Yan J, Zhang H, Lv J, Yao Q, Duan Y, Zhou H, Liu T, He Y, Bian T, Dai W, Huai J, Wang X, He Q, Gao Y, Ren W, Niu G, Zhao G","CSF, cancer cell, cytology, deep learning, leptomeningeal metastasis (LM)","Background: It is a critical challenge to diagnose leptomeningeal metastasis (LM), given its technical difficulty and the lack of typical symptoms. The existing gold standard of diagnosing LM is to use positive cerebrospinal fluid (CSF) cytology, which consumes significantly more time to classify cells under a microscope. Objective: This study aims to establish a deep learning model to classify cancer cells in CSF, thus facilitating doctors to achieve an accurate and fast diagnosis of LM in an early stage. Method: The cerebrospinal fluid laboratory of Xijing Hospital provides 53,255 cells from 90 LM patients in the research. We used two deep convolutional neural networks (CNN) models to classify cells in the CSF. A five-way cell classification model (CNN1) consists of lymphocytes, monocytes, neutrophils, erythrocytes, and cancer cells. A four-way cancer cell classification model (CNN2) consists of lung cancer cells, gastric cancer cells, breast cancer cells, and pancreatic cancer cells. Here, the CNN models were constructed by Resnet-inception-V2. We evaluated the performance of the proposed models on two external datasets and compared them with the results from 42 doctors of various levels of experience in the human-machine tests. Furthermore, we develop a computer-aided diagnosis (CAD) software to generate cytology diagnosis reports in the research rapidly. Results: With respect to the validation set, the mean average precision (mAP) of CNN1 is over 95% and that of CNN2 is close to 80%. Hence, the proposed deep learning model effectively classifies cells in CSF to facilitate the screening of cancer cells. In the human-machine tests, the accuracy of CNN1 is similar to the results from experts, with higher accuracy than doctors in other levels. Moreover, the overall accuracy of CNN2 is 10% higher than that of experts, with a time consumption of only one-third of that consumed by an expert. Using the CAD software saves 90% working time of cytologists. Conclusion: A deep learning method has been developed to assist the LM diagnosis with high accuracy and low time consumption effectively. Thanks to labeled data and step-by-step training, our proposed method can successfully classify cancer cells in the CSF to assist LM diagnosis early. In addition, this unique research can predict cancer's primary source of LM, which relies on cytomorphologic features without immunohistochemistry. Our results show that deep learning can be widely used in medical images to classify cerebrospinal fluid cells. For complex cancer classification tasks, the accuracy of the proposed method is significantly higher than that of specialist doctors, and its performance is better than that of junior doctors and interns. The application of CNNs and CAD software may ultimately aid in expediting the diagnosis and overcoming the shortage of experienced cytologists, thereby facilitating earlier treatment and improving the prognosis of LM.",Journal Article,The authors declare that the research was conducted without any commercial or financial relationships that could be construed as a potential conflict of interest.
35242624,10.21037/tlcr-21-870,Malignant thoracic lymph node classification with deep convolutional neural networks on real-time endobronchial ultrasound (EBUS) images.,2022 Jan,Translational lung cancer research,"Yong SH, Lee SH, Oh SI, Keum JS, Kim KN, Park MS, Chang YS, Kim EY","Convolutional neural networks (CNNs), deep learning, endobronchial ultrasound (EBUS), endobronchial ultrasound-guided transbronchial needle aspiration (EBUS-TBNA), lung cancer","BACKGROUND: Thoracic lymph node (LN) evaluation is essential for the accurate diagnosis of lung cancer and deciding the appropriate course of treatment. Endobronchial ultrasound-guided transbronchial needle aspiration (EBUS-TBNA) is considered a standard method for mediastinal nodal staging. This study aims to build a deep convolutional neural network (CNN) for the automatic classification of metastatic malignancies involving thoracic LN, using EBUS-TBNA. METHODS: Patients who underwent EBUS-TBNAs to assess the presence of malignancy in mediastinal LNs during a ten-month period at Severance Hospital, Seoul, Republic of Korea, were included in the study. Corresponding LN ultrasound images, pathology reports, demographic data, and clinical history were collected and analyzed. RESULTS: A total of 2,394 endobronchial ultrasound (EBUS) images of 1,459 benign LNs from 193 patients, and 935 malignant LNs from 177 patients, were collected. We employed the visual geometry group (VGG)-16 network to classify malignant LNs using only traditional cross-entropy for classification loss. The sensitivity, specificity, and accuracy of predicting malignancy were 69.7%, 74.3%, and 72.0%, respectively, and the overall area under the curve (AUC) was 0.782. We applied the new loss function to train the network and, using the modified VGG-16, the AUC improved to a value of 0.8. The sensitivity, specificity, and accuracy improved to 72.7%, 79.0%, and 75.8%, respectively. In addition, the proposed network can process 63 images per second on a single mainstream graphics processing unit (GPU) device, making it suitable for real-time analysis of EBUS images. CONCLUSIONS: Deep CNNs can effectively classify malignant LNs from EBUS images. Selecting LNs that require biopsy using real-time EBUS image analysis with deep learning is expected to shorten the EBUS-TBNA procedure time, increase lung cancer nodal staging accuracy, and improve patient safety.",Journal Article,Conflicts of Interest: All authors have completed the ICMJE uniform disclosure form (available at https://tlcr.amegroups.com/article/view/10.21037/tlcr-21-870/coif). SIO and JSK have been full-time employees of Waycen Inc. during this study. KNK has been the CEO of Waycen Inc. during this study. The other authors have no conflicts of interest to declare.
35238972,10.1007/s00330-022-08635-4,Developing an understanding of artificial intelligence lung nodule risk prediction using insights from the Brock model.,2022 Aug,European radiology,"Chetan MR, Dowson N, Price NW, Ather S, Nicolson A, Gleeson FV","Artificial Intelligence, Humans, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, *Precancerous Conditions, Tomography, X-Ray Computed/methods, Algorithms, Artificial intelligence, Early detection of cancer, Multidetector computed tomography, Neural networks, Computer","OBJECTIVES: To determine if predictions of the Lung Cancer Prediction convolutional neural network (LCP-CNN) artificial intelligence (AI) model are analogous to the Brock model. METHODS: In total, 10,485 lung nodules in 4660 participants from the National Lung Screening Trial (NLST) were analysed. Both manual and automated nodule measurements were inputted into the Brock model, and this was compared to LCP-CNN. The performance of an experimental AI model was tested after ablating imaging features in a manner analogous to removing predictors from the Brock model. First, the nodule was ablated leaving lung parenchyma only. Second, a sphere of the same size as the nodule was implanted in the parenchyma. Third, internal texture of both nodule and parenchyma was ablated. RESULTS: Automated axial diameter (AUC 0.883) and automated equivalent spherical diameter (AUC 0.896) significantly improved the accuracy of Brock when compared to manual measurement (AUC 0.873), although not to the level of the LCP-CNN (AUC 0.936). Ablating nodule and parenchyma texture (AUC 0.915) led to a small drop in AI predictive accuracy, as did implanting a sphere of the same size as the nodule (AUC 0.889). Ablating the nodule leaving parenchyma only led to a large drop in AI performance (AUC 0.717). CONCLUSIONS: Feature ablation is a feasible technique for understanding AI model predictions. Nodule size and morphology play the largest role in AI prediction, with nodule internal texture and background parenchyma playing a limited role. This is broadly analogous to the relative importance of morphological factors over clinical factors within the Brock model. KEY POINTS: * Brock lung cancer risk prediction accuracy was significantly improved using automated axial or equivalent spherical measurements of lung nodule diameter, when compared to manual measurements. * Predictive accuracy was further improved by using the Lung Cancer Prediction convolutional neural network, an artificial intelligence-based model which obviates the requirement for nodule measurement. * Nodule size and morphology are important factors in artificial intelligence lung cancer risk prediction, with nodule texture and background parenchyma contributing a small, but measurable, role.",Journal Article,
35232390,10.1186/s12880-022-00755-z,A novel adaptive momentum method for medical image classification using convolutional neural network.,2022 Mar 1,BMC medical imaging,"Aytac UC, Gunes A, Ajlouni N","Brain/*diagnostic imaging, Brain Neoplasms/*diagnostic imaging, COVID-19/*diagnostic imaging, Datasets as Topic, Diagnostic Imaging, Humans, Image Interpretation, Computer-Assisted, Lung/diagnostic imaging, Neural Networks, Computer, Radiography, Thoracic/*methods, SARS-CoV-2, Tomography, X-Ray Computed/*methods, *Adaptive momentum methods, *Backpropagation algorithm, *Convolutional neural networks, *Medical image classification, *Nonconvex optimization","BACKGROUND: AI for medical diagnosis has made a tremendous impact by applying convolutional neural networks (CNNs) to medical image classification and momentum plays an essential role in stochastic gradient optimization algorithms for accelerating or improving training convolutional neural networks. In traditional optimizers in CNNs, the momentum is usually weighted by a constant. However, tuning hyperparameters for momentum can be computationally complex. In this paper, we propose a novel adaptive momentum for fast and stable convergence. METHOD: Applying adaptive momentum rate proposes increasing or decreasing based on every epoch's error changes, and it eliminates the need for momentum hyperparameter optimization. We tested the proposed method with 3 different datasets: REMBRANDT Brain Cancer, NIH Chest X-ray, COVID-19 CT scan. We compared the performance of a novel adaptive momentum optimizer with Stochastic gradient descent (SGD) and other adaptive optimizers such as Adam and RMSprop. RESULTS: Proposed method improves SGD performance by reducing classification error from 6.12 to 5.44%, and it achieved the lowest error and highest accuracy compared with other optimizers. To strengthen the outcomes of this study, we investigated the performance comparison for the state-of-the-art CNN architectures with adaptive momentum. The results shows that the proposed method achieved the highest with 95% compared to state-of-the-art CNN architectures while using the same dataset. The proposed method improves convergence performance by reducing classification error and achieves high accuracy compared with other optimizers.",Journal Article,
35204388,10.3390/diagnostics12020298,Deep Learning Applications in Computed Tomography Images for Pulmonary Nodule Detection and Diagnosis: A Review.,2022 Jan 25,"Diagnostics (Basel, Switzerland)","Li R, Xiao C, Huang Y, Hassan H, Huang B","deep learning, lung cancer, lung nodule computer-aided diagnosis, lung nodule segmentation and classification","Lung cancer has one of the highest mortality rates of all cancers and poses a severe threat to people's health. Therefore, diagnosing lung nodules at an early stage is crucial to improving patient survival rates. Numerous computer-aided diagnosis (CAD) systems have been developed to detect and classify such nodules in their early stages. Currently, CAD systems for pulmonary nodules comprise data acquisition, pre-processing, lung segmentation, nodule detection, false-positive reduction, segmentation, and classification. A number of review articles have considered various components of such systems, but this review focuses on segmentation and classification parts. Specifically, categorizing segmentation parts based on lung nodule type and network architectures, i.e., general neural network and multiview convolution neural network (CNN) architecture. Moreover, this work organizes related literature for classification of parts based on nodule or non-nodule and benign or malignant. The essential CT lung datasets and evaluation metrics used in the detection and diagnosis of lung nodules have been systematically summarized as well. Thus, this review provides a baseline understanding of the topic for interested readers.","Journal Article, Review",
35197087,10.1186/s13014-022-02012-7,Development of AI-driven prediction models to realize real-time tumor tracking during radiotherapy.,2022 Feb 23,"Radiation oncology (London, England)","Zhou D, Nakamura M, Mukumoto N, Tanabe H, Iizuka Y, Yoshimura M, Kokubo M, Matsuo Y, Mizowaki T","*Artificial Intelligence, Computer Simulation, Computer Systems, Forecasting, Humans, Liver Neoplasms/*radiotherapy, Lung Neoplasms/*radiotherapy, *Neural Networks, Computer, Pancreatic Neoplasms/*radiotherapy, Adaptive neuro-fuzzy inference system, Convolutional neural network, Real-time tumor tracking, Tumor motion prediction","BACKGROUND: In infrared reflective (IR) marker-based hybrid real-time tumor tracking (RTTT), the internal target position is predicted with the positions of IR markers attached on the patient's body surface using a prediction model. In this work, we developed two artificial intelligence (AI)-driven prediction models to improve RTTT radiotherapy, namely, a convolutional neural network (CNN) and an adaptive neuro-fuzzy inference system (ANFIS) model. The models aim to improve the accuracy in predicting three-dimensional tumor motion. METHODS: From patients whose respiration-induced motion of the tumor, indicated by the fiducial markers, exceeded 8 mm, 1079 logfiles of IR marker-based hybrid RTTT (IR Tracking) with the gimbal-head radiotherapy system were acquired and randomly divided into two datasets. All the included patients were breathing freely with more than four external IR markers. The historical dataset for the CNN model contained 1003 logfiles, while the remaining 76 logfiles complemented the evaluation dataset. The logfiles recorded the external IR marker positions at a frequency of 60 Hz and fiducial markers as surrogates for the detected target positions every 80-640 ms for 20-40 s. For each logfile in the evaluation dataset, the prediction models were trained based on the data in the first three quarters of the recording period. In the last quarter, the performance of the patient-specific prediction models was tested and evaluated. The overall performance of the AI-driven prediction models was ranked by the percentage of predicted target position within 2 mm of the detected target position. Moreover, the performance of the AI-driven models was compared to a regression prediction model currently implemented in gimbal-head radiotherapy systems. RESULTS: The percentage of the predicted target position within 2 mm of the detected target position was 95.1%, 92.6% and 85.6% for the CNN, ANFIS, and regression model, respectively. In the evaluation dataset, the CNN, ANFIS, and regression model performed best in 43, 28 and 5 logfiles, respectively. CONCLUSIONS: The proposed AI-driven prediction models outperformed the regression prediction model, and the overall performance of the CNN model was slightly better than that of the ANFIS model on the evaluation dataset.",Journal Article,
35188835,10.1177/15330338211073380,Deep Learning-Based Internal Target Volume (ITV) Prediction Using Cone-Beam CT Images in Lung Stereotactic Body Radiotherapy.,2022 Jan-Dec,Technology in cancer research & treatment,"Li Z, Zhang S, Zhang L, Li Y, Zheng X, Fu J, Qiu J","Cone-Beam Computed Tomography/methods, *Deep Learning, Four-Dimensional Computed Tomography/methods, Humans, Lung/pathology, *Lung Neoplasms/diagnostic imaging/radiotherapy/surgery, *Radiosurgery/methods, Radiotherapy Planning, Computer-Assisted/methods, Respiration, *4DCT, *CBCT, *Mask R-CNN, *SBRT, *deep learning","Purpose:This study aims to develop a deep learning (DL)-based (Mask R-CNN) method to predict the internal target volume (ITV) in cone beam computed tomography (CBCT) images for lung stereotactic body radiotherapy (SBRT) patients and to evaluate the prediction accuracy of the model using 4DCT as ground truth. Methods and Materials: This study enrolled 78 phantom cases and 156 patient cases who received SBRT treatment. We used a novel DL model (Mask R-CNN) to identify and delineate lung tumor ITV in CBCT images. The results of the DL-based method were compared quantitatively with the ground truth (4DCT) using 4 metrics, including Dice Similarity Coefficient (DSC), Relative Volume Index (RVI), 3D Motion Range (R3D), and Hausdorff Surface Distance (HD). Paired t-tests were used to determine the differences between the DL-based method and manual contouring. Results: The DSC value for 4DCTMIP versus CBCT is 0.86 +/- 0.16 and for 4DCTAVG versus CBCT is 0.83 +/- 0.18, indicating a high similarity of tumor delineation in CBCT and 4DCT. The mean Accuracy Precision (mAP), R3D, RVI, and HD values for phantom evaluation are 0.94 +/- 0.04, 1.37 +/- 0.36, 0.79 +/- 0.02, and 6.79 +/- 0.68, respectively. For patient evaluation, the mAP, R3D, RVI, and HD achieved averaged values of 0.74 +/- 0.23, 2.39 +/- 1.59, 1.27 +/- 0.47, and 17.00 +/- 19.89, respectively. These results showed a good correlation between predicted ITV and manually contoured ITV. The phantom p-value for RVI, R3D, and HD are 0.75, 0.08, 0.86, and patient p-value are 0.53, 0.07, 0.28, respectively. These p-values for phantom and patient showed no significant difference between the predicted ITV and physician's manual contouring. Conclusion:The current improved method (Mask R-CNN) yielded a good similarity between predicted ITV in CBCT and the manual contouring in 4DCT, thus indicating great potential for using CBCT for patient ITV contouring.","Journal Article, Research Support, Non-U.S. Gov't",
35176595,10.1016/j.cmpb.2022.106680,Pulmonary nodules detection assistant platform: An effective computer aided system for early pulmonary nodules detection in physical examination.,2022 Apr,Computer methods and programs in biomedicine,"Han Y, Qi H, Wang L, Chen C, Miao J, Xu H, Wang Z, Guo Z, Xu Q, Lin Q, Liu H, Lu J, Liang F, Feng W, Li H, Liu Y","Early Detection of Cancer, Humans, *Lung Neoplasms/diagnostic imaging, *Multiple Pulmonary Nodules/diagnostic imaging, Physical Examination, Radiographic Image Interpretation, Computer-Assisted/methods, Sensitivity and Specificity, *Solitary Pulmonary Nodule/diagnostic imaging, Tomography, X-Ray Computed/methods, Classification of pulmonary nodules, Computer aided detection system, Deep learning, Early pulmonary nodules detection, Low-Dose computer tomography (LDCT)","BACKGROUND AND OBJECTIVE: Early detection of the pulmonary nodule from physical examination low-dose computer tomography (LDCT) images is an effective measure to reduce the mortality rate of lung cancer. Although there are many computer aided diagnosis (CAD) methods used for detecting pulmonary nodules, there are few CAD systems for small pulmonary nodule detection with a large amount of physical examination LDCT images. METHODS: In this work, we designed a CAD system called Pulmonary Nodules Detection Assistant Platform for early pulmonary nodules detection and classification based on the physical examination LDCT images. Based on the preprocessed physical examination CT images, the three-dimensional (3D) CNN-based model is presented to detect candidate pulmonary nodules and output detection results with quantitative parameters, the 3D ResNet is used to classify the detected nodules into intrapulmonary nodules and pleural nodules to reduce the physician workloads, and the Fully Connected Neural Network (FCNN) is used to classify ground-glass opacity (GGO) nodules and non-GGO nodules to help doctor pay more attention to those suspected early lung cancer nodules. RESULTS: Experiments are performed on our 1000 samples of physical examinations (LNPE1000) with an average diameter of 5.3 mm and LUNA16 dataset with an average diameter of 8.31 mm, which show that the designed CAD system is automatic and efficient for detecting smaller and larger nodules from different datasets, especially for the detection of smaller nodules with diameter between 3 mm and 6 mm in physical examinations. The accuracy of pulmonary nodule detection reaches 0.879 with an average of 1 false positive per CT in LNPE1000 dataset, which is comparable to the experienced physicians. The classification accuracy reaches 0.911 between intrapulmonary and pleural nodules, and 0.950 between GGO and non-GGO nodules, respectively. CONCLUSION: Experimental results show that the proposed pulmonary nodule detection model is robust for different datasets, which can successfully detect smaller and larger nodules in CT images obtained by physical examination. The interactive platform of the designed CAD system has been on trial in a hospital by combining with manual reading, which helps doctors analyze clinical data dynamically and improves the nodule detection efficiency in physical examination applications.",Journal Article,"Declaration of Competing Interest We declare that we have no financial and personal relationships with other people or organizations that can inappropriately influence our work, there is no professional or other personal interest of any nature or kind in any product, service and/or company that could be construed as influencing the position presented in, or the review of, the manuscript entitled ""Pulmonary Nodules Detection Assistant Platform: An Effective Computer Aided System for Early Pulmonary Nodules Detection in Physical Examination""."
35172253,10.1016/j.cmpb.2021.106592,Analysis of high-resolution reconstruction of medical images based on deep convolutional neural networks in lung cancer diagnostics.,2022 Apr,Computer methods and programs in biomedicine,"Bai Y, Li D, Duan Q, Chen X","Humans, Image Processing, Computer-Assisted, *Lung Neoplasms/diagnostic imaging, *Neural Networks, Computer, Retrospective Studies, Thorax, Tomography, X-Ray Computed, 64-Row spiral, Convolutional neural network, Deep learning, Lung cancer, MRI","BACKGROUND AND OBJECTIVE: To study the diagnostic effect of 64-slice spiral CT and MRI high-resolution images based on deep convolutional neural networks(CNN) in lung cancer. METHODS: In this paper, we Select 74 patients with highly suspected lung cancer who were treated in our hospital from January 2017 to January 2021 as the research objects. The enhanced 64-slice spiral CT and MRI were used to detect and diagnose respectively, and the images and accuracy of CT diagnosis and MRI diagnosis were retrospectively analyzed. RESULTS: The accuracy of CT diagnosis is 94.6% (70/74), and the accuracy of MRI diagnosis is 89.2% (66/74). CT examination has the advantages of non-invasive, convenient operation and fast examination. MRI is showing there are advantages in the relationship between the chest wall and the mediastinum, and the relationship between the lesion and the large blood vessels. CONCLUSION: Enhanced CT and MRI examinations based on convolutional neural networks(CNN) to improve image clarity have high application value in the diagnosis of lung cancer patients, but the focus of performance is different.",Journal Article,Declaration of Competing Interest The authors declare no conflicts of interest.
35161552,10.3390/s22030807,Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion.,2022 Jan 21,"Sensors (Basel, Switzerland)","Jabeen K, Khan MA, Alhaisoni M, Tariq U, Zhang YD, Hamza A, Mickus A, Damasevicius R","Breast, *Breast Neoplasms/diagnostic imaging, *Deep Learning, Female, Humans, Probability, Ultrasonography, Mammary, breast cancer, classification, data augmentation, deep learning, feature optimization","After lung cancer, breast cancer is the second leading cause of death in women. If breast cancer is detected early, mortality rates in women can be reduced. Because manual breast cancer diagnosis takes a long time, an automated system is required for early cancer detection. This paper proposes a new framework for breast cancer classification from ultrasound images that employs deep learning and the fusion of the best selected features. The proposed framework is divided into five major steps: (i) data augmentation is performed to increase the size of the original dataset for better learning of Convolutional Neural Network (CNN) models; (ii) a pre-trained DarkNet-53 model is considered and the output layer is modified based on the augmented dataset classes; (iii) the modified model is trained using transfer learning and features are extracted from the global average pooling layer; (iv) the best features are selected using two improved optimization algorithms known as reformed differential evaluation (RDE) and reformed gray wolf (RGW); and (v) the best selected features are fused using a new probability-based serial approach and classified using machine learning algorithms. The experiment was conducted on an augmented Breast Ultrasound Images (BUSI) dataset, and the best accuracy was 99.1%. When compared with recent techniques, the proposed framework outperforms them.",Journal Article,
35146436,10.1148/ryai.210105,Improved Detection of Chronic Obstructive Pulmonary Disease at Chest CT Using the Mean Curvature of Isophotes.,2022 Jan,Radiology. Artificial intelligence,"Savadjiev P, Gallix B, Rezanejad M, Bhatnagar S, Semionov A, Siddiqi K, Forghani R, Reinhold C, Eidelman DH, Dandurand RJ","CT, Chronic Obstructive Pulmonary Disease, Lung, Quantification","PURPOSE: To determine if the mean curvature of isophotes (MCI), a standard computer vision technique, can be used to improve detection of chronic obstructive pulmonary disease (COPD) at chest CT. MATERIALS AND METHODS: In this retrospective study, chest CT scans were obtained in 243 patients with COPD and 31 controls (among all 274: 151 women [mean age, 70 years; range, 44-90 years] and 123 men [mean age, 71 years; range, 29-90 years]) from two community practices between 2006 and 2019. A convolutional neural network (CNN) architecture was trained on either CT images or CT images transformed through the MCI algorithm. Separately, a linear classification based on a single feature derived from the MCI computation (called hMCI1) was also evaluated. All three models were evaluated with cross-validation, using precision-macro and recall-macro metrics, that is, the mean of per-class precision and recall values, respectively (the latter being equivalent to balanced accuracy). RESULTS: Linear classification based on hMCI1 resulted in a higher recall-macro relative to the CNN trained and applied on CT images (0.85 [95% CI: 0.84, 0.86] vs 0.77 [95% CI: 0.75, 0.79]) but with a similar reduction in precision-macro (0.66 [95% CI: 0.65, 0.67] vs 0.77 [95% CI: 0.75, 0.79]). The CNN model trained and applied on MCI-transformed images had a higher recall-macro (0.85 [95% CI: 0.83, 0.87] vs 0.77 [95% CI: 0.75, 0.79]) and precision-macro (0.85 [95% CI: 0.83, 0.87] vs 0.77 [95% CI: 0.75, 0.79]) relative to the CNN trained and applied on CT images. CONCLUSION: The MCI algorithm may be valuable toward the automated detection and diagnosis of COPD on chest CT scans as part of a CNN-based pipeline or with stand-alone features.Keywords: Chronic Obstructive Pulmonary Disease, Quantification, Lung, CT Supplemental material is available for this article. See also the invited commentary by Vannier in this issue.(c) RSNA, 2021.",Journal Article,"Disclosures of conflicts of interest: P.S. Patent application (https://patents.google.com/patent/US20190392579A1/) under review, author is coinventor. B.G. Patent application (https://patents.google.com/patent/US20190392579A1/) under review. M.R. Funding for PhD studies from McGill University (School of Computer Science) under supervision of K.S.; Arts and Science postdoctoral fellowship from the University of Toronto; author's contribution to this work mainly from author's time as a PhD student at McGill University. S.B. No relevant relationships. A.S. No relevant relationships. K.S. Patent application (https://patents.google.com/patent/US20190392579A1/) under review. R.F. Clinical research scholar (chercheur-boursier clinicien) supported by the Fonds de recherche en sante du Quebec (FRQS) and has an operating grant jointly funded by the FRQS and the Fondation de l'Association des radiologistes du Quebec (FARQ); payment or honoraria from GE Healthcare (dual-energy CT, AI); method and system of performing medical treatment outcome assessment or medical condition diagnostic, contributor (5%), patent pending US20190392579A1. C.R. Contributor to patent (https://patents.google.com/patent/US20190392579A1/). D.H.E. No relevant relationships. R.J.D. Contributor to patent (https://patents.google.com/patent/US20190392579A1/)."
35146434,10.1148/ryai.210080,A Fully Automated Deep Learning Pipeline for Multi-Vertebral Level Quantification and Characterization of Muscle and Adipose Tissue on Chest CT Scans.,2022 Jan,Radiology. Artificial intelligence,"Bridge CP, Best TD, Wrobel MM, Marquardt JP, Magudia K, Javidan C, Chung JH, Kalpathy-Cramer J, Andriole KP, Fintelmann FJ","Adipose Tissue, Body Composition Analysis, CT, Chest, Convolutional Neural Network (CNN), Skeletal Muscle, Supervised Learning","Body composition on chest CT scans encompasses a set of important imaging biomarkers. This study developed and validated a fully automated analysis pipeline for multi-vertebral level assessment of muscle and adipose tissue on routine chest CT scans. This study retrospectively trained two convolutional neural networks on 629 chest CT scans from 629 patients (55% women; mean age, 67 years +/- 10 [standard deviation]) obtained between 2014 and 2017 prior to lobectomy for primary lung cancer at three institutions. A slice-selection network was developed to identify an axial image at the level of the fifth, eighth, and 10th thoracic vertebral bodies. A segmentation network (U-Net) was trained to segment muscle and adipose tissue on an axial image. Radiologist-guided manual-level selection and segmentation generated ground truth. The authors then assessed the predictive performance of their approach for cross-sectional area (CSA) (in centimeters squared) and attenuation (in Hounsfield units) on an independent test set. For the pipeline, median absolute error and intraclass correlation coefficients for both tissues were 3.6% (interquartile range, 1.3%-7.0%) and 0.959-0.998 for the CSA and 1.0 HU (interquartile range, 0.0-2.0 HU) and 0.95-0.99 for median attenuation. This study demonstrates accurate and reliable fully automated multi-vertebral level quantification and characterization of muscle and adipose tissue on routine chest CT scans. Keywords: Skeletal Muscle, Adipose Tissue, CT, Chest, Body Composition Analysis, Convolutional Neural Network (CNN), Supervised Learning Supplemental material is available for this article. (c) RSNA, 2022.",Journal Article,"Disclosures of conflicts of interest: C.P.B. Support from the MGH and BWH Center for Clinical Data Science (CCDS) for travel to conferences. The CCDS in turn receives support from GE Healthcare, Nuance Communications, Nvidia, Diagnostico da America S.A., and Fujifilm Sonosite; US Patent applications pending for: Computed Tomography Medical Imaging Intracranial Hemorrhage Model (US Patent Application 16/587,828). In collaboration with GE Healthcare and Medical Imaging Stroke Model (US Patent Application 16/588,080). In collaboration with GE Healthcare. T.D.B. No relevant relationships. M.M.W. No relevant relationships. J.P.M. No relevant relationships. K.M. Former trainee editorial board member for Radiology: Artificial Intelligence. C.J. No relevant relationships. J.H.C. Editorial board member of Radiology: Cardiothoracic Imaging. J.K.C. Deputy editor of Radiology: Artificial Intelligence. K.P.A. A Mobile Health Diagnostic Device for HIV Self-Testing NIH 1R61 AI140489-01A1 PI: Shafiee, Andriole, Co-Investigator, Study goals are to develop a hand-held device for HIV self-testing using artificial intelligence algorithms for data analysis. 8/2019-7/2022; associate editor of Radiology: Artificial Intelligence. F.J.F. American Roentgen Ray Society scholarship grant (related to this work); grant from William M. Wood Foundation (not related to this work); grant form Society of Interventional Oncology (unrelated to this work); research support from Boston Scientific (unrelated to this work); patents related to body composition analysis."
35144242,10.1088/2057-1976/ac53bd,A few-shot U-Net deep learning model for lung cancer lesion segmentation via PET/CT imaging.,2022 Feb 18,Biomedical physics & engineering express,"Protonotarios NE, Katsamenis I, Sykiotis S, Dikaios N, Kastis GA, Chatziioannou SN, Metaxas M, Doulamis N, Doulamis A","*Deep Learning, Fluorodeoxyglucose F18, Humans, *Lung Neoplasms/diagnostic imaging, Positron Emission Tomography Computed Tomography, Tomography, X-Ray Computed, *PET/CT, *U-Net architectures, *convolutional neural networks (CNN), *deep learning, *few-shot learning, *lung cancer lesion segmentation","Over the past few years, positron emission tomography/computed tomography (PET/CT) imaging for computer-aided diagnosis has received increasing attention. Supervised deep learning architectures are usually employed for the detection of abnormalities, with anatomical localization, especially in the case of CT scans. However, the main limitations of the supervised learning paradigm include (i) large amounts of data required for model training, and (ii) the assumption of fixed network weights upon training completion, implying that the performance of the model cannot be further improved after training. In order to overcome these limitations, we apply a few-shot learning (FSL) scheme. Contrary to traditional deep learning practices, in FSL the model is provided with less data during training. The model then utilizes end-user feedback after training to constantly improve its performance. We integrate FSL in a U-Net architecture for lung cancer lesion segmentation on PET/CT scans, allowing for dynamic model weight fine-tuning and resulting in an online supervised learning scheme. Constant online readjustments of the model weights according to the users' feedback, increase the detection and classification accuracy, especially in cases where low detection performance is encountered. Our proposed method is validated on the Lung-PET-CT-DX TCIA database. PET/CT scans from 87 patients were included in the dataset and were acquired 60 minutes after intravenous(18)F-FDG injection. Experimental results indicate the superiority of our approach compared to other state-of-the-art methods.","Journal Article, Research Support, Non-U.S. Gov't",
35125924,10.1007/s11042-021-11748-5,Diagnosis of hypercritical chronic pulmonary disorders using dense convolutional network through chest radiography.,2022,Multimedia tools and applications,"Mehrotra R, Agrawal R, Ansari MA","CNN, COVID-19, Chest x-ray (CXR), Chronic pulmonary disorders, Deep learning, Pneumonia","Lung-related ailments are prevalent all over the world which majorly includes asthma, chronic obstructive pulmonary disease (COPD), tuberculosis, pneumonia, fibrosis, etc. and now COVID-19 is added to this list. Infection of COVID-19 poses respirational complications with other indications like cough, high fever, and pneumonia. WHO had identified cancer in the lungs as a fatal cancer type amongst others and thus, the timely detection of such cancer is pivotal for an individual's health. Since the elementary convolutional neural networks have not performed fairly well in identifying atypical image types hence, we recommend a novel and completely automated framework with a deep learning approach for the recognition and classification of chronic pulmonary disorders (CPD) and COVID-pneumonia using Thoracic or Chest X-Ray (CXR) images. A novel three-step, completely automated, approach is presented that first extracts the region of interest from CXR images for preprocessing, and they are then used to detects infected lungs X-rays from the Normal ones. Thereafter, the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD), which might be utilized in the current scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases. And finally, highlight the regions in the CXR which are indicative of severe chronic pulmonary disorders like COVID-19 and pneumonia. A detailed investigation of various pivotal parameters based on several experimental outcomes are made here. This paper presents an approach that detects the Normal lung X-rays from infected ones and the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders with an utmost accuracy of 96.8%. Several other collective performance measurements validate the superiority of the presented model. The proposed framework shows effective results in classifying lung images into Normal, COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD). This framework can be effectively utilized in this current pandemic scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases.",Journal Article,
35115593,10.1038/s41598-022-05709-7,Classification of subtypes including LCNEC in lung cancer biopsy slides using convolutional neural network from scratch.,2022 Feb 3,Scientific reports,"Yang JW, Song DH, An HJ, Seo SB","Adenocarcinoma of Lung/classification/*diagnosis/pathology, Area Under Curve, Biopsy, Carcinoma, Non-Small-Cell Lung/classification/*diagnosis/pathology, Carcinoma, Squamous Cell/classification/*diagnosis/pathology, Datasets as Topic, Eosine Yellowish-(YS), Hematoxylin, Histocytochemistry/statistics & numerical data, Humans, Image Interpretation, Computer-Assisted/statistics & numerical data, Lung/pathology, Lung Neoplasms/classification/*diagnosis/pathology, *Neural Networks, Computer, Small Cell Lung Carcinoma/classification/*diagnosis/pathology","Identifying the lung carcinoma subtype in small biopsy specimens is an important part of determining a suitable treatment plan but is often challenging without the help of special and/or immunohistochemical stains. Pathology image analysis that tackles this issue would be helpful for diagnoses and subtyping of lung carcinoma. In this study, we developed AI models to classify multinomial patterns of lung carcinoma; ADC, LCNEC, SCC, SCLC, and non-neoplastic lung tissue based on convolutional neural networks (CNN or ConvNet). Four CNNs that were pre-trained using transfer learning and one CNN built from scratch were used to classify patch images from pathology whole-slide images (WSIs). We first evaluated the diagnostic performance of each model in the test sets. The Xception model and the CNN built from scratch both achieved the highest performance with a macro average AUC of 0.90. The CNN built from scratch model obtained a macro average AUC of 0.97 on the dataset of four classes excluding LCNEC, and 0.95 on the dataset of three subtypes of lung carcinomas; NSCLC, SCLC, and non-tumor, respectively. Of particular note is that the relatively simple CNN built from scratch may be an approach for pathological image analysis.","Journal Article, Research Support, Non-U.S. Gov't",
35113252,10.1186/s40658-022-00437-3,Freely available convolutional neural network-based quantification of PET/CT lesions is associated with survival in patients with lung cancer.,2022 Feb 3,EJNMMI physics,"Borrelli P, Gongora JLL, Kaboteh R, Ulen J, Enqvist O, Tragardh E, Edenbrandt L","Computer-assisted analysis, Prognosis, Total lesion glycolysis, Tumour burden","BACKGROUND: Metabolic positron emission tomography/computed tomography (PET/CT) parameters describing tumour activity contain valuable prognostic information, but to perform the measurements manually leads to both intra- and inter-reader variability and is too time-consuming in clinical practice. The use of modern artificial intelligence-based methods offers new possibilities for automated and objective image analysis of PET/CT data. PURPOSE: We aimed to train a convolutional neural network (CNN) to segment and quantify tumour burden in [(18)F]-fluorodeoxyglucose (FDG) PET/CT images and to evaluate the association between CNN-based measurements and overall survival (OS) in patients with lung cancer. A secondary aim was to make the method available to other researchers. METHODS: A total of 320 consecutive patients referred for FDG PET/CT due to suspected lung cancer were retrospectively selected for this study. Two nuclear medicine specialists manually segmented abnormal FDG uptake in all of the PET/CT studies. One-third of the patients were assigned to a test group. Survival data were collected for this group. The CNN was trained to segment lung tumours and thoracic lymph nodes. Total lesion glycolysis (TLG) was calculated from the CNN-based and manual segmentations. Associations between TLG and OS were investigated using a univariate Cox proportional hazards regression model. RESULTS: The test group comprised 106 patients (median age, 76 years (IQR 61-79); n = 59 female). Both CNN-based TLG (hazard ratio 1.64, 95% confidence interval 1.21-2.21; p = 0.001) and manual TLG (hazard ratio 1.54, 95% confidence interval 1.14-2.07; p = 0.004) estimations were significantly associated with OS. CONCLUSION: Fully automated CNN-based TLG measurements of PET/CT data showed were significantly associated with OS in patients with lung cancer. This type of measurement may be of value for the management of future patients with lung cancer. The CNN is publicly available for research purposes.",Journal Article,
35096609,10.3389/fonc.2021.805911,Apparent Diffusion Coefficient-Based Convolutional Neural Network Model Can Be Better Than Sole Diffusion-Weighted Magnetic Resonance Imaging to Improve the Differentiation of Invasive Breast Cancer From Breast Ductal Carcinoma In Situ.,2021,Frontiers in oncology,"Yin H, Jiang Y, Xu Z, Huang W, Chen T, Lin G","breast cancer, deep learning, diffusion-weighted imaging, ductal carcinoma in situ, magnetic resonance imaging","BACKGROUND AND PURPOSE: Breast ductal carcinoma in situ (DCIS) has no metastatic potential, and has better clinical outcomes compared with invasive breast cancer (IBC). Convolutional neural networks (CNNs) can adaptively extract features and may achieve higher efficiency in apparent diffusion coefficient (ADC)-based tumor invasion assessment. This study aimed to determine the feasibility of constructing an ADC-based CNN model to discriminate DCIS from IBC. METHODS: The study retrospectively enrolled 700 patients with primary breast cancer between March 2006 and June 2019 from our hospital, and randomly selected 560 patients as the training and validation sets (ratio of 3 to 1), and 140 patients as the internal test set. An independent external test set of 102 patients during July 2019 and May 2021 from a different scanner of our hospital was selected as the primary cohort using the same criteria. In each set, the status of tumor invasion was confirmed by pathologic examination. The CNN model was constructed to discriminate DCIS from IBC using the training and validation sets. The CNN model was evaluated using the internal and external tests, and compared with the discriminating performance using the mean ADC. The area under the curve (AUC), sensitivity, specificity, and accuracy were calculated to evaluate the performance of the previous model. RESULTS: The AUCs of the ADC-based CNN model using the internal and external test sets were larger than those of the mean ADC (AUC: 0.977 vs. 0.866, P = 0.001; and 0.926 vs. 0.845, P = 0.096, respectively). Regarding the internal test set and external test set, the ADC-based CNN model yielded sensitivities of 0.893 and 0.873, specificities of 0.929 and 0.894, and accuracies of 0.907 and 0.902, respectively. Regarding the two test sets, the mean ADC showed sensitivities of 0.845 and 0.818, specificities of 0.821 and 0.829, and accuracies of 0.836 and 0.824, respectively. Using the ADC-based CNN model, the prediction only takes approximately one second for a single lesion. CONCLUSION: The ADC-based CNN model can improve the differentiation of IBC from DCIS with higher accuracy and less time.",Journal Article,The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.
35087078,10.1038/s41598-022-05372-y,Pulmonary nodules detection based on multi-scale attention networks.,2022 Jan 27,Scientific reports,"Zhang H, Peng Y, Guo Y","Datasets as Topic, *Deep Learning, Early Detection of Cancer/*methods, Humans, Imaging, Three-Dimensional, Lung/*diagnostic imaging/pathology, Multiple Pulmonary Nodules/*diagnosis/pathology, Radiographic Image Interpretation, Computer-Assisted/*methods, Tomography, X-Ray Computed/methods","Pulmonary nodules are the main manifestation of early lung cancer. Therefore, accurate detection of nodules in CT images is vital for lung cancer diagnosis. A 3D automatic detection system of pulmonary nodules based on multi-scale attention networks is proposed in this paper to use multi-scale features of nodules and avoid network over-fitting problems. The system consists of two parts, nodule candidate detection (determining the locations of candidate nodules), false positive reduction (minimizing the number of false positive nodules). Specifically, with Res2Net structure, using pre-activation operation and convolutional quadruplet attention module, the 3D multi-scale attention block is designed. It makes full use of multi-scale information of pulmonary nodules by extracting multi-scale features at a granular level and alleviates over-fitting by pre-activation. The U-Net-like encoder-decoder structure is combined with multi-scale attention blocks as the backbone network of Faster R-CNN for detection of candidate nodules. Then a 3D deep convolutional neural network based on multi-scale attention blocks is designed for false positive reduction. The extensive experiments on LUNA16 and TianChi competition datasets demonstrate that the proposed approach can effectively improve the detection sensitivity and control the number of false positive nodules, which has clinical application value.","Journal Article, Research Support, Non-U.S. Gov't",
35068705,10.1007/s00530-021-00878-3,"BDCNet: multi-classification convolutional neural network model for classification of COVID-19, pneumonia, and lung cancer from chest radiographs.",2022,Multimedia systems,"Malik H, Anees T, Mui-Zzud-Din","COVID-19, Chest radiographs, Coronavirus, Deep learning","Globally, coronavirus disease (COVID-19) has badly affected the medical system and economy. Sometimes, the deadly COVID-19 has the same symptoms as other chest diseases such as pneumonia and lungs cancer and can mislead the doctors in diagnosing coronavirus. Frontline doctors and researchers are working assiduously in finding the rapid and automatic process for the detection of COVID-19 at the initial stage, to save human lives. However, the clinical diagnosis of COVID-19 is highly subjective and variable. The objective of this study is to implement a multi-classification algorithm based on deep learning (DL) model for identifying the COVID-19, pneumonia, and lung cancer diseases from chest radiographs. In the present study, we have proposed a model with the combination of Vgg-19 and convolutional neural networks (CNN) named BDCNet and applied it on different publically available benchmark databases to diagnose the COVID-19 and other chest tract diseases. To the best of our knowledge, this is the first study to diagnose the three chest diseases in a single deep learning model. We also computed and compared the classification accuracy of our proposed model with four well-known pre-trained models such as ResNet-50, Vgg-16, Vgg-19, and inception v3. Our proposed model achieved an AUC of 0.9833 (with an accuracy of 99.10%, a recall of 98.31%, a precision of 99.9%, and an f1-score of 99.09%) in classifying the different chest diseases. Moreover, CNN-based pre-trained models VGG-16, VGG-19, ResNet-50, and Inception-v3 achieved an accuracy of classifying multi-diseases are 97.35%, 97.14%, 97.15%, and 95.10%, respectively. The results revealed that our proposed model produced a remarkable performance as compared to its competitor approaches, thus providing significant assistance to diagnostic radiographers and health experts.",Journal Article,Conflict of interestThe authors declare no conflict of interest.
35049843,10.3390/jimaging8010002,Effectiveness of Learning Systems from Common Image File Types to Detect Osteosarcoma Based on Convolutional Neural Networks (CNNs) Models.,2021 Dec 27,Journal of imaging,"Loraksa C, Mongkolsomlit S, Nimsuk N, Uscharapong M, Kiatisevi P","Convolutional Neural Networks, bone cancer, common image file, computer-aided diagnosis, osteosarcoma","Osteosarcoma is a rare bone cancer which is more common in children than in adults and has a high chance of metastasizing to the patient's lungs. Due to initiated cases, it is difficult to diagnose and hard to detect the nodule in a lung at the early state. Convolutional Neural Networks (CNNs) are effectively applied for early state detection by considering CT-scanned images. Transferring patients from small hospitals to the cancer specialized hospital, Lerdsin Hospital, poses difficulties in information sharing because of the privacy and safety regulations. CD-ROM media was allowed for transferring patients' data to Lerdsin Hospital. Digital Imaging and Communications in Medicine (DICOM) files cannot be stored on a CD-ROM. DICOM must be converted into other common image formats, such as BMP, JPG and PNG formats. Quality of images can affect the accuracy of the CNN models. In this research, the effect of different image formats is studied and experimented. Three popular medical CNN models, VGG-16, ResNet-50 and MobileNet-V2, are considered and used for osteosarcoma detection. The positive and negative class images are corrected from Lerdsin Hospital, and 80% of all images are used as a training dataset, while the rest are used to validate the trained models. Limited training images are simulated by reducing images in the training dataset. Each model is trained and validated by three different image formats, resulting in 54 testing cases. F1-Score and accuracy are calculated and compared for the models' performance. VGG-16 is the most robust of all the formats. PNG format is the most preferred image format, followed by BMP and JPG formats, respectively.",Journal Article,
35047635,10.1155/2022/4185835,Cloud-Based Lung Tumor Detection and Stage Classification Using Deep Learning Techniques.,2022,BioMed research international,"Kasinathan G, Jayakumar S","*Cloud Computing, *Databases, Factual, *Deep Learning, Humans, Lung Neoplasms/*diagnostic imaging, Neoplasm Staging, *Positron Emission Tomography Computed Tomography, *Radiographic Image Interpretation, Computer-Assisted","Artificial intelligence (AI), Internet of Things (IoT), and the cloud computing have recently become widely used in the healthcare sector, which aid in better decision-making for a radiologist. PET imaging or positron emission tomography is one of the most reliable approaches for a radiologist to diagnosing many cancers, including lung tumor. In this work, we proposed stage classification of lung tumor which is a more challenging task in computer-aided diagnosis. As a result, a modified computer-aided diagnosis is being considered as a way to reduce the heavy workloads and second opinion to radiologists. In this paper, we present a strategy for classifying and validating different stages of lung tumor progression, as well as a deep neural model and data collection using cloud system for categorizing phases of pulmonary illness. The proposed system presents a Cloud-based Lung Tumor Detector and Stage Classifier (Cloud-LTDSC) as a hybrid technique for PET/CT images. The proposed Cloud-LTDSC initially developed the active contour model as lung tumor segmentation, and multilayer convolutional neural network (M-CNN) for classifying different stages of lung cancer has been modelled and validated with standard benchmark images. The performance of the presented technique is evaluated using a benchmark image LIDC-IDRI dataset of 50 low doses and also utilized the lung CT DICOM images. Compared with existing techniques in the literature, our proposed method achieved good result for the performance metrics accuracy, recall, and precision evaluated. Under numerous aspects, our proposed approach produces superior outcomes on all of the applied dataset images. Furthermore, the experimental result achieves an average lung tumor stage classification accuracy of 97%-99.1% and an average of 98.6% which is significantly higher than the other existing techniques.",Journal Article,The authors declare that there is no conflict of interest regarding the publication of this paper.
35003258,10.1155/2021/5499385,Deep Learning to Predict EGFR Mutation and PD-L1 Expression Status in Non-Small-Cell Lung Cancer on Computed Tomography Images.,2021,Journal of oncology,"Wang C, Xu X, Shao J, Zhou K, Zhao K, He Y, Li J, Guo J, Yi Z, Li W",,"OBJECTIVE: The detection of epidermal growth factor receptor (EGFR) mutation and programmed death ligand-1 (PD-L1) expression status is crucial to determine the treatment strategies for patients with non-small-cell lung cancer (NSCLC). Recently, the rapid development of radiomics including but not limited to deep learning techniques has indicated the potential role of medical images in the diagnosis and treatment of diseases. METHODS: Eligible patients diagnosed/treated at the West China Hospital of Sichuan University from January 2013 to April 2019 were identified retrospectively. The preoperative CT images were obtained, as well as the gene status regarding EGFR mutation and PD-L1 expression. Tumor region of interest (ROI) was delineated manually by experienced respiratory specialists. We used 3D convolutional neural network (CNN) with ROI information as input to construct a classification model and established a prognostic model combining deep learning features and clinical features to stratify survival risk of lung cancer patients. RESULTS: The whole cohort (N = 1262) was divided into a training set (N = 882, 70%), validation set (N = 125, 10%), and test set (N = 255, 20%). We used a 3D convolutional neural network (CNN) to construct a prediction model, with AUCs of 0.96 (95% CI: 0.94-0.98), 0.80 (95% CI: 0.72-0.88), and 0.73 (95% CI: 0.63-0.83) in the training, validation, and test cohorts, respectively. The combined prognostic model showed a good performance on survival prediction in NSCLC patients (C-index: 0.71). CONCLUSION: In this study, a noninvasive and effective model was proposed to predict EGFR mutation and PD-L1 expression status as a clinical decision support tool. Additionally, the combination of deep learning features with clinical features demonstrated great stratification capabilities in the prognostic model. Our team would continue to explore the application of imaging markers for treatment selection of lung cancer patients.",Journal Article,All authors have no conflicts of interest.
34970309,10.1155/2021/2392395,A Robust and Novel Approach for Brain Tumor Classification Using Convolutional Neural Network.,2021,Computational intelligence and neuroscience,"Tazin T, Sarker S, Gupta P, Ayaz F, Islam S, Monirujjaman Khan M, Bourouis S, Idris SA, Alshazly H","Brain, *Brain Neoplasms/diagnostic imaging, Humans, Male, Neural Networks, Computer, *Quality of Life, Reproducibility of Results","Brain tumors are the most common and aggressive illness, with a relatively short life expectancy in their most severe form. Thus, treatment planning is an important step in improving patients' quality of life. In general, image methods such as computed tomography (CT), magnetic resonance imaging (MRI), and ultrasound images are used to assess tumors in the brain, lung, liver, breast, prostate, and so on. X-ray images, in particular, are utilized in this study to diagnose brain tumors. This paper describes the investigation of the convolutional neural network (CNN) to identify brain tumors from X-ray images. It expedites and increases the reliability of the treatment. Because there has been a significant amount of study in this field, the presented model focuses on boosting accuracy while using a transfer learning strategy. Python and Google Colab were utilized to perform this investigation. Deep feature extraction was accomplished with the help of pretrained deep CNN models, VGG19, InceptionV3, and MobileNetV2. The classification accuracy is used to assess the performance of this paper. MobileNetV2 had the accuracy of 92%, InceptionV3 had the accuracy of 91%, and VGG19 had the accuracy of 88%. MobileNetV2 has offered the highest level of accuracy among these networks. These precisions aid in the early identification of tumors before they produce physical adverse effects such as paralysis and other impairments.",Journal Article,The authors declare that they have no conflicts of interest to report regarding the present study.
34958422,10.1007/s00259-021-05650-3,Quantitative imaging biomarkers of immune-related adverse events in immune-checkpoint blockade-treated metastatic melanoma patients: a pilot study.,2022 May,European journal of nuclear medicine and molecular imaging,"Hribernik N, Huff DT, Studen A, Zevnik K, Klanecek Z, Emamekhoo H, Skalic K, Jeraj R, Rebersek M","Biomarkers, Fluorodeoxyglucose F18, Humans, Immune Checkpoint Inhibitors/adverse effects, *Melanoma/diagnostic imaging/drug therapy, *Neoplasms, Second Primary, Pilot Projects, Positron Emission Tomography Computed Tomography/methods, Positron-Emission Tomography, Retrospective Studies, Skin Neoplasms, *18F-FDG PET/CT, *Immune-checkpoint inhibitors, *Immune-related adverse effects, *Quantitative imaging biomarkers","PURPOSE: To develop quantitative molecular imaging biomarkers of immune-related adverse event (irAE) development in malignant melanoma (MM) patients receiving immune-checkpoint inhibitors (ICI) imaged with (18)F-FDG PET/CT. METHODS: (18)F-FDG PET/CT images of 58 MM patients treated with anti-PD-1 or anti-CTLA-4 ICI were retrospectively analyzed for indication of irAE. Three target organs, most commonly affected by irAE, were considered: bowel, lung, and thyroid. Patient charts were reviewed to identify which patients experienced irAE, irAE grade, and time to irAE diagnosis. Target organs were segmented using a convolutional neural network (CNN), and novel quantitative imaging biomarkers - SUV percentiles (SUVX%) of (18)F-FDG uptake within the target organs - were correlated with the clinical irAE status. Area under the receiver-operating characteristic curve (AUROC) was used to quantify irAE detection performance. Patients who did not experience irAE were used to establish normal ranges for target organ (18)F-FDG uptake. RESULTS: A total of 31% (18/58) patients experienced irAE in the three target organs: bowel (n=6), lung (n=5), and thyroid (n=9). Optimal percentiles for identifying irAE were bowel (SUV95%, AUROC=0.79), lung (SUV95%, AUROC=0.98), and thyroid (SUV75%, AUROC=0.88). Optimal cut-offs for irAE detection were bowel (SUV95%>2.7 g/mL), lung (SUV95%>1.7 g/mL), and thyroid (SUV75%>2.1 g/mL). Normal ranges (95% confidence interval) for the SUV percentiles in patients without irAE were bowel [1.74, 2.86 g/mL], lung [0.73, 1.46 g/mL], and thyroid [0.86, 1.99 g/mL]. CONCLUSIONS: Increased (18)F-FDG uptake within irAE-affected organs provides predictive information about the development of irAE in MM patients receiving ICI and represents a potential quantitative imaging biomarker for irAE. Some irAE can be detected on (18)F-FDG PET/CT well before clinical symptoms appear.",Journal Article,
34941646,10.3390/tomography7040074,Convolutional Neural Network Addresses the Confounding Impact of CT Reconstruction Kernels on Radiomics Studies.,2021 Dec 3,"Tomography (Ann Arbor, Mich.)","Yoon JH, Sun SH, Xiao M, Yang H, Lu L, Li Y, Schwartz LH, Zhao B","Humans, *Lung Neoplasms/diagnostic imaging/genetics, Neural Networks, Computer, Reproducibility of Results, Tomography Scanners, X-Ray Computed, *Tomography, X-Ray Computed/methods, *computed tomography, *convolutional neural network, *kernel conversion, *quantitative imaging, *radiomics, *reproducibility","Achieving high feature reproducibility while preserving biological information is one of the main challenges for the generalizability of current radiomics studies. Non-clinical imaging variables, such as reconstruction kernels, have shown to significantly impact radiomics features. In this study, we retrain an open-source convolutional neural network (CNN) to harmonize computerized tomography (CT) images with various reconstruction kernels to improve feature reproducibility and radiomic model performance using epidermal growth factor receptor (EGFR) mutation prediction in lung cancer as a paradigm. In the training phase, the CNN was retrained and tested on 32 lung cancer patients' CT images between two different groups of reconstruction kernels (smooth and sharp). In the validation phase, the retrained CNN was validated on an external cohort of 223 lung cancer patients' CT images acquired using different CT scanners and kernels. The results showed that the retrained CNN could be successfully applied to external datasets with different CT scanner parameters, and harmonization of reconstruction kernels from sharp to smooth could significantly improve the performance of radiomics model in predicting EGFR mutation status in lung cancer. In conclusion, the CNN based method showed great potential in improving feature reproducibility and generalizability by harmonizing medical images with heterogeneous reconstruction kernels.","Journal Article, Research Support, N.I.H., Extramural",
34924632,10.1016/j.patcog.2021.108499,COVID-MTL: Multitask learning with Shift3D and random-weighted loss for COVID-19 diagnosis and severity assessment.,2022 Apr,Pattern recognition,"Bao G, Chen H, Liu T, Gong G, Yin Y, Wang L, Wang X","3D CNNs, COVID-19, Computer tomography, Deep learning, Diagnosis, Multitask learning, Severity assessment","There is an urgent need for automated methods to assist accurate and effective assessment of COVID-19. Radiology and nucleic acid test (NAT) are complementary COVID-19 diagnosis methods. In this paper, we present an end-to-end multitask learning (MTL) framework (COVID-MTL) that is capable of automated and simultaneous detection (against both radiology and NAT) and severity assessment of COVID-19. COVID-MTL learns different COVID-19 tasks in parallel through our novel random-weighted loss function, which assigns learning weights under Dirichlet distribution to prevent task dominance; our new 3D real-time augmentation algorithm (Shift3D) introduces space variances for 3D CNN components by shifting low-level feature representations of volumetric inputs in three dimensions; thereby, the MTL framework is able to accelerate convergence and improve joint learning performance compared to single-task models. By only using chest CT scans, COVID-MTL was trained on 930 CT scans and tested on separate 399 cases. COVID-MTL achieved AUCs of 0.939 and 0.846, and accuracies of 90.23% and 79.20% for detection of COVID-19 against radiology and NAT, respectively, which outperformed the state-of-the-art models. Meanwhile, COVID-MTL yielded AUC of 0.800 +/- 0.020 and 0.813 +/- 0.021 (with transfer learning) for classifying control/suspected, mild/regular, and severe/critically-ill cases. To decipher the recognition mechanism, we also identified high-throughput lung features that were significantly related (P < 0.001) to the positivity and severity of COVID-19.",Journal Article,The authors declare no competing interests.
34917779,10.1016/j.phro.2021.11.007,Artificial intelligence based treatment planning of radiotherapy for locally advanced breast cancer.,2021 Oct,Physics and imaging in radiation oncology,"van de Sande D, Sharabiani M, Bluemink H, Kneepkens E, Bakx N, Hagelaar E, van der Sangen M, Theuws J, Hurkmans C","Convolutional neural networks, Dose mimicking, Dose prediction, Locally advanced breast cancer, Machine learning","BACKGROUND AND PURPOSE: Treatment planning of radiotherapy for locally advanced breast cancer patients can be a time consuming process. Artificial intelligence based treatment planning could be used as a tool to speed up this process and maintain plan quality consistency. The purpose of this study was to create treatment plans for locally advanced breast cancer patients using a Convolutional Neural Network (CNN). MATERIALS AND METHODS: Data of 60 patients treated for left-sided breast cancer was used with a training, validation and test split of 36/12/12, respectively. The in-house built CNN model was a hierarchically densely connected U-net (HD U-net). The inputs for the HD U-net were 2D distance maps of the relevant regions of interest. Dose predictions, generated by the HD U-net, were used for a mimicking algorithm in order to create clinically deliverable plans. RESULTS: Dose predictions were generated by the HD U-net and mimicked using a commercial treatment planning system. The predicted plans fulfilling all clinical goals while showing small (</=0.5 Gy) statistically significant differences (p < 0.05) in the doses compared to the manual plans. The mimicked plans show statistically significant differences in the average doses for the heart and lung of </=0.5 Gy and a reduced D2% of all PTVs. In total, ten of the twelve mimicked plans were clinically acceptable. CONCLUSIONS: We created a CNN model which can generate clinically acceptable plans for left-sided locally advanced breast cancer patients. This model shows great potential to speed up the treatment planning process while maintaining consistent plan quality.",Journal Article,The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
34910645,10.1109/JBHI.2021.3135647,Automatic Lung Nodule Segmentation and Intra-Nodular Heterogeneity Image Generation.,2022 Jun,IEEE journal of biomedical and health informatics,"Song J, Huang SC, Kelly B, Liao G, Shi J, Wu N, Li W, Liu Z, Cui L, Lungre M, Moseley ME, Gao P, Tian J, Yeom KW","Databases, Factual, Humans, Image Processing, Computer-Assisted/methods, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging, Thorax, Tomography, X-Ray Computed/methods","Automatic segmentation of lung nodules on computed tomography (CT) images is challenging owing to the variability of morphology, location, and intensity. In addition, few segmentation methods can capture intra-nodular heterogeneity to assist lung nodule diagnosis. In this study, we propose an end-to-end architecture to perform fully automated segmentation of multiple types of lung nodules and generate intra-nodular heterogeneity images for clinical use. To this end, a hybrid loss is considered by introducing a Faster R-CNN model based on generalized intersection over union loss in generative adversarial network. The Lung Image Database Consortium image collection dataset, comprising 2,635 lung nodules, was combined with 3,200 lung nodules from five hospitals for this study. Compared with manual segmentation by radiologists, the proposed model obtained an average dice coefficient (DC) of 82.05% on the test dataset. Compared with U-net, NoduleNet, nnU-net, and other three models, the proposed method achieved comparable performance on lung nodule segmentation and generated more vivid and valid intra-nodular heterogeneity images, which are beneficial in radiological diagnosis. In an external test of 91 patients from another hospital, the proposed model achieved an average DC of 81.61%. The proposed method effectively addresses the challenges of inevitable human interaction and additional pre-processing procedures in the existing solutions for lung nodule segmentation. In addition, the results show that the intra-nodular heterogeneity images generated by the proposed model are suitable to facilitate lung nodule diagnosis in radiology.","Journal Article, Research Support, Non-U.S. Gov't",
34903781,10.1038/s41598-021-03206-x,Using a convolutional neural network for classification of squamous and non-squamous non-small cell lung cancer based on diagnostic histopathology HES images.,2021 Dec 13,Scientific reports,"Le Page AL, Ballot E, Truntzer C, Derangere V, Ilie A, Rageot D, Bibeau F, Ghiringhelli F","Carcinoma, Non-Small-Cell Lung/classification/*pathology, Carcinoma, Squamous Cell/classification/*pathology, Humans, Image Interpretation, Computer-Assisted/*methods/standards, Immunohistochemistry/methods, Machine Learning/*standards, Sensitivity and Specificity, Software/standards","Histological stratification in metastatic non-small cell lung cancer (NSCLC) is essential to properly guide therapy. Morphological evaluation remains the basis for subtyping and is completed by additional immunohistochemistry labelling to confirm the diagnosis, which delays molecular analysis and utilises precious sample. Therefore, we tested the capacity of convolutional neural networks (CNNs) to classify NSCLC based on pathologic HES diagnostic biopsies. The model was estimated with a learning cohort of 132 NSCLC patients and validated on an external validation cohort of 65 NSCLC patients. Based on image patches, a CNN using InceptionV3 architecture was trained and optimized to classify NSCLC between squamous and non-squamous subtypes. Accuracies of 0.99, 0.87, 0.85, 0.85 was reached in the training, validation and test sets and in the external validation cohort. At the patient level, the CNN model showed a capacity to predict the tumour histology with accuracy of 0.73 and 0.78 in the learning and external validation cohorts respectively. Selecting tumour area using virtual tissue micro-array improved prediction, with accuracy of 0.82 in the external validation cohort. This study underlines the capacity of CNN to predict NSCLC subtype with good accuracy and to be applied to small pathologic samples without annotation.",Journal Article,
34891972,10.1109/EMBC46164.2021.9630092,A generative adversarial network-based CT image standardization model for predicting progression-free survival of lung cancer.,2021 Nov,Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference,"Wu Q, Huang W, Wang S, Yu H, Wang L, Wu Z, Zhu Y, Liu Z, Ma H, Tian J","Humans, *Lung Neoplasms/diagnostic imaging, Progression-Free Survival, Radionuclide Imaging, Reference Standards, *Tomography, X-Ray Computed","Progression-free survival (PFS) prediction using computed tomography (CT) images is important for treatment planning in lung cancer. However, the generalization ability of current analysis methods is usually affected by the scanning parameters of CT images, such as slice thickness and reconstruction kernel. In this paper, we proposed a generative adversarial network (GAN)-based model to convert heterogenous CT images into standardized CT images with uniform slice thickness and reconstruction kernel to increase the generalization of the predictive model. This model was trained in 173 patients with multiple CT sequences including both thin/thick voxel-spacing and sharp/soft reconstruction kernel. Afterward, we built a 3D-CNN model to predict the individualized 1year PFS of lung cancer using the standardized CT images in 281 patients. Finally, we evaluated the predictive model by 5-fold cross-validation and the mean area under the receiver operating characteristic curve (AUC). After transforming to the heterogenous CT images into the uniform thin-spacing and sharp kernel CT images, the AUC value of the 3D-CNN model improved from 0.614 to 0.686. Furthermore, this model can stratify the patients into high-risk and low-risk groups, where patients in these two groups showed significant difference in PFS (P < 0.001).","Journal Article, Research Support, Non-U.S. Gov't",
34891926,10.1109/EMBC46164.2021.9630096,Dual Skip Connections Minimize the False Positive Rate of Lung Nodule Detection in CT images.,2021 Nov,Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference,"Xu J, Ernst P, Liu TL, Nurnberger A","Diagnosis, Computer-Assisted, Humans, Lung, *Lung Neoplasms/diagnostic imaging, *Neural Networks, Computer, Tomography, X-Ray Computed","Pulmonary cancer is one of the most commonly diagnosed and fatal cancers and is often diagnosed by incidental findings on computed tomography. Automated pulmonary nodule detection is an essential part of computer-aided diagnosis, which is still facing great challenges and difficulties to quickly and accurately locate the exact nodules' positions. This paper proposes a dual skip connection upsampling strategy based on Dual Path network in a U-Net structure generating multiscale feature maps, which aims to minimize the ratio of false positives and maximize the sensitivity for lesion detection of nodules. The results show that our new upsampling strategy improves the performance by having 85.3% sensitivity at 4 FROC per image compared to 84.2% for the regular upsampling strategy or 81.2% for VGG16-based Faster-R-CNN.","Journal Article, Research Support, Non-U.S. Gov't",
34884000,10.3390/s21237996,A Convolutional Neural Network-Based Intelligent Medical System with Sensors for Assistive Diagnosis and Decision-Making in Non-Small Cell Lung Cancer.,2021 Nov 30,"Sensors (Basel, Switzerland)","Zhan X, Long H, Gou F, Duan X, Kong G, Wu J","*Carcinoma, Non-Small-Cell Lung/diagnosis, China, Humans, *Lung Neoplasms/diagnosis, Neural Networks, Computer, CNN, NSCLC, dynamic sampling, semantic features, sensors, transfer learning","In many regions of the world, early diagnosis of non-small cell lung cancer (NSCLC) is a major challenge due to the large population and lack of medical resources, which is difficult toeffectively address via limited physician manpower alone. Therefore, we developed a convolutional neural network (CNN)-based assisted diagnosis and decision-making intelligent medical system with sensors. This system analyzes NSCLC patients' medical records using sensors to assist staging a diagnosis and provides recommended treatment plans to physicians. To address the problem of unbalanced case samples across pathological stages, we used transfer learning and dynamic sampling techniques to reconstruct and iteratively train the model to improve the accuracy of the prediction system. In this paper, all data for training and testing the system were obtained from the medical records of 2,789,675 patients with NSCLC, which were recorded in three hospitals in China over a five-year period. When the number of case samples reached 8000, the system achieved an accuracy rate of 0.84, which is already close to that of the doctors (accuracy: 0.86). The experimental results proved that the system can quickly and accurately analyze patient data and provide decision information support for physicians.",Journal Article,
34882262,10.1007/s00259-021-05637-0,Comparison of deep learning-based emission-only attenuation correction methods for positron emission tomography.,2022 May,European journal of nuclear medicine and molecular imaging,"Hwang D, Kang SK, Kim KY, Choi H, Lee JS","*Deep Learning, Fluorodeoxyglucose F18, Humans, Image Processing, Computer-Assisted/methods, Magnetic Resonance Imaging/methods, *Positron Emission Tomography Computed Tomography, Positron-Emission Tomography/methods, *Attenuation correction, *Deep learning, *Scatter correction, *Simultaneous reconstruction","PURPOSE: This study aims to compare two approaches using only emission PET data and a convolution neural network (CNN) to correct the attenuation (mu) of the annihilation photons in PET. METHODS: One of the approaches uses a CNN to generate mu-maps from the non-attenuation-corrected (NAC) PET images (mu-CNNNAC). In the other method, CNN is used to improve the accuracy of mu-maps generated using maximum likelihood estimation of activity and attenuation (MLAA) reconstruction (mu-CNNMLAA). We investigated the improvement in the CNN performance by combining the two methods (mu-CNNMLAA+NAC) and the suitability of mu-CNNNAC for providing the scatter distribution required for MLAA reconstruction. Image data from (18)F-FDG (n = 100) or (68) Ga-DOTATOC (n = 50) PET/CT scans were used for neural network training and testing. RESULTS: The error of the attenuation correction factors estimated using mu-CT and mu-CNNNAC was over 7%, but that of scatter estimates was only 2.5%, indicating the validity of the scatter estimation from mu-CNNNAC. However, CNNNAC provided less accurate bone structures in the mu-maps, while the best results in recovering the fine bone structures were obtained by applying CNNMLAA+NAC. Additionally, the mu-values in the lungs were overestimated by CNNNAC. Activity images (lambda) corrected for attenuation using mu-CNNMLAA and mu-CNNMLAA+NAC were superior to those corrected using mu-CNNNAC, in terms of their similarity to lambda-CT. However, the improvement in the similarity with lambda-CT by combining the CNNNAC and CNNMLAA approaches was insignificant (percent error for lung cancer lesions, lambda-CNNNAC = 5.45% +/- 7.88%; lambda-CNNMLAA = 1.21% +/- 5.74%; lambda-CNNMLAA+NAC = 1.91% +/- 4.78%; percent error for bone cancer lesions, lambda-CNNNAC = 1.37% +/- 5.16%; lambda-CNNMLAA = 0.23% +/- 3.81%; lambda-CNNMLAA+NAC = 0.05% +/- 3.49%). CONCLUSION: The use of CNNNAC was feasible for scatter estimation to address the chicken-egg dilemma in MLAA reconstruction, but CNNMLAA outperformed CNNNAC.",Journal Article,
34825875,10.2174/1573405617666211126151713,Computer-Aided Detection of Human Lung Nodules on Computer Tomography Images via Novel Optimized Techniques.,2022,Current medical imaging,"Seelan LJ, Suresh LP, K S A, P K V","Computers, Diagnosis, Computer-Assisted/methods, Humans, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging/pathology, *Tomography, X-Ray Computed/methods, CAD, CNN, Canny edge detector, Curvelet transform, GLRM, fuzzy thresholding","BACKGROUND: As the mortality rate of lung cancer is enormously high, its impact is also extremely higher than the other types of cancer. Lung malignancy is thus considered one of the deadliest diseases with a high death rate in the world. It is reported that nearly 1.2 million people are diagnosed with this disease and about 1.1 million individuals are died due to this type of cancer every year. The early detection of this disease is the only solution for minimizing the death rate or maximizing the survival rate. However, the timely identification of lung malignant growth is a complex process and hence various imaging algorithms are employed in the process of detecting lung cancer on time. AIM: The Computer-Aided Diagnosis (CAD) is highly beneficial for the radiologist to rapidly detect and diagnose the irregularities in advance. The CAD systems usually focus on identifying and detecting the lung nodules. As the treatment of this disease is provided on the basis of its stages, the early detection of cancer has to be given much importance. The major drawbacks of existing CAD systems are less accuracy in segmenting the nodule and staging the lung cancer. OBJECTIVE: The major aim of this work is to categorize the lung nodules from the CT image and classify the tumorous cells for identifying the exact position of cancer with higher sensitivity, precision, and accuracy than other strategies. METHODS: The methods employed in this study are listed as follows: (i) For the process of de-noising and edge sharpening of lung image, the curvelet transform was used. (ii) The Fuzzy thresholding technique was used to perform lung image binarization and lung boundary corrections. (iii) Segmentation was performed by implementing the K-means algorithm. (iv) By using Convolutional Neural Network (CNN), different stages of lung nodules, like benign and malignant, were identified. RESULTS: The proposed classifier achieves optimal accuracy of 97.3%, a sensitivity of 98.6% and a specificity of 96.1% which are significantly better than the other approaches. Thus, the proposed approach is highly helpful in detecting lung cancer in its early stages. CONCLUSION: The results validate that the proposed algorithms are highly capable of classifying the lung images into various stages, which effectively helps the radiologist in the decision-making process.",Journal Article,
34811644,10.1007/s11517-021-02462-3,CAD system for lung nodule detection using deep learning with CNN.,2022 Jan,Medical & biological engineering & computing,"Manickavasagam R, Selvan S, Selvan M","Bayes Theorem, *Deep Learning, Diagnosis, Computer-Assisted, Humans, Lung, *Lung Neoplasms/diagnostic imaging, Radiographic Image Interpretation, Computer-Assisted, *Solitary Pulmonary Nodule/diagnostic imaging, Computed tomography (CT), Convolutional neural network (CNN), Deep learning, LIDC, Lung nodules","The early detection of pulmonary nodules using computer-aided diagnosis (CAD) systems is very essential in reducing mortality rates of lung cancer. In this paper, we propose a new deep learning approach to improve the classification accuracy of pulmonary nodules in computed tomography (CT) images. Our proposed CNN-5CL (convolutional neural network with 5 convolutional layers) approach uses an 11-layer convolutional neural network (with 5 convolutional layers) for automatic feature extraction and classification. The proposed method is evaluated using LIDC/IDRI images. The proposed method is implemented in the Python platform, and the performance is evaluated with metrics such as accuracy, sensitivity, specificity, and receiver operating characteristics (ROC). The results show that the proposed method achieves accuracy, sensitivity, specificity, and area under the roc curve (AUC) of 98.88%, 99.62%, 93.73%, and 0.928, respectively. The proposed approach outperforms various other methods such as Naive Bayes, K-nearest neighbor, support vector machine, adaptive neuro fuzzy inference system methods, and also other deep learning-based approaches.",Journal Article,
34798623,10.1088/1361-6560/ac3b66,Deep learning-based 3Din vivodose reconstruction with an electronic portal imaging device for magnetic resonance-linear accelerators: a proof of concept study.,2021 Dec 2,Physics in medicine and biology,"Li Y, Xiao F, Liu B, Qi M, Lu X, Cai J, Zhou L, Song T","Algorithms, *Deep Learning, Electronics, Humans, Magnetic Resonance Spectroscopy, *Neoplasms, Particle Accelerators, Phantoms, Imaging, Proof of Concept Study, Radiometry/methods, Radiotherapy Dosage, Radiotherapy Planning, Computer-Assisted/methods, *Radiotherapy, Intensity-Modulated/methods, *EPID, *MR-LINAC, *deep learning, *in vivo dose reconstruction","Objective.To develop a novel deep learning-based 3Din vivodose reconstruction framework with an electronic portal imaging device (EPID) for magnetic resonance-linear accelerators (MR-LINACs).Approach.The proposed method directly back-projected 2D portal dose into 3D patient coarse dose, which bypassed the complicated patient-to-EPID scatter estimation step used in conventional methods. A pre-trained convolutional neural network (CNN) was then employed to map the coarse dose to the final accurate dose. The electron return effect caused by the magnetic field was captured with the CNN model. Patient dose and portal dose datasets were synchronously generated with Monte Carlo simulation for 96 patients (78 cases for training and validation and 18 cases for testing) treated with fixed-beam intensity-modulated radiotherapy in four different tumor sites, including the brain, nasopharynx, lung, and rectum. Beam angles from the training dataset were further rotated 2-3 times, and doses were recalculated to augment the datasets.Results.The comparison between reconstructed doses and MC ground truth doses showed mean absolute errors <0.88% for all tumor sites. The averaged 3Dgamma-passing rates (3%, 2 mm) were 97.42%+/-2.66% (brain), 98.53%+/-0.95% (nasopharynx), 99.41%+/-0.46% (lung), and 98.63%+/-1.01% (rectum). The dose volume histograms and indices also showed good consistency. The average dose reconstruction time, including back projection and CNN dose mapping, was less than 3 s for each individual beam.Significance.The proposed method can be potentially used for accurate and fast 3D dosimetric verification for online adaptive radiotherapy using MR-LINACs.","Journal Article, Research Support, Non-U.S. Gov't",
34794136,10.1088/1361-6560/ac3b32,Lung cancer subtype classification using histopathological images based on weakly supervised multi-instance learning.,2021 Dec 2,Physics in medicine and biology,"Zhao L, Xu X, Hou R, Zhao W, Zhong H, Teng H, Han Y, Fu X, Sun J, Zhao J","Algorithms, *Carcinoma, Non-Small-Cell Lung/diagnostic imaging, Humans, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, *Lung cancer, *multi-instance learning, *pathological image, *subtype classification","Objective.Subtype classification plays a guiding role in the clinical diagnosis and treatment of non-small-cell lung cancer (NSCLC). However, due to the gigapixel of whole slide images (WSIs) and the absence of definitive morphological features, most automatic subtype classification methods for NSCLC require manually delineating the regions of interest (ROIs) on WSIs.Approach.In this paper, a weakly supervised framework is proposed for accurate subtype classification while freeing pathologists from pixel-level annotation. With respect to the characteristics of histopathological images, we design a two-stage structure with ROI localization and subtype classification. We first develop a method called multi-resolution expectation-maximization convolutional neural network (MR-EM-CNN) to locate ROIs for subsequent subtype classification. The EM algorithm is introduced to select the discriminative image patches for training a patch-wise network, with only WSI-wise labels available. A multi-resolution mechanism is designed for fine localization, similar to the coarse-to-fine process of manual pathological analysis. In the second stage, we build a novel hierarchical attention multi-scale network (HMS) for subtype classification. HMS can capture multi-scale features flexibly driven by the attention module and implement hierarchical features interaction.Results.Experimental results on the 1002-patient Cancer Genome Atlas dataset achieved an AUC of 0.9602 in the ROI localization and an AUC of 0.9671 for subtype classification.Significance.The proposed method shows superiority compared with other algorithms in the subtype classification of NSCLC. The proposed framework can also be extended to other classification tasks with WSIs.","Journal Article, Research Support, Non-U.S. Gov't",
34778923,10.1186/s40658-021-00424-0,Fully automated identification of brain abnormality from whole-body FDG-PET imaging using deep learning-based brain extraction and statistical parametric mapping.,2021 Nov 14,EJNMMI physics,"Whi W, Choi H, Paeng JC, Cheon GJ, Kang KW, Lee DS","Brain FDG-PET, Brain segmentation, Convolutional neural network, Deep learning, FDG-PET, Quantitative PET analysis","BACKGROUND: The whole brain is often covered in [(18)F]Fluorodeoxyglucose positron emission tomography ([(18)F]FDG-PET) in oncology patients, but the covered brain abnormality is typically screened by visual interpretation without quantitative analysis in clinical practice. In this study, we aimed to develop a fully automated quantitative interpretation pipeline of brain volume from an oncology PET image. METHOD: We retrospectively collected 500 oncologic [(18)F]FDG-PET scans for training and validation of the automated brain extractor. We trained the model for extracting brain volume with two manually drawn bounding boxes on maximal intensity projection images. ResNet-50, a 2-D convolutional neural network (CNN), was used for the model training. The brain volume was automatically extracted using the CNN model and spatially normalized. For validation of the trained model and an application of this automated analytic method, we enrolled 24 subjects with small cell lung cancer (SCLC) and performed voxel-wise two-sample T test for automatic detection of metastatic lesions. RESULT: The deep learning-based brain extractor successfully identified the existence of whole-brain volume, with an accuracy of 98% for the validation set. The performance of extracting the brain measured by the intersection-over-union of 3-D bounding boxes was 72.9 +/- 12.5% for the validation set. As an example of the application to automatically identify brain abnormality, this approach successfully identified the metastatic lesions in three of the four cases of SCLC patients with brain metastasis. CONCLUSION: Based on the deep learning-based model, extraction of the brain volume from whole-body PET was successfully performed. We suggest this fully automated approach could be used for the quantitative analysis of brain metabolic patterns to identify abnormalities during clinical interpretation of oncologic PET studies.",Journal Article,
34771708,10.3390/cancers13215546,State-of-the-Art Challenges and Perspectives in Multi-Organ Cancer Diagnosis via Deep Learning-Based Methods.,2021 Nov 4,Cancers,"Ali S, Li J, Pei Y, Khurram R, Rehman KU, Rasool AB","automated computer-aid diagnosis systems, cancer diagnosis, deep learning, machine learning, medical imaging","Thus far, the most common cause of death in the world is cancer. It consists of abnormally expanding areas that are threatening to human survival. Hence, the timely detection of cancer is important to expanding the survival rate of patients. In this survey, we analyze the state-of-the-art approaches for multi-organ cancer detection, segmentation, and classification. This article promptly reviews the present-day works in the breast, brain, lung, and skin cancer domain. Afterwards, we analytically compared the existing approaches to provide insight into the ongoing trends and future challenges. This review also provides an objective description of widely employed imaging techniques, imaging modality, gold standard database, and related literature on each cancer in 2016-2021. The main goal is to systematically examine the cancer diagnosis systems for multi-organs of the human body as mentioned. Our critical survey analysis reveals that greater than 70% of deep learning researchers attain promising results with CNN-based approaches for the early diagnosis of multi-organ cancer. This survey includes the extensive discussion part along with current research challenges, possible solutions, and prospects. This research will endow novice researchers with valuable information to deepen their knowledge and also provide the room to develop new robust computer-aid diagnosis systems, which assist health professionals in bridging the gap between rapid diagnosis and treatment planning for cancer patients.","Journal Article, Review",
34741906,10.1016/j.compbiomed.2021.104961,LungNet: A hybrid deep-CNN model for lung cancer diagnosis using CT and wearable sensor-based medical IoT data.,2021 Dec,Computers in biology and medicine,"Faruqui N, Yousuf MA, Whaiduzzaman M, Azad AKM, Barros A, Moni MA","Humans, Lung, *Lung Neoplasms/diagnostic imaging, Neural Networks, Computer, Tomography, X-Ray Computed, *Wearable Electronic Devices, *CNN Architecture, *Centralized server, *Feature enhancement, *LungNet, *Medical internet of things, *Stage classification","Lung cancer, also known as pulmonary cancer, is one of the deadliest cancers, but yet curable if detected at the early stage. At present, the ambiguous features of the lung cancer nodule make the computer-aided automatic diagnosis a challenging task. To alleviate this, we present LungNet, a novel hybrid deep-convolutional neural network-based model, trained with CT scan and wearable sensor-based medical IoT (MIoT) data. LungNet consists of a unique 22-layers Convolutional Neural Network (CNN), which combines latent features that are learned from CT scan images and MIoT data to enhance the diagnostic accuracy of the system. Operated from a centralized server, the network has been trained with a balanced dataset having 525,000 images that can classify lung cancer into five classes with high accuracy (96.81%) and low false positive rate (3.35%), outperforming similar CNN-based classifiers. Moreover, it classifies the stage-1 and stage-2 lung cancers into 1A, 1B, 2A and 2B sub-classes with 91.6% accuracy and false positive rate of 7.25%. High predictive capability accompanied with sub-stage classification renders LungNet as a promising prospect in developing CNN-based automatic lung cancer diagnosis systems.",Journal Article,
34736166,10.1016/j.cmpb.2021.106464,Deep embeddings and logistic regression for rapid active learning in histopathological images.,2021 Nov,Computer methods and programs in biomedicine,"Jiao Y, Yuan J, Qiang Y, Fei S","Area Under Curve, Image Processing, Computer-Assisted, Logistic Models, *Neural Networks, Computer, Active learning, Computer-aided diagnosis, Data annotation, Deep learning, Digital pathology, Tissue classification","BACKGROUND AND OBJECTIVE: Recognizing different tissue components is one of the most fundamental and essential works in digital pathology. Current methods are often based on convolutional neural networks (CNNs), which need numerous annotated samples for training. Creating large-scale histopathological datasets is labor-intensive, where interactive data annotation is a potential solution. METHODS: We propose DELR (Deep Embedding-based Logistic Regression) to enable rapid model training and inference for histopathological image analysis. DELR utilizes a pretrained CNN to encode images as compact embeddings with low computational cost. The embeddings are then used to train a Logistic Regression model efficiently. We implemented DELR in an active learning framework, and validated it on three histopathological problems (binary, 4-category, and 8-category classification challenge for lung, breast, and colorectal cancer, respectively). We also investigated the influence of active learning strategy and type of the encoder. RESULTS: On all the three datasets, DELR can achieve an area under curve (AUC) metric higher than 0.95 with only 100 image patches per class. Although its AUC is slightly lower than a fine-tuned CNN counterpart, DELR can be 536, 316, and 1481 times faster after pre-encoding. Moreover, DELR is proved to be compatible with a variety of active learning strategies and encoders. CONCLUSIONS: DELR can achieve comparable accuracy to CNN with rapid running speed. These advantages make it a potential solution for real-time interactive data annotation.",Journal Article,Declaration of Competing Interest The authors declared that they have no conflicts of interest in this work.
34727340,10.1007/s12539-021-00472-1,Identification of Benign and Malignant Lung Nodules in CT Images Based on Ensemble Learning Method.,2022 Mar,"Interdisciplinary sciences, computational life sciences","Xu Y, Wang S, Sun X, Yang Y, Fan J, Jin W, Li Y, Su F, Zhang W, Cui Q, Hu Y, Wang S, Zhang J, Chen C","Diagnosis, Computer-Assisted, Diagnosis, Differential, Humans, *Lung Neoplasms/diagnostic imaging, *Machine Learning, Radiographic Image Interpretation, Computer-Assisted/methods, *Solitary Pulmonary Nodule/diagnostic imaging, Tomography, X-Ray Computed/methods, CNN, CT images, Ensemble learning, Logistic regression, Pulmonary nodules, YOLOv3 network","BACKGROUND AND OBJECTIVE: Under the background of urgent need for computer-aided technology to provide physicians with objective decision support, aiming at reducing the false positive rate of nodule CT detection in pulmonary nodules detection and improving the accuracy of lung nodule recognition, this paper puts forward a method based on ensemble learning to distinguish between malignant and benign pulmonary nodules. METHODS: Firstly, trained on a public data set, a multi-layer feature fusion YOLOv3 network is used to detect lung nodules. Secondly, a CNN was trained to differentiate benign from malignant pulmonary nodules. Then, based on the idea of ensemble learning, the confidence probability of the above two models and the label of the training set are taken as data features to build a Logistic regression model. Finally, two test sets (public data set and private data set) were tested, and the confidence probability output by the two models was fused into the established logistic regression model to determine benign and malignant pulmonary nodules. RESULTS: The YOLOv3 network was trained to detect chest CT images of the test set. The number of pulmonary nodules detected in the public and private test sets was 356 and 314, respectively. The accuracy, sensitivity and specificity of the two test sets were 80.97%, 81.63%, 78.75% and 79.69%, 86.59%, 72.16%, respectively. With CNN training pulmonary nodules benign and malignant discriminant model analysis of two kinds of test set, the result of accuracy, sensitivity and specificity were 90.12%, 90.66%, 89.47% and 88.57%, 85.62%, 90.87%, respectively. Fused model based on YOLOv3 network and CNN is tested on two test sets, and the result of accuracy, sensitivity and specificity were 93.82%, 94.85%, 92.59% and 92.31%, 92.68%, 91.89%, respectively. CONCLUSION: The ensemble learning model is more effective than YOLOv3 network and CNN in removing false positives, and the accuracy of the ensemble. Learning model is higher than the other two networks in identifying pulmonary nodules.",Journal Article,
34721825,10.1155/2021/6556266,Deep Learning-Based Computed Tomography Imaging to Diagnose the Lung Nodule and Treatment Effect of Radiofrequency Ablation.,2021,Journal of healthcare engineering,"Guo X, Li Y, Yang C, Hu Y, Zhou Y, Wang Z, Zhang L, Hu H, Wu Y","*Deep Learning, Humans, Lung/diagnostic imaging/pathology/surgery, *Lung Neoplasms/diagnostic imaging/surgery, *Radiofrequency Ablation, Radiographic Image Interpretation, Computer-Assisted, Tomography, X-Ray Computed/methods","This study aimed to detect and diagnose the lung nodules as early as possible to effectively treat them, thereby reducing the burden on the medical system and patients. A lung computed tomography (CT) image segmentation algorithm was constructed based on the deep learning convolutional neural network (CNN). The clinical data of 69 patients with lung nodules diagnosed by needle biopsy and pathological comprehensive diagnosis at hospital were collected for specific analysis. The CT image segmentation algorithm was used to distinguish the nature and volume of lung nodules and compared with other computer aided design (CAD) software (Philips ISP). 69 patients with lung nodules were treated by radiofrequency ablation (RFA). The results showed that the diagnostic sensitivity of the CT image segmentation algorithm based on the CNN was obviously higher than that of the Philips ISP for solid nodules <5 mm (63 cases vs. 33 cases) (P < 0.05); it was the same result for the subsolid nodule <5 mm (33 case vs. 5 cases) (P < 0.05) that was slightly higher for solid and subsolid nodules with a diameter of 5-10 mm (37 cases vs. 28 cases) (P < 0.05). In addition, the CNN algorithm can reach all detection for calcified nodules and pleural nodules (7 cases; 5 cases), and the diagnostic sensitivities were much better than those of Philips ISP (2 cases; 3 cases) (P < 0.05). Patients with pulmonary nodules treated by RFA were in good postoperative condition, with a half-year survival rate of 100% and a one-year survival rate of 72.4%. Therefore, it could be concluded that the CT image segmentation algorithm based on the CNN could effectively detect and diagnose the lung nodules early, and the RFA could effectively treat the lung nodules.","Journal Article, Research Support, Non-U.S. Gov't",The authors declare that they have no conflicts of interest.
34713592,10.1111/1759-7714.14140,Predictive value of a novel Asian lung cancer screening nomogram based on artificial intelligence and epidemiological characteristics.,2021 Dec,Thoracic cancer,"Liu D, Sun X, Liu A, Li L, Li S, Li J, Liu X, Yang Y, Wu Z, Leng X, Wo Y, Huang Z, Su W, Du W, Yuan T, Jiao W","Aged, *Artificial Intelligence, China/epidemiology, Early Detection of Cancer/*standards, Epidemiologic Methods, Female, Humans, Lung Neoplasms/*diagnosis/*epidemiology, Male, Middle Aged, Neural Networks, Computer, *Nomograms, Predictive Value of Tests, Retrospective Studies, Risk Factors, Tomography, X-Ray Computed, *Asians lung cancer screening, *artificial intelligence, *convolutional neural networks, *epidemiological characteristics, *nomogram","BACKGROUND: To develop and validate a risk prediction nomogram based on a deep learning convolutional neural networks (CNN) model and epidemiological characteristics for lung cancer screening in patients with small pulmonary nodules (SPN). METHODS: This study included three data sets. First, a CNN model was developed and tested on data set 1. Then, a hybrid prediction model was developed on data set 2 by multivariable binary logistic regression analysis. We combined the CNN model score and the selected epidemiological risk factors, and a risk prediction nomogram was presented. An independent multicenter cohort was used for model external validation. The performance of the nomogram was assessed with respect to its calibration and discrimination. RESULTS: The final hybrid model included the CNN model score and the screened risk factors included age, gender, smoking status and family history of cancer. The nomogram showed good discrimination and calibration with an area under the curve (AUC) of 91.6% (95% CI: 89.4%-93.5%), compare with the CNN model, the improvement was significance. The performance of the nomogram still showed good discrimination and good calibration in the multicenter validation cohort, with an AUC of 88.3% (95% CI: 83.1%-92.3%). CONCLUSIONS: Our study showed that epidemiological characteristics should be considered in lung cancer screening, which can significantly improve the efficiency of the artificial intelligence (AI) model alone. We combined the CNN model score with Asian lung cancer epidemiological characteristics to develop a new nomogram to facilitate and accurately perform individualized lung cancer screening, especially for Asians.","Journal Article, Multicenter Study, Validation Study",
34679484,10.3390/diagnostics11101785,Textured-Based Deep Learning in Prostate Cancer Classification with 3T Multiparametric MRI: Comparison with PI-RADS-Based Classification.,2021 Sep 28,"Diagnostics (Basel, Switzerland)","Liu Y, Zheng H, Liang Z, Miao Q, Brisbane WG, Marks LS, Raman SS, Reiter RE, Yang G, Sung K","PI-RADS, convolutional neural network, deep learning, prostate cancer classification, texture analysis","The current standardized scheme for interpreting MRI requires a high level of expertise and exhibits a significant degree of inter-reader and intra-reader variability. An automated prostate cancer (PCa) classification can improve the ability of MRI to assess the spectrum of PCa. The purpose of the study was to evaluate the performance of a texture-based deep learning model (Textured-DL) for differentiating between clinically significant PCa (csPCa) and non-csPCa and to compare the Textured-DL with Prostate Imaging Reporting and Data System (PI-RADS)-based classification (PI-RADS-CLA), where a threshold of PI-RADS >/= 4, representing highly suspicious lesions for csPCa, was applied. The study cohort included 402 patients (60% (n = 239) of patients for training, 10% (n = 42) for validation, and 30% (n = 121) for testing) with 3T multiparametric MRI matched with whole-mount histopathology after radical prostatectomy. For a given suspicious prostate lesion, the volumetric patches of T2-Weighted MRI and apparent diffusion coefficient images were cropped and used as the input to Textured-DL, consisting of a 3D gray-level co-occurrence matrix extractor and a CNN. PI-RADS-CLA by an expert reader served as a baseline to compare classification performance with Textured-DL in differentiating csPCa from non-csPCa. Sensitivity and specificity comparisons were performed using Mcnemar's test. Bootstrapping with 1000 samples was performed to estimate the 95% confidence interval (CI) for AUC. CIs of sensitivity and specificity were calculated by the Wald method. The Textured-DL model achieved an AUC of 0.85 (CI [0.79, 0.91]), which was significantly higher than the PI-RADS-CLA (AUC of 0.73 (CI [0.65, 0.80]); p < 0.05) for PCa classification, and the specificity was significantly different between Textured-DL and PI-RADS-CLA (0.70 (CI [0.59, 0.82]) vs. 0.47 (CI [0.35, 0.59]); p < 0.05). In sub-analyses, Textured-DL demonstrated significantly higher specificities in the peripheral zone (PZ) and solitary tumor lesions compared to the PI-RADS-CLA (0.78 (CI [0.66, 0.90]) vs. 0.42 (CI [0.28, 0.57]); 0.75 (CI [0.54, 0.96]) vs. 0.38 [0.14, 0.61]; all p values < 0.05). Moreover, Textured-DL demonstrated a high negative predictive value of 92% while maintaining a high positive predictive value of 58% among the lesions with a PI-RADS score of 3. In conclusion, the Textured-DL model was superior to the PI-RADS-CLA in the classification of PCa. In addition, Textured-DL demonstrated superior performance in the specificities for the peripheral zone and solitary tumors compared with PI-RADS-based risk assessment.",Journal Article,
34669994,10.1002/mp.15307,Deep learning predicts epidermal growth factor receptor mutation subtypes in lung adenocarcinoma.,2021 Dec,Medical physics,"Song J, Ding C, Huang Q, Luo T, Xu X, Chen Z, Li S","*Adenocarcinoma of Lung/diagnostic imaging/genetics, *Deep Learning, ErbB Receptors/genetics, Humans, *Lung Neoplasms/diagnostic imaging/genetics, Mutation, Retrospective Studies, EGFR mutation subtypes, convolutional neural network, deep learning, lung adenocarcinoma, radiomics","PURPOSE: This study aimed to explore the predictive ability of deep learning (DL) for the common epidermal growth factor receptor (EGFR) mutation subtypes in patients with lung adenocarcinoma. METHODS: A total of 665 patients with lung adenocarcinoma (528/137) were recruited from two different institutions. In the training set, an 18-layer convolutional neural network (CNN) and fivefold cross-validation strategy were used to establish a CNN model. Subsequently, an independent external validation cohort from the other institution was used to evaluate the predictive efficacy of the CNN model. Grad-weighted class activation mapping (Grad-CAM) technology was used for the visual interpretation of the CNN model. In addition, this study also compared the prediction abilities of the radiomics and CNN models. Receiver operating characteristic (ROC) curves, accuracy and precision values, and recall and F1-score were used to evaluate the effectiveness of the CNN model and compare its performance with that of the radiomics model. RESULTS: In the validation set, the micro- and macroaverage values of the area under the ROC curve of the CNN model to identify the three EGFR subtypes were 0.78 and 0.79, respectively. All evaluation indicators of the CNN model were better than those of the radiomics model. CONCLUSIONS: Our study confirmed the potential of DL for predicting the EGFR mutation status in lung adenocarcinoma. The imaging phenotypes of the three mutation subtypes were found to be different, which can provide a basis for choosing more accurate and personalized treatment in patients with lung adenocarcinoma.",Journal Article,
34661294,10.1002/mp.15302,A deep learning- and CT image-based prognostic model for the prediction of survival in non-small cell lung cancer.,2021 Dec,Medical physics,"Chen W, Hou X, Hu Y, Huang G, Ye X, Nie S","*Carcinoma, Non-Small-Cell Lung/diagnostic imaging, *Deep Learning, Humans, *Lung Neoplasms/diagnostic imaging, Prognosis, Retrospective Studies, Tomography, X-Ray Computed, A_CNN, CT, deep learning, non-small cell lung cancer, survival prognosis model","OBJECTIVE: To assist clinicians in arranging personalized treatment, planning follow-up programs and extending survival times for non-small cell lung cancer (NSCLC) patients, a method of deep learning combined with computed tomography (CT) imaging for survival prediction was designed. METHODS: Data were collected from 484 patients from four research centers. The data from 344 patients were utilized to build the A_CNN survival prognosis model to classify 2-year overall survival time ranges (730 days cut-off). Data from 140 patients, including independent internal and external test sets, were utilized for model testing. First, a series of preprocessing techniques were used to process the original CT images and generate training and test data sets from the axial, coronal, and sagittal planes. Second, the structure of the A_CNN model was designed based on asymmetric convolution, bottleneck blocks, the uniform cross-entropy (UC) loss function, and other advanced techniques. After that, the A_CNN model was trained, and numerous comparative experiments were designed to obtain the best prognostic survival model. Last, the model performance was evaluated, and the predicted survival curves were analyzed. RESULTS: The A_CNN survival prognosis model yielded a high patient-level accuracy of 88.8%, a patch-level accuracy of 82.9%, and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.932. When tested on an external data set, the maximum patient-level accuracy was 80.0%. CONCLUSIONS: The results suggest that using a deep learning method can improve prognosis in patients with NSCLC and has important application value in establishing individualized prognostic models.",Journal Article,
34657293,10.1002/mp.15303,"Automated segmentation of lung, liver, and liver tumors from Tc-99m MAA SPECT/CT images for Y-90 radioembolization using convolutional neural networks.",2021 Dec,Medical physics,"Chaichana A, Frey EC, Teyateeti A, Rhoongsittichai K, Tocharoenchai C, Pusuwan P, Jangpatarapongsa K","*Embolization, Therapeutic, Humans, *Liver Neoplasms/diagnostic imaging/radiotherapy, Lung, Microspheres, Neural Networks, Computer, Retrospective Studies, Single Photon Emission Computed Tomography Computed Tomography, Yttrium Radioisotopes/therapeutic use, 90Y selective internal radiation therapy, 99mTc macro-aggregated albumin SPECT/CT, convolutional neural network, hepatocellular carcinoma, segmentation","PURPOSE: (90) Y selective internal radiation therapy (SIRT) has become a safe and effective treatment option for liver cancer. However, segmentation of target and organ-at-risks is labor-intensive and time-consuming in (90) Y SIRT planning. In this study, we developed a convolutional neural network (CNN)-based method for automated lungs, liver, and tumor segmentation on (99m) Tc-MAA SPECT/CT images for (90) Y SIRT planning. METHODS: (99m) Tc-MAA SPECT/CT images and corresponding clinical segmentations were retrospectively collected from 56 patients who underwent (90) Y SIRT. The collected data were used to train three CNN-based segmentation algorithms for lungs, liver, and tumor segmentation. Segmentation performance was evaluated using the Dice similarity coefficient (DSC), surface DSC, and average symmetric surface distance (ASSD). Dosimetric parameters (volume, counts, and lung shunt fraction) were measured from the segmentation results and were compared with clinical reference segmentations. RESULTS: The evaluation results show that the method can accurately segment lungs, liver, and tumor with median [interquartile range] DSCs of 0.98 [0.97-0.98], 0.91 [0.83-0.93], and 0.85 [0.71-0.88]; surface DSCs of 0.99 [0.97-0.99], 0.86 [0.77-0.93], and 0.85 [0.62-0.93], and ASSDs of 0.91 [0.69-1.5], 4.8 [2.6-8.4], and 4.7 [3.5-9.2] mm, respectively. Dosimetric parameters from the three segmentation networks show relationship with those from the reference segmentations. The overall segmentation took about 1 min per patient on an NVIDIA RTX-2080Ti GPU. CONCLUSION: This work presents CNN-based algorithms to segment lungs, liver, and tumor from (99m) Tc-MAA SPECT/CT images. The results demonstrated the potential of the proposed CNN-based segmentation method for assisting (90) Y SIRT planning while drastically reducing operator time.",Journal Article,
34655238,10.1002/mp.15298,3D gray density coding feature for benign-malignant pulmonary nodule classification on chest CT.,2021 Dec,Medical physics,"Zheng B, Yang D, Zhu Y, Liu Y, Hu J, Bai C","Humans, Lung, *Lung Neoplasms/diagnostic imaging, *Multiple Pulmonary Nodules, Radiographic Image Interpretation, Computer-Assisted, *Solitary Pulmonary Nodule/diagnostic imaging, Tomography, X-Ray Computed, 3d gray density coding feature, benign-malignant classification, geometric features, pulmonary nodules, random forest","PURPOSE: Early detection is significant to reduce lung cancer-related death. Computer-aided detection system (CADs) can help radiologists to make an early diagnosis. In this paper, we propose a novel 3D gray density coding feature (3D GDC) and fuse it with extracted geometric features. The fusion feature and random forest are used for benign-malignant pulmonary nodule classification on Chest CT. METHODS: First, a dictionary model is created to acquire codebook. It is used to obtain feature descriptors and includes 3D block database (BD) and distance matrix clustering centers. 3D BD is balanced and randomly selecting from benign and malignant pulmonary nodules of training data. Clustering centers is got by clustering the distance matrix, which is the distance between every two blocks in 3D BD. Then, feature descriptor is obtained by coding the pulmonary nodule with codebook, and 3D GDC feature is the result of histogram statistics on feature descriptor. Second, geometric features are extracted for fusion feature. Finally, random forest is performed for benign-malignant pulmonary nodule classification with fusion feature of the 3D gray density coding feature and the geometric features. RESULTS: We verify the effectiveness of our method on the public LIDC-IDRI dataset and the private ZSHD dataset. For LIDC-IDRI dataset, compared with other state-of-the-art methods, we achieve more satisfactory results with 93.17 +/- 1.94% for accuracy and 97.53 +/- 1.62% for AUC. As for private ZSHD dataset, it contains a total of 238 lung nodules from 203 patients. The accuracy and AUC achieved by our method are 90.0% and 93.15%. CONCLUSIONS: The results show that our method can provide doctors with more accurate results of benign-malignant pulmonary nodule classification for auxiliary diagnosis, and our method is more interpretable than 3D CNN methods, which can provide doctors with more auxiliary information.",Journal Article,
34608652,10.1002/mp.15260,Automatic segmentation of organs-at-risks of nasopharynx cancer and lung cancer by cross-layer attention fusion network with TELD-Loss.,2021 Nov,Medical physics,"Liu Z, Sun C, Wang H, Li Z, Gao Y, Lei W, Zhang S, Wang G, Zhang S","Humans, Image Processing, Computer-Assisted, Lung, *Lung Neoplasms/diagnostic imaging, *Nasopharyngeal Neoplasms/diagnostic imaging/radiotherapy, Organs at Risk, Tomography, X-Ray Computed, automatic segmentation, deep learning, organs at risk, radiotherapy planning","PURPOSE: Radiotherapy is one of the main treatments of nasopharyngeal cancer (NPC) and lung cancer. Accurate segmentation of organs at risks (OARs) in CT images is a key step in radiotherapy planning for NPC and lung cancer. However, the segmentation of OARs is influenced by the highly imbalanced size of organs, which often results in very poor segmentation results for small and difficult-to-segment organs. In addition, the complex morphological changes and fuzzy boundaries of OARs also pose great challenges to the segmentation task. In this paper, we propose a cross-layer attention fusion network (CLAF-CNN) to solve the problem of accurately segmenting OARs. METHODS: In CLAF-CNN, we integrate the spatial attention maps of the adjacent spatial attention modules to make the segmentation targets more accurately focused, so that the network can capture more target-related features. In this way, the spatial attention modules in the network can be learned and optimized together. In addition, we introduce a new Top-K exponential logarithmic Dice loss (TELD-Loss) to solve the imbalance problem in OAR segmentation. The TELD-Loss further introduces a Top-K optimization mechanism based on Dice loss and exponential logarithmic loss, which makes the network pay more attention to small organs and difficult-to-segment organs, so as to enhance the overall performance of the segmentation model. RESULTS: We validated our framework on the OAR segmentation datasets of the head and neck and lung CT images in the StructSeg 2019 challenge. Experiments show that the CLAF-CNN outperforms the state-of-the-art attention-based segmentation methods in the OAR segmentation task with average Dice coefficient of 79.65% for head and neck OARs and 88.39% for lung OARs. CONCLUSIONS: This work provides a new network named CLAF-CNN which contains cross-layer spatial attention map fusion architecture and TELD-Loss for OAR segmentation. Results demonstrated that the proposed method could obtain accurate segmentation results for OARs, which has a potential of improving the efficiency of radiotherapy planning for nasopharynx cancer and lung cancer.",Journal Article,
34556141,10.1186/s12938-021-00932-1,A 2D-3D hybrid convolutional neural network for lung lobe auto-segmentation on standard slice thickness computed tomography of patients receiving radiotherapy.,2021 Sep 23,Biomedical engineering online,"Gu H, Gan W, Zhang C, Feng A, Wang H, Huang Y, Chen H, Shao Y, Duan Y, Xu Z","*Carcinoma, Non-Small-Cell Lung, Humans, Image Processing, Computer-Assisted, Lung/diagnostic imaging, *Lung Neoplasms/diagnostic imaging/radiotherapy, Neural Networks, Computer, Retrospective Studies, Tomography, X-Ray Computed, Artificial intelligence, Automatic segmentation, Computed tomography, Convolutional neural network, Lung lobe","BACKGROUND: Accurate segmentation of lung lobe on routine computed tomography (CT) images of locally advanced stage lung cancer patients undergoing radiotherapy can help radiation oncologists to implement lobar-level treatment planning, dose assessment and efficacy prediction. We aim to establish a novel 2D-3D hybrid convolutional neural network (CNN) to provide reliable lung lobe auto-segmentation results in the clinical setting. METHODS: We retrospectively collected and evaluated thorax CT scans of 105 locally advanced non-small-cell lung cancer (NSCLC) patients treated at our institution from June 2019 to August 2020. The CT images were acquired with 5 mm slice thickness. Two CNNs were used for lung lobe segmentation, a 3D CNN for extracting 3D contextual information and a 2D CNN for extracting texture information. Contouring quality was evaluated using six quantitative metrics and visual evaluation was performed to assess the clinical acceptability. RESULTS: For the 35 cases in the test group, Dice Similarity Coefficient (DSC) of all lung lobes contours exceeded 0.75, which met the pass criteria of the segmentation result. Our model achieved high performances with DSC as high as 0.9579, 0.9479, 0.9507, 0.9484, and 0.9003 for left upper lobe (LUL), left lower lobe (LLL), right upper lobe (RUL), right lower lobe (RLL), and right middle lobe (RML), respectively. The proposed model resulted in accuracy, sensitivity, and specificity of 99.57, 98.23, 99.65 for LUL; 99.6, 96.14, 99.76 for LLL; 99.67, 96.13, 99.81 for RUL; 99.72, 92.38, 99.83 for RML; 99.58, 96.03, 99.78 for RLL, respectively. Clinician's visual assessment showed that 164/175 lobe contours met the requirements for clinical use, only 11 contours need manual correction. CONCLUSIONS: Our 2D-3D hybrid CNN model achieved accurate automatic segmentation of lung lobes on conventional slice-thickness CT of locally advanced lung cancer patients, and has good clinical practicability.",Journal Article,
34535256,10.1016/j.aca.2021.338821,Accurate diagnosis of lung tissues for 2D Raman spectrogram by deep learning based on short-time Fourier transform.,2021 Sep 22,Analytica chimica acta,"Qi Y, Yang L, Liu B, Liu L, Liu Y, Zheng Q, Liu D, Luo J","*Deep Learning, Fourier Analysis, Lung, Neural Networks, Computer, Support Vector Machine, Deep learning, Lung cancer, Raman spectrogram, Short-time Fourier transform","Multivariate statistical analysis methods have an important role in spectrochemical analyses to rapidly identify and diagnose cancer and the subtype. However, utilizing these methods to analyze lager amount spectral data is challenging, and poses a major bottleneck toward achieving high accuracy. Here, a new convolutional neural networks (CNN) method based on short-time Fourier transform (STFT) to diagnose lung tissues via Raman spectra readily is proposed. The models yield that the accuracies of the new method are higher than the conventional methods (principal components analysis -linear discriminant analysis and support vector machine) for validation group (95.2% vs 85.5%, 94.4%) and test group (96.5% vs 90.4%, 93.9%) after cross-validation. The results illustrate that the new method which converts one-dimensional Raman data into two-dimensional Raman spectrograms improve the discriminatory ability of lung tissues and can achieve automatically accurate diagnosis of lung tissues.",Journal Article,Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
